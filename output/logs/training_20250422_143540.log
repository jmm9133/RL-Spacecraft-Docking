2025-04-22 14:35:40,163 [__main__] [INFO] Initializing Ray...
2025-04-22 14:35:43,835 [__main__] [INFO] Creating temporary environment to get action/observation spaces...
2025-04-22 14:35:43,842 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-22 14:35:43,842 [__main__] [INFO] Spaces retrieved.
2025-04-22 14:35:43,843 [__main__] [INFO] Configuring RLlib PPO Algorithm...
2025-04-22 14:35:43,843 [__main__] [INFO] Using 15 environment runners (workers).
2025-04-22 14:35:43,843 [__main__] [INFO] Setting train_batch_size to 4000 (min required estimate: 3000)
2025-04-22 14:35:43,845 [__main__] [INFO] Building Algorithm...
2025-04-22 14:36:03,919 [__main__] [INFO] Algorithm Built. Using Policy/Module Class: DefaultPPOTorchRLModule
2025-04-22 14:36:03,919 [__main__] [INFO] 
--- Starting Training for 100 iterations ---
2025-04-22 14:36:09,475 [__main__] [INFO] Iter: 1/100, Ts(iter): 0, Ts(total): 4000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.56s
2025-04-22 14:36:17,993 [__main__] [INFO] Iter: 2/100, Ts(iter): 0, Ts(total): 8000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 8.51s
2025-04-22 14:36:27,059 [__main__] [INFO] Iter: 3/100, Ts(iter): 0, Ts(total): 12000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 9.06s
2025-04-22 14:36:33,382 [__main__] [INFO] Iter: 4/100, Ts(iter): 0, Ts(total): 16000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 6.32s
2025-04-22 14:36:38,387 [__main__] [INFO] Iter: 5/100, Ts(iter): 0, Ts(total): 20000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.00s
2025-04-22 14:36:43,475 [__main__] [INFO] Iter: 6/100, Ts(iter): 0, Ts(total): 24000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.09s
2025-04-22 14:36:48,637 [__main__] [INFO] Iter: 7/100, Ts(iter): 0, Ts(total): 28000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.16s
2025-04-22 14:36:54,143 [__main__] [INFO] Iter: 8/100, Ts(iter): 0, Ts(total): 32000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.51s
2025-04-22 14:36:58,928 [__main__] [INFO] Iter: 9/100, Ts(iter): 0, Ts(total): 36000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 4.78s
2025-04-22 14:37:21,840 [__main__] [INFO] Iter: 10/100, Ts(iter): 0, Ts(total): 40000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 22.91s
2025-04-22 14:37:21,841 [__main__] [DEBUG] Full result dict at iter 10: {'timers': {'training_iteration': 5.532647211910518, 'restore_env_runners': 8.13717220086347e-05, 'training_step': 5.531975365375533, 'env_runner_sampling_timer': 1.7942577322774016, 'learner_update_timer': 3.71980400737343, 'synch_weights': 0.014643054108566993, 'synch_env_connectors': 0.015106669691564826, 'restore_eval_env_runners': 1.1964002624154091e-05, 'evaluation_iteration': nan, 'synch_eval_env_connectors': 0.3265130429645069}, 'env_runners': {'num_env_steps_sampled': 4000, 'num_module_steps_sampled_lifetime': {'target': 40000, 'servicer': 40000}, 'timers': {'connectors': {'numpy_to_tensor': 0.00020103947026655077, 'batch_individual_items': 0.00015657127369195223, 'add_time_dim_to_batch_and_zero_pad': 7.04334699548781e-05, 'agent_to_module_mapping': 3.158980204413334e-05, 'add_states_from_episodes_to_batch': 3.829686902463436e-05, 'add_observations_from_episodes_to_batch': 0.00012535152879233162}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.0004000479124434584, 'listify_data_for_vector_env': 4.90630958810875e-05, 'remove_single_ts_time_rank_from_batch': 1.0360383906324027e-05, 'get_actions': 0.00101854954483723, 'module_to_agent_unmapping': 2.2801774080738958e-05, 'un_batch_to_individual_items': 0.00015375045624253626, 'tensor_to_numpy': 0.00034336434178123333}}, 'connector_pipeline_timer': 0.0023407362414109363}, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 40000, 'servicer': 40000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 0.00013743126486341905, 'add_time_dim_to_batch_and_zero_pad': 5.054636607533149e-05, 'agent_to_module_mapping': 2.4168574019188444e-05, 'add_states_from_episodes_to_batch': 3.80539620674586e-05, 'add_observations_from_episodes_to_batch': 9.793196477585553e-05, 'numpy_to_tensor': 0.0002193802951842997}}, 'connector_pipeline_timer': 0.0008388926079985949}, 'env_to_module_sum_episodes_length_in': 175.07360663293434, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'connector_pipeline_timer': 0.001179325138218701, 'env_step_timer': 0.001042836968500918, 'sample': 1.7189527425916713, 'rlmodule_inference_timer': 0.001158531563537335, 'weights_seq_no': 9.0, 'env_to_module_sum_episodes_length_out': 175.07360663293434, 'num_env_steps_sampled_lifetime': 40000, 'env_reset_timer': 0.0006519301251197855, 'time_between_sampling': 3.8781226268640423, 'episode_return_mean': -168.80877059879052, 'module_episode_returns_mean': {'target': -2.6311576257348057, 'servicer': -166.17761297305574}, 'episode_return_max': -164.040644915361, 'episode_return_min': -172.73436770415296, 'agent_episode_returns_mean': {'servicer': -166.17761297305574, 'target': -2.6311576257348057}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 11.995061706379058, 'num_episodes_lifetime': 15, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 738.7823556769414}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 1.7546181627788535e-05, 'general_advantage_estimation': 0.134030745678833, 'add_observations_from_episodes_to_batch': 0.0008007477456934687, 'add_one_ts_to_episodes_and_truncate': 0.014476668082869869, 'numpy_to_tensor': 0.0003559570029006961, 'add_columns_from_episodes_to_train_batch': 0.2578416455669035, 'batch_individual_items': 0.5087598394078311, 'add_time_dim_to_batch_and_zero_pad': 4.9407055181251505e-05, 'agent_to_module_mapping': 0.01344461562813201}}, 'connector_pipeline_timer': 0.9303900285237716}, 'num_env_steps_trained': 504000, 'num_module_steps_trained_lifetime': 322560, 'num_non_trainable_parameters': 0.0, 'num_module_steps_trained': 32256, 'num_env_steps_trained_lifetime': 5040000, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'curr_entropy_coeff': 2e-06, 'vf_loss': 8.32608639029786e-05, 'curr_kl_coeff': 0.15000000596046448, 'entropy': 8.348675727844238, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 8.32608639029786e-05, 'gradients_default_optimizer_global_norm': 1.020065426826477, 'num_trainable_parameters': 142093.0, 'policy_loss': -0.004129220265895128, 'mean_kl_loss': 0.008752312511205673, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': -0.03474557399749756, 'module_train_batch_size_mean': 128.0, 'total_loss': -0.002749806735664606, 'weights_seq_no': 10.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 161280}, 'servicer': {'mean_kl_loss': 0.004051428288221359, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.10956698656082153, 'total_loss': 0.3344220817089081, 'weights_seq_no': 10.0, 'curr_kl_coeff': 0.15000000596046448, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 2e-06, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 161280, 'vf_loss': 0.16470672190189362, 'entropy': 7.891948699951172, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 0.16470672190189362, 'gradients_default_optimizer_global_norm': 3.3440310955047607, 'num_trainable_parameters': 142093.0, 'policy_loss': 0.16851568222045898}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 40000, 'evaluation': {'env_runners': {'num_env_steps_sampled': 7500, 'num_module_steps_sampled_lifetime': {'target': 7500, 'servicer': 7500}, 'episode_return_mean': -180.8183656733099, 'timers': {'connectors': {'numpy_to_tensor': 0.00016516901087015867, 'add_time_dim_to_batch_and_zero_pad': 0.00021535600535571575, 'agent_to_module_mapping': 3.166601527482271e-05, 'add_states_from_episodes_to_batch': 4.747702041640878e-05, 'batch_individual_items': 0.0003348669852130115, 'add_observations_from_episodes_to_batch': 0.0009939500014297664}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.00017704695058876264, 'listify_data_for_vector_env': 2.5417171365161547e-05, 'get_actions': 0.00019702376205840653, 'remove_single_ts_time_rank_from_batch': 3.533706538607142e-06, 'module_to_agent_unmapping': 1.0480374357990282e-05, 'un_batch_to_individual_items': 6.82243279256014e-05, 'tensor_to_numpy': 0.0001702879570292968}}, 'connector_pipeline_timer': 0.0008120978735578746}, 'module_episode_returns_mean': {'target': -0.6634329526126386, 'servicer': -180.15493272069725}, 'num_module_steps_sampled': {'servicer': 7500, 'target': 7500}, 'episode_return_max': -180.80308401955998, 'num_agent_steps_sampled_lifetime': {'target': 7500, 'servicer': 7500}, 'episode_return_min': -180.87949228830965, 'agent_episode_returns_mean': {'servicer': -180.15493272069725, 'target': -0.6634329526126386}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 6.616641514814503e-05, 'add_time_dim_to_batch_and_zero_pad': 2.3217813593993213e-05, 'agent_to_module_mapping': 1.1115524604448303e-05, 'add_states_from_episodes_to_batch': 1.4110773113984614e-05, 'add_observations_from_episodes_to_batch': 4.962797410290875e-05, 'numpy_to_tensor': 0.00010404133972237554}}, 'connector_pipeline_timer': 0.000391260097250705}, 'env_to_module_sum_episodes_length_in': 1401.0004172977287, 'num_agent_steps_sampled': {'servicer': 7500, 'target': 7500}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 3.9683167352108284, 'connector_pipeline_timer': 0.00323081505484879, 'env_step_timer': 0.00048582966600152293, 'sample': 20.810951263003517, 'num_episodes_lifetime': 5, 'rlmodule_inference_timer': 0.0005028682483540725, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'weights_seq_no': 9.0, 'num_episodes': 5, 'env_to_module_sum_episodes_length_out': 1401.0004172977287, 'num_env_steps_sampled_lifetime': 7500, 'env_reset_timer': 0.007764507958199829}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'fault_tolerance': {'num_healthy_workers': 15, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 738.7823556769414, 'done': False, 'training_iteration': 10, 'trial_id': 'default', 'date': '2025-04-22_14-37-21', 'timestamp': 1745347041, 'time_this_iter_s': 22.86004114151001, 'time_total_s': 77.17459344863892, 'pid': 58263, 'hostname': 'Nathans-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 15, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 4, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x15acc7d80>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 2e-06, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 77.17459344863892, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 43.230303030303034, 'ram_util_percent': 66.15757575757576}}
2025-04-22 14:37:27,663 [__main__] [INFO] Iter: 11/100, Ts(iter): 0, Ts(total): 44000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.82s
2025-04-22 14:37:41,914 [__main__] [INFO] Iter: 12/100, Ts(iter): 0, Ts(total): 48000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 14.25s
2025-04-22 14:37:50,203 [__main__] [INFO] Iter: 13/100, Ts(iter): 0, Ts(total): 52000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 8.29s
2025-04-22 14:37:57,787 [__main__] [INFO] Iter: 14/100, Ts(iter): 0, Ts(total): 56000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 7.58s
2025-04-22 14:38:04,278 [__main__] [INFO] Iter: 15/100, Ts(iter): 0, Ts(total): 60000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 6.49s
2025-04-22 14:38:10,835 [__main__] [INFO] Iter: 16/100, Ts(iter): 0, Ts(total): 64000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 6.56s
2025-04-22 14:38:17,215 [__main__] [INFO] Iter: 17/100, Ts(iter): 0, Ts(total): 68000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 6.38s
2025-04-22 14:38:24,126 [__main__] [INFO] Iter: 18/100, Ts(iter): 0, Ts(total): 72000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 6.91s
2025-04-22 14:38:30,065 [__main__] [INFO] Iter: 19/100, Ts(iter): 0, Ts(total): 76000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.94s
2025-04-22 14:38:54,870 [__main__] [INFO] Iter: 20/100, Ts(iter): 0, Ts(total): 80000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 24.80s
2025-04-22 14:38:54,871 [__main__] [DEBUG] Full result dict at iter 20: {'timers': {'training_iteration': 5.702038112442126, 'restore_env_runners': 7.644733664694718e-05, 'training_step': 5.7013711443531445, 'env_runner_sampling_timer': 1.8794472308034318, 'learner_update_timer': 3.8035192910194993, 'synch_weights': 0.015020784000925002, 'synch_env_connectors': 0.015261480648016433, 'restore_eval_env_runners': 1.2010032078251243e-05, 'evaluation_iteration': 22.836452930991072, 'synch_eval_env_connectors': 0.3235866870346945}, 'env_runners': {'num_env_steps_sampled': 4000, 'num_module_steps_sampled_lifetime': {'target': 80000, 'servicer': 80000}, 'timers': {'connectors': {'numpy_to_tensor': 0.00020103947026655077, 'batch_individual_items': 0.00015657127369195223, 'add_time_dim_to_batch_and_zero_pad': 7.04334699548781e-05, 'agent_to_module_mapping': 3.158980204413334e-05, 'add_states_from_episodes_to_batch': 3.829686902463436e-05, 'add_observations_from_episodes_to_batch': 0.00012535152879233162}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.00042388697169342565, 'listify_data_for_vector_env': 5.461812574644127e-05, 'remove_single_ts_time_rank_from_batch': 1.1206321924959576e-05, 'get_actions': 0.0010887096465896976, 'module_to_agent_unmapping': 2.7280041715986524e-05, 'un_batch_to_individual_items': 0.0007239534348526045, 'tensor_to_numpy': 0.0003927324322079171}}, 'connector_pipeline_timer': 0.0030998958339119405}, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 80000, 'servicer': 80000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 0.0001434953252077616, 'add_time_dim_to_batch_and_zero_pad': 5.5523647674972014e-05, 'agent_to_module_mapping': 2.6067072774021326e-05, 'add_states_from_episodes_to_batch': 3.706900009145143e-05, 'add_observations_from_episodes_to_batch': 0.0001106960979523192, 'numpy_to_tensor': 0.00024841045682495494}}, 'connector_pipeline_timer': 0.0009257213946185553}, 'env_to_module_sum_episodes_length_in': 175.34915821885585, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'connector_pipeline_timer': 0.001179325138218701, 'env_step_timer': 0.0011132711744642786, 'sample': 1.7773901458355874, 'rlmodule_inference_timer': 0.0012754261106751152, 'weights_seq_no': 19.0, 'env_to_module_sum_episodes_length_out': 175.34915821885585, 'num_env_steps_sampled_lifetime': 80000, 'env_reset_timer': 0.0006519301251197855, 'time_between_sampling': 4.059308195617288, 'episode_return_mean': -175.42989217402712, 'module_episode_returns_mean': {'target': -2.5885442803164325, 'servicer': -172.84134789371072}, 'episode_return_max': -172.0872550208069, 'episode_return_min': -183.69738772719856, 'agent_episode_returns_mean': {'servicer': -172.84134789371072, 'target': -2.5885442803164325}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 16.783899250199706, 'num_episodes_lifetime': 45, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 641.4431342563925}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 1.7617732647090376e-05, 'general_advantage_estimation': 0.13319823313677706, 'add_observations_from_episodes_to_batch': 0.000806174207533067, 'add_one_ts_to_episodes_and_truncate': 0.014561917305967374, 'numpy_to_tensor': 0.00035974330281627687, 'add_columns_from_episodes_to_train_batch': 0.25890100941666583, 'batch_individual_items': 0.5076533863959493, 'add_time_dim_to_batch_and_zero_pad': 5.162344977913821e-05, 'agent_to_module_mapping': 0.013527900039983411}}, 'connector_pipeline_timer': 0.9296909005619263}, 'num_env_steps_trained': 504000, 'num_module_steps_trained_lifetime': 645120, 'num_non_trainable_parameters': 0.0, 'num_module_steps_trained': 32256, 'num_env_steps_trained_lifetime': 10080000, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'curr_entropy_coeff': 2e-06, 'vf_loss': 4.950134825776331e-05, 'curr_kl_coeff': 0.15000000596046448, 'entropy': 7.753432273864746, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 4.950134825776331e-05, 'gradients_default_optimizer_global_norm': 0.7837075591087341, 'num_trainable_parameters': 142093.0, 'policy_loss': 0.12093780934810638, 'mean_kl_loss': 0.011959103867411613, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.06532144546508789, 'module_train_batch_size_mean': 128.0, 'total_loss': 0.1227656826376915, 'weights_seq_no': 20.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 322560}, 'servicer': {'mean_kl_loss': 0.0010372675023972988, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.05535358190536499, 'total_loss': 0.29293665289878845, 'weights_seq_no': 20.0, 'curr_kl_coeff': 0.11250000447034836, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 2e-06, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 322560, 'vf_loss': 0.21191062033176422, 'entropy': 7.9985833168029785, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 0.21191062033176422, 'gradients_default_optimizer_global_norm': 1.6032425165176392, 'num_trainable_parameters': 142093.0, 'policy_loss': 0.08080865442752838}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_env_steps_sampled': 7500, 'num_module_steps_sampled_lifetime': {'target': 15000, 'servicer': 15000}, 'episode_return_mean': -181.03734002787232, 'timers': {'connectors': {'numpy_to_tensor': 0.00016518282606848517, 'add_time_dim_to_batch_and_zero_pad': 0.0002153613039525226, 'agent_to_module_mapping': 3.1666418170789254e-05, 'add_states_from_episodes_to_batch': 4.747950811870396e-05, 'batch_individual_items': 0.00033487170651205815, 'add_observations_from_episodes_to_batch': 0.0009939019311277662}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.00017708036441336058, 'listify_data_for_vector_env': 2.540776935332825e-05, 'get_actions': 0.0001971185599253448, 'remove_single_ts_time_rank_from_batch': 3.535563892066095e-06, 'module_to_agent_unmapping': 1.0478885652135602e-05, 'un_batch_to_individual_items': 6.824136263358542e-05, 'tensor_to_numpy': 0.000170176800689761}}, 'connector_pipeline_timer': 0.000812148316367632}, 'module_episode_returns_mean': {'target': -0.6677945675949261, 'servicer': -180.36954546027744}, 'num_module_steps_sampled': {'servicer': 7500, 'target': 7500}, 'episode_return_max': -180.80308401955998, 'num_agent_steps_sampled_lifetime': {'target': 15000, 'servicer': 15000}, 'episode_return_min': -181.47534854547595, 'agent_episode_returns_mean': {'servicer': -180.36954546027744, 'target': -0.6677945675949261}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 6.613468544036492e-05, 'add_time_dim_to_batch_and_zero_pad': 2.3218184341830107e-05, 'agent_to_module_mapping': 1.1123267161980855e-05, 'add_states_from_episodes_to_batch': 1.4122877667822868e-05, 'add_observations_from_episodes_to_batch': 4.9628837066559364e-05, 'numpy_to_tensor': 0.00010402814506425285}}, 'connector_pipeline_timer': 0.0003912529082000569}, 'env_to_module_sum_episodes_length_in': 1401.0004172977287, 'num_agent_steps_sampled': {'servicer': 7500, 'target': 7500}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 4.148215617476186, 'connector_pipeline_timer': 0.003230770042340737, 'env_step_timer': 0.00048617070982467697, 'sample': 20.81116637244582, 'num_episodes_lifetime': 10, 'rlmodule_inference_timer': 0.000503124432588812, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'weights_seq_no': 19.0, 'num_episodes': 5, 'env_to_module_sum_episodes_length_out': 1401.0004172977287, 'num_env_steps_sampled_lifetime': 15000, 'env_reset_timer': 0.00776402313040453, 'num_env_steps_sampled_per_second': 328.42228268392074, 'time_between_sampling': 70.06400312599726}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 80000, 'fault_tolerance': {'num_healthy_workers': 15, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 641.4431342563925, 'done': False, 'training_iteration': 20, 'trial_id': 'default', 'date': '2025-04-22_14-38-54', 'timestamp': 1745347134, 'time_this_iter_s': 24.75239396095276, 'time_total_s': 169.5022964477539, 'pid': 58263, 'hostname': 'Nathans-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 15, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 4, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x15acc7d80>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 2e-06, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 169.5022964477539, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 47.92285714285714, 'ram_util_percent': 71.35428571428572}}
2025-04-22 14:38:54,975 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/leo/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 5.702038112442126, 'restore_env_runners': 7.644733664694718e-05, 'training_step': 5.7013711443531445, 'env_runner_sampling_timer': 1.8794472308034318, 'learner_update_timer': 3.8035192910194993, 'synch_weights': 0.015020784000925002, 'synch_env_connectors': 0.015261480648016433, 'restore_eval_env_runners': 1.2010032078251243e-05, 'evaluation_iteration': 22.836452930991072, 'synch_eval_env_connectors': 0.3235866870346945}, 'env_runners': {'num_env_steps_sampled': 4000, 'num_module_steps_sampled_lifetime': {'target': 80000, 'servicer': 80000}, 'timers': {'connectors': {'numpy_to_tensor': 0.00020103947026655077, 'batch_individual_items': 0.00015657127369195223, 'add_time_dim_to_batch_and_zero_pad': 7.04334699548781e-05, 'agent_to_module_mapping': 3.158980204413334e-05, 'add_states_from_episodes_to_batch': 3.829686902463436e-05, 'add_observations_from_episodes_to_batch': 0.00012535152879233162}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.00042388697169342565, 'listify_data_for_vector_env': 5.461812574644127e-05, 'remove_single_ts_time_rank_from_batch': 1.1206321924959576e-05, 'get_actions': 0.0010887096465896976, 'module_to_agent_unmapping': 2.7280041715986524e-05, 'un_batch_to_individual_items': 0.0007239534348526045, 'tensor_to_numpy': 0.0003927324322079171}}, 'connector_pipeline_timer': 0.0030998958339119405}, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 80000, 'servicer': 80000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 0.0001434953252077616, 'add_time_dim_to_batch_and_zero_pad': 5.5523647674972014e-05, 'agent_to_module_mapping': 2.6067072774021326e-05, 'add_states_from_episodes_to_batch': 3.706900009145143e-05, 'add_observations_from_episodes_to_batch': 0.0001106960979523192, 'numpy_to_tensor': 0.00024841045682495494}}, 'connector_pipeline_timer': 0.0009257213946185553}, 'env_to_module_sum_episodes_length_in': 175.34915821885585, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'connector_pipeline_timer': 0.001179325138218701, 'env_step_timer': 0.0011132711744642786, 'sample': 1.7773901458355874, 'rlmodule_inference_timer': 0.0012754261106751152, 'weights_seq_no': 19.0, 'env_to_module_sum_episodes_length_out': 175.34915821885585, 'num_env_steps_sampled_lifetime': 80000, 'env_reset_timer': 0.0006519301251197855, 'time_between_sampling': 4.059308195617288, 'episode_return_mean': -175.42989217402712, 'module_episode_returns_mean': {'target': -2.5885442803164325, 'servicer': -172.84134789371072}, 'episode_return_max': -172.0872550208069, 'episode_return_min': -183.69738772719856, 'agent_episode_returns_mean': {'servicer': -172.84134789371072, 'target': -2.5885442803164325}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 16.783899250199706, 'num_episodes_lifetime': 45, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 641.4431342563925}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 1.7617732647090376e-05, 'general_advantage_estimation': 0.13319823313677706, 'add_observations_from_episodes_to_batch': 0.000806174207533067, 'add_one_ts_to_episodes_and_truncate': 0.014561917305967374, 'numpy_to_tensor': 0.00035974330281627687, 'add_columns_from_episodes_to_train_batch': 0.25890100941666583, 'batch_individual_items': 0.5076533863959493, 'add_time_dim_to_batch_and_zero_pad': 5.162344977913821e-05, 'agent_to_module_mapping': 0.013527900039983411}}, 'connector_pipeline_timer': 0.9296909005619263}, 'num_env_steps_trained': 504000, 'num_module_steps_trained_lifetime': 645120, 'num_non_trainable_parameters': 0.0, 'num_module_steps_trained': 32256, 'num_env_steps_trained_lifetime': 10080000, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'curr_entropy_coeff': 2e-06, 'vf_loss': 4.950134825776331e-05, 'curr_kl_coeff': 0.15000000596046448, 'entropy': 7.753432273864746, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 4.950134825776331e-05, 'gradients_default_optimizer_global_norm': 0.7837075591087341, 'num_trainable_parameters': 142093.0, 'policy_loss': 0.12093780934810638, 'mean_kl_loss': 0.011959103867411613, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.06532144546508789, 'module_train_batch_size_mean': 128.0, 'total_loss': 0.1227656826376915, 'weights_seq_no': 20.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 322560}, 'servicer': {'mean_kl_loss': 0.0010372675023972988, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.05535358190536499, 'total_loss': 0.29293665289878845, 'weights_seq_no': 20.0, 'curr_kl_coeff': 0.11250000447034836, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 2e-06, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 322560, 'vf_loss': 0.21191062033176422, 'entropy': 7.9985833168029785, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 0.21191062033176422, 'gradients_default_optimizer_global_norm': 1.6032425165176392, 'num_trainable_parameters': 142093.0, 'policy_loss': 0.08080865442752838}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_env_steps_sampled': 7500, 'num_module_steps_sampled_lifetime': {'target': 15000, 'servicer': 15000}, 'episode_return_mean': -181.03734002787232, 'timers': {'connectors': {'numpy_to_tensor': 0.00016518282606848517, 'add_time_dim_to_batch_and_zero_pad': 0.0002153613039525226, 'agent_to_module_mapping': 3.1666418170789254e-05, 'add_states_from_episodes_to_batch': 4.747950811870396e-05, 'batch_individual_items': 0.00033487170651205815, 'add_observations_from_episodes_to_batch': 0.0009939019311277662}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.00017708036441336058, 'listify_data_for_vector_env': 2.540776935332825e-05, 'get_actions': 0.0001971185599253448, 'remove_single_ts_time_rank_from_batch': 3.535563892066095e-06, 'module_to_agent_unmapping': 1.0478885652135602e-05, 'un_batch_to_individual_items': 6.824136263358542e-05, 'tensor_to_numpy': 0.000170176800689761}}, 'connector_pipeline_timer': 0.000812148316367632}, 'module_episode_returns_mean': {'target': -0.6677945675949261, 'servicer': -180.36954546027744}, 'num_module_steps_sampled': {'servicer': 7500, 'target': 7500}, 'episode_return_max': -180.80308401955998, 'num_agent_steps_sampled_lifetime': {'target': 15000, 'servicer': 15000}, 'episode_return_min': -181.47534854547595, 'agent_episode_returns_mean': {'servicer': -180.36954546027744, 'target': -0.6677945675949261}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 6.613468544036492e-05, 'add_time_dim_to_batch_and_zero_pad': 2.3218184341830107e-05, 'agent_to_module_mapping': 1.1123267161980855e-05, 'add_states_from_episodes_to_batch': 1.4122877667822868e-05, 'add_observations_from_episodes_to_batch': 4.9628837066559364e-05, 'numpy_to_tensor': 0.00010402814506425285}}, 'connector_pipeline_timer': 0.0003912529082000569}, 'env_to_module_sum_episodes_length_in': 1401.0004172977287, 'num_agent_steps_sampled': {'servicer': 7500, 'target': 7500}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 4.148215617476186, 'connector_pipeline_timer': 0.003230770042340737, 'env_step_timer': 0.00048617070982467697, 'sample': 20.81116637244582, 'num_episodes_lifetime': 10, 'rlmodule_inference_timer': 0.000503124432588812, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'weights_seq_no': 19.0, 'num_episodes': 5, 'env_to_module_sum_episodes_length_out': 1401.0004172977287, 'num_env_steps_sampled_lifetime': 15000, 'env_reset_timer': 0.00776402313040453, 'num_env_steps_sampled_per_second': 328.42228268392074, 'time_between_sampling': 70.06400312599726}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 80000, 'fault_tolerance': {'num_healthy_workers': 15, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 641.4431342563925, 'done': False, 'training_iteration': 20, 'trial_id': 'default', 'date': '2025-04-22_14-38-54', 'timestamp': 1745347134, 'time_this_iter_s': 24.75239396095276, 'time_total_s': 169.5022964477539, 'pid': 58263, 'hostname': 'Nathans-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 15, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 4, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x15acc7d80>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 2e-06, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 169.5022964477539, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 47.92285714285714, 'ram_util_percent': 71.35428571428572}})
2025-04-22 14:39:01,006 [__main__] [INFO] Iter: 21/100, Ts(iter): 0, Ts(total): 84000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 6.03s
2025-04-22 14:39:06,755 [__main__] [INFO] Iter: 22/100, Ts(iter): 0, Ts(total): 88000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.75s
2025-04-22 14:39:12,654 [__main__] [INFO] Iter: 23/100, Ts(iter): 0, Ts(total): 92000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.90s
2025-04-22 14:39:18,534 [__main__] [INFO] Iter: 24/100, Ts(iter): 0, Ts(total): 96000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.88s
2025-04-22 14:39:24,656 [__main__] [INFO] Iter: 25/100, Ts(iter): 0, Ts(total): 100000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 6.12s
2025-04-22 14:39:29,973 [__main__] [INFO] Iter: 26/100, Ts(iter): 0, Ts(total): 104000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.32s
2025-04-22 14:39:35,860 [__main__] [INFO] Iter: 27/100, Ts(iter): 0, Ts(total): 108000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.89s
2025-04-22 14:39:41,460 [__main__] [INFO] Iter: 28/100, Ts(iter): 0, Ts(total): 112000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.60s
2025-04-22 14:39:47,561 [__main__] [INFO] Iter: 29/100, Ts(iter): 0, Ts(total): 116000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 6.10s
2025-04-22 14:40:10,396 [__main__] [INFO] Iter: 30/100, Ts(iter): 0, Ts(total): 120000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 22.83s
2025-04-22 14:40:10,397 [__main__] [DEBUG] Full result dict at iter 30: {'timers': {'training_iteration': 5.702204750742694, 'restore_env_runners': 7.137885063484452e-05, 'training_step': 5.701548539910929, 'env_runner_sampling_timer': 1.8943711413537976, 'learner_update_timer': 3.788886338260956, 'synch_weights': 0.01488384861073136, 'synch_env_connectors': 0.015892524396636583, 'restore_eval_env_runners': 1.2051871872972696e-05, 'evaluation_iteration': 22.85537655685097, 'synch_eval_env_connectors': 0.32040612905406163}, 'env_runners': {'num_env_steps_sampled': 4000, 'num_module_steps_sampled_lifetime': {'target': 120000, 'servicer': 120000}, 'timers': {'connectors': {'numpy_to_tensor': 0.00020103947026655077, 'batch_individual_items': 0.00015657127369195223, 'add_time_dim_to_batch_and_zero_pad': 7.04334699548781e-05, 'agent_to_module_mapping': 3.158980204413334e-05, 'add_states_from_episodes_to_batch': 3.829686902463436e-05, 'add_observations_from_episodes_to_batch': 0.00012535152879233162}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.0004099268904574899, 'listify_data_for_vector_env': 5.355129203021787e-05, 'remove_single_ts_time_rank_from_batch': 8.177038279160769e-06, 'get_actions': 0.0010415865571190917, 'module_to_agent_unmapping': 2.3635594327570278e-05, 'un_batch_to_individual_items': 0.0002878246740277624, 'tensor_to_numpy': 0.0003692946834277597}}, 'connector_pipeline_timer': 0.0025675190586514555}, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 120000, 'servicer': 120000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 0.0001443437729679776, 'add_time_dim_to_batch_and_zero_pad': 5.642402661417935e-05, 'agent_to_module_mapping': 2.693798464646258e-05, 'add_states_from_episodes_to_batch': 3.76997811600547e-05, 'add_observations_from_episodes_to_batch': 0.0001093977174547701, 'numpy_to_tensor': 0.00023501415941994575}}, 'connector_pipeline_timer': 0.0009030733203667261}, 'env_to_module_sum_episodes_length_in': 175.52170132942442, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'connector_pipeline_timer': 0.001179325138218701, 'env_step_timer': 0.0010689787578457106, 'sample': 1.8061580187284825, 'rlmodule_inference_timer': 0.0012424160248227774, 'weights_seq_no': 29.0, 'env_to_module_sum_episodes_length_out': 175.52170132942442, 'num_env_steps_sampled_lifetime': 120000, 'env_reset_timer': 0.0006519301251197855, 'time_between_sampling': 4.23991615404056, 'episode_return_mean': -171.30746547058558, 'module_episode_returns_mean': {'target': -2.3760891886423035, 'servicer': -168.93137628194327}, 'episode_return_max': -165.85573094370824, 'episode_return_min': -176.599662941239, 'agent_episode_returns_mean': {'servicer': -168.93137628194327, 'target': -2.3760891886423035}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 10.734605540214885, 'num_episodes_lifetime': 75, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 717.2127899330645}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 1.7691456298113376e-05, 'general_advantage_estimation': 0.13181447120533352, 'add_observations_from_episodes_to_batch': 0.0008111096136524178, 'add_one_ts_to_episodes_and_truncate': 0.014676648277627106, 'numpy_to_tensor': 0.00036332829880034655, 'add_columns_from_episodes_to_train_batch': 0.2602907397195047, 'batch_individual_items': 0.5054489827406432, 'add_time_dim_to_batch_and_zero_pad': 5.3477248149409464e-05, 'agent_to_module_mapping': 0.013679363294335316}}, 'connector_pipeline_timer': 0.9277676817781678}, 'num_env_steps_trained': 504000, 'num_module_steps_trained_lifetime': 967680, 'num_non_trainable_parameters': 0.0, 'num_module_steps_trained': 32256, 'num_env_steps_trained_lifetime': 15120000, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'curr_entropy_coeff': 2e-06, 'vf_loss': 4.778684160555713e-05, 'curr_kl_coeff': 0.07500000298023224, 'entropy': 6.599981307983398, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 4.778684160555713e-05, 'gradients_default_optimizer_global_norm': 1.0756080150604248, 'num_trainable_parameters': 142093.0, 'policy_loss': 0.04643995314836502, 'mean_kl_loss': 0.005959717091172934, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.09690433740615845, 'module_train_batch_size_mean': 128.0, 'total_loss': 0.046921517699956894, 'weights_seq_no': 30.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 483840}, 'servicer': {'mean_kl_loss': 0.008072893135249615, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.0940520167350769, 'total_loss': 0.33712977170944214, 'weights_seq_no': 30.0, 'curr_kl_coeff': 0.05625000223517418, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 2e-06, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 483840, 'vf_loss': 0.23511621356010437, 'entropy': 8.164209365844727, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 0.23511621356010437, 'gradients_default_optimizer_global_norm': 1.8692412376403809, 'num_trainable_parameters': 142093.0, 'policy_loss': 0.1015758216381073}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_env_steps_sampled': 7500, 'num_module_steps_sampled_lifetime': {'target': 22500, 'servicer': 22500}, 'episode_return_mean': -179.15901214577607, 'timers': {'connectors': {'numpy_to_tensor': 0.0001652011856631143, 'add_time_dim_to_batch_and_zero_pad': 0.0002153489789760206, 'agent_to_module_mapping': 3.1665322904358616e-05, 'add_states_from_episodes_to_batch': 4.747936256648973e-05, 'batch_individual_items': 0.0003348532909861533, 'add_observations_from_episodes_to_batch': 0.0009937636304314947}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.00017692273880577083, 'listify_data_for_vector_env': 2.53819470481836e-05, 'get_actions': 0.00019685827452562294, 'remove_single_ts_time_rank_from_batch': 3.53334560161741e-06, 'module_to_agent_unmapping': 1.0470659233221581e-05, 'un_batch_to_individual_items': 6.818411501411654e-05, 'tensor_to_numpy': 0.00016988581998252455}}, 'connector_pipeline_timer': 0.000811210097431906}, 'module_episode_returns_mean': {'target': -0.6529624475787089, 'servicer': -178.50604969819742}, 'num_module_steps_sampled': {'servicer': 7500, 'target': 7500}, 'episode_return_max': -169.51063130788995, 'num_agent_steps_sampled_lifetime': {'target': 22500, 'servicer': 22500}, 'episode_return_min': -181.47534854547595, 'agent_episode_returns_mean': {'servicer': -178.50604969819742, 'target': -0.6529624475787089}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 6.605290788952522e-05, 'add_time_dim_to_batch_and_zero_pad': 2.3193445218108867e-05, 'agent_to_module_mapping': 1.1113689574246613e-05, 'add_states_from_episodes_to_batch': 1.4114592232472816e-05, 'add_observations_from_episodes_to_batch': 4.960825613226434e-05, 'numpy_to_tensor': 0.00010389347494296308}}, 'connector_pipeline_timer': 0.00039089737042281717}, 'env_to_module_sum_episodes_length_in': 1401.0004172977287, 'num_agent_steps_sampled': {'servicer': 7500, 'target': 7500}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 4.148776895209449, 'connector_pipeline_timer': 0.0032304775517771485, 'env_step_timer': 0.000485461572197445, 'sample': 20.81139612321027, 'num_episodes_lifetime': 15, 'rlmodule_inference_timer': 0.0005025026516781737, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'weights_seq_no': 29.0, 'num_episodes': 5, 'env_to_module_sum_episodes_length_out': 1401.0004172977287, 'num_env_steps_sampled_lifetime': 22500, 'env_reset_timer': 0.0077628308655672005, 'num_env_steps_sampled_per_second': 328.41956343736354, 'time_between_sampling': 70.06245065520005}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 120000, 'fault_tolerance': {'num_healthy_workers': 15, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 717.2127899330645, 'done': False, 'training_iteration': 30, 'trial_id': 'default', 'date': '2025-04-22_14-40-10', 'timestamp': 1745347210, 'time_this_iter_s': 22.786391019821167, 'time_total_s': 244.2641921043396, 'pid': 58263, 'hostname': 'Nathans-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 15, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 4, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x15acc7d80>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 2e-06, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 244.2641921043396, 'iterations_since_restore': 30, 'perf': {'cpu_util_percent': 41.38484848484848, 'ram_util_percent': 62.07575757575758}}
2025-04-22 14:40:15,855 [__main__] [INFO] Iter: 31/100, Ts(iter): 0, Ts(total): 124000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.46s
2025-04-22 14:40:21,142 [__main__] [INFO] Iter: 32/100, Ts(iter): 0, Ts(total): 128000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.29s
2025-04-22 14:40:26,629 [__main__] [INFO] Iter: 33/100, Ts(iter): 0, Ts(total): 132000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.49s
2025-04-22 14:40:31,914 [__main__] [INFO] Iter: 34/100, Ts(iter): 0, Ts(total): 136000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.28s
2025-04-22 14:40:37,305 [__main__] [INFO] Iter: 35/100, Ts(iter): 0, Ts(total): 140000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.39s
2025-04-22 14:40:42,975 [__main__] [INFO] Iter: 36/100, Ts(iter): 0, Ts(total): 144000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.67s
2025-04-22 14:40:48,667 [__main__] [INFO] Iter: 37/100, Ts(iter): 0, Ts(total): 148000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.69s
2025-04-22 14:40:53,268 [__main__] [INFO] Iter: 38/100, Ts(iter): 0, Ts(total): 152000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 4.60s
2025-04-22 14:40:58,090 [__main__] [INFO] Iter: 39/100, Ts(iter): 0, Ts(total): 156000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 4.82s
2025-04-22 14:41:18,930 [__main__] [INFO] Iter: 40/100, Ts(iter): 0, Ts(total): 160000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 20.84s
2025-04-22 14:41:18,931 [__main__] [DEBUG] Full result dict at iter 40: {'timers': {'training_iteration': 5.654591463477846, 'restore_env_runners': 6.634977972828222e-05, 'training_step': 5.653954075433273, 'env_runner_sampling_timer': 1.8884118424914296, 'learner_update_timer': 3.7471942683598654, 'synch_weights': 0.01492477074093068, 'synch_env_connectors': 0.01566633582706906, 'restore_eval_env_runners': 1.205853340087924e-05, 'evaluation_iteration': 22.854499696782582, 'synch_eval_env_connectors': 0.31723523999399006}, 'env_runners': {'num_env_steps_sampled': 4000, 'num_module_steps_sampled_lifetime': {'target': 160000, 'servicer': 160000}, 'timers': {'connectors': {'numpy_to_tensor': 0.00020103947026655077, 'batch_individual_items': 0.00015657127369195223, 'add_time_dim_to_batch_and_zero_pad': 7.04334699548781e-05, 'agent_to_module_mapping': 3.158980204413334e-05, 'add_states_from_episodes_to_batch': 3.829686902463436e-05, 'add_observations_from_episodes_to_batch': 0.00012535152879233162}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.0003693580619036392, 'listify_data_for_vector_env': 4.941215008440156e-05, 'remove_single_ts_time_rank_from_batch': 8.918108245052331e-06, 'get_actions': 0.0009576432995962586, 'module_to_agent_unmapping': 2.2777376435726387e-05, 'un_batch_to_individual_items': 0.00017704012802820162, 'tensor_to_numpy': 0.00032377548972350464}}, 'connector_pipeline_timer': 0.002244692227340976}, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 160000, 'servicer': 160000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 0.00013487145918666341, 'add_time_dim_to_batch_and_zero_pad': 5.056541517856448e-05, 'agent_to_module_mapping': 2.6921535121639124e-05, 'add_states_from_episodes_to_batch': 3.4003549278958254e-05, 'add_observations_from_episodes_to_batch': 9.936336964112523e-05, 'numpy_to_tensor': 0.0002173188877526533}}, 'connector_pipeline_timer': 0.0008309092686560917}, 'env_to_module_sum_episodes_length_in': 167.4497341725226, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'connector_pipeline_timer': 0.001179325138218701, 'env_step_timer': 0.0009866252151641962, 'sample': 1.8127629970628436, 'rlmodule_inference_timer': 0.001131770110929951, 'weights_seq_no': 39.0, 'env_to_module_sum_episodes_length_out': 167.4497341725226, 'num_env_steps_sampled_lifetime': 160000, 'env_reset_timer': 0.0006519301251197855, 'time_between_sampling': 4.363136438746613, 'episode_return_mean': -165.50698354950586, 'module_episode_returns_mean': {'target': -2.1210160134931404, 'servicer': -163.3859675360127}, 'episode_return_max': -160.52807771116292, 'episode_return_min': -169.90680701452698, 'agent_episode_returns_mean': {'servicer': -163.3859675360127, 'target': -2.1210160134931404}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 9.490450580406469, 'num_episodes_lifetime': 105, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'num_episodes': 15, 'num_env_steps_sampled_lifetime_throughput': 732.1111559264446}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 1.7733578369018756e-05, 'general_advantage_estimation': 0.1299429770478446, 'add_observations_from_episodes_to_batch': 0.0008141275387586862, 'add_one_ts_to_episodes_and_truncate': 0.01478396972555439, 'numpy_to_tensor': 0.0003663117541563182, 'add_columns_from_episodes_to_train_batch': 0.261623643004474, 'batch_individual_items': 0.5019658187438456, 'add_time_dim_to_batch_and_zero_pad': 5.482379878446799e-05, 'agent_to_module_mapping': 0.013808654481274784}}, 'connector_pipeline_timer': 0.9239864809900575}, 'num_env_steps_trained': 504000, 'num_module_steps_trained_lifetime': 1290240, 'num_non_trainable_parameters': 0.0, 'num_module_steps_trained': 32256, 'num_env_steps_trained_lifetime': 20160000, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'curr_entropy_coeff': 2e-06, 'vf_loss': 6.693458271911368e-05, 'curr_kl_coeff': 0.01875000074505806, 'entropy': 5.588146686553955, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 6.693458271911368e-05, 'gradients_default_optimizer_global_norm': 1.355878233909607, 'num_trainable_parameters': 142093.0, 'policy_loss': 0.12056872993707657, 'mean_kl_loss': 0.009136169217526913, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.10506433248519897, 'module_train_batch_size_mean': 128.0, 'total_loss': 0.12079578638076782, 'weights_seq_no': 40.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 645120}, 'servicer': {'mean_kl_loss': 0.007429925724864006, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.04301893711090088, 'total_loss': 0.3426823019981384, 'weights_seq_no': 40.0, 'curr_kl_coeff': 0.003515625139698386, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 2e-06, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 645120, 'vf_loss': 0.4151480197906494, 'entropy': 7.57484245300293, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 0.4151480197906494, 'gradients_default_optimizer_global_norm': 0.71403568983078, 'num_trainable_parameters': 142093.0, 'policy_loss': -0.07247668504714966}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_env_steps_sampled': 7500, 'num_module_steps_sampled_lifetime': {'target': 30000, 'servicer': 30000}, 'episode_return_mean': -176.8936057559163, 'timers': {'connectors': {'numpy_to_tensor': 0.00016521522368566306, 'add_time_dim_to_batch_and_zero_pad': 0.000215318639166581, 'agent_to_module_mapping': 3.166221770053438e-05, 'add_states_from_episodes_to_batch': 4.7475780674810524e-05, 'batch_individual_items': 0.0003348094077992363, 'add_observations_from_episodes_to_batch': 0.000993537554954036}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.00017672005559074593, 'listify_data_for_vector_env': 2.5348648093123406e-05, 'get_actions': 0.00019650623895495388, 'remove_single_ts_time_rank_from_batch': 3.528444300484841e-06, 'module_to_agent_unmapping': 1.0455396731578e-05, 'un_batch_to_individual_items': 6.810523791347124e-05, 'tensor_to_numpy': 0.00016957267926214463}}, 'connector_pipeline_timer': 0.0008100463532848161}, 'module_episode_returns_mean': {'target': -0.6413998385965827, 'servicer': -176.25220591731966}, 'num_module_steps_sampled': {'servicer': 7500, 'target': 7500}, 'episode_return_max': -162.11612620060325, 'num_agent_steps_sampled_lifetime': {'target': 30000, 'servicer': 30000}, 'episode_return_min': -181.47534854547595, 'agent_episode_returns_mean': {'servicer': -176.25220591731966, 'target': -0.6413998385965827}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 6.59381050016509e-05, 'add_time_dim_to_batch_and_zero_pad': 2.3158237967051796e-05, 'agent_to_module_mapping': 1.1099556029704416e-05, 'add_states_from_episodes_to_batch': 1.4106399030625606e-05, 'add_observations_from_episodes_to_batch': 4.9536602102883144e-05, 'numpy_to_tensor': 0.00010369923970797039}}, 'connector_pipeline_timer': 0.0003903504793284554}, 'env_to_module_sum_episodes_length_in': 1401.0004172977287, 'num_agent_steps_sampled': {'servicer': 7500, 'target': 7500}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 4.1074214203073645, 'connector_pipeline_timer': 0.003229918574820232, 'env_step_timer': 0.00048463062161270743, 'sample': 20.811447632100187, 'num_episodes_lifetime': 20, 'rlmodule_inference_timer': 0.0005015086736822321, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'weights_seq_no': 39.0, 'num_episodes': 5, 'env_to_module_sum_episodes_length_out': 1401.0004172977287, 'num_env_steps_sampled_lifetime': 30000, 'env_reset_timer': 0.007760937718012752, 'num_env_steps_sampled_per_second': 328.41699728493205, 'time_between_sampling': 70.0588692536433}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 160000, 'fault_tolerance': {'num_healthy_workers': 15, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 732.1111559264446, 'done': False, 'training_iteration': 40, 'trial_id': 'default', 'date': '2025-04-22_14-41-18', 'timestamp': 1745347278, 'time_this_iter_s': 20.79437017440796, 'time_total_s': 312.08163118362427, 'pid': 58263, 'hostname': 'Nathans-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 15, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 4, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x15acc7d80>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 2e-06, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 312.08163118362427, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': 39.00333333333332, 'ram_util_percent': 70.81999999999998}}
2025-04-22 14:41:18,992 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/leo/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 5.654591463477846, 'restore_env_runners': 6.634977972828222e-05, 'training_step': 5.653954075433273, 'env_runner_sampling_timer': 1.8884118424914296, 'learner_update_timer': 3.7471942683598654, 'synch_weights': 0.01492477074093068, 'synch_env_connectors': 0.01566633582706906, 'restore_eval_env_runners': 1.205853340087924e-05, 'evaluation_iteration': 22.854499696782582, 'synch_eval_env_connectors': 0.31723523999399006}, 'env_runners': {'num_env_steps_sampled': 4000, 'num_module_steps_sampled_lifetime': {'target': 160000, 'servicer': 160000}, 'timers': {'connectors': {'numpy_to_tensor': 0.00020103947026655077, 'batch_individual_items': 0.00015657127369195223, 'add_time_dim_to_batch_and_zero_pad': 7.04334699548781e-05, 'agent_to_module_mapping': 3.158980204413334e-05, 'add_states_from_episodes_to_batch': 3.829686902463436e-05, 'add_observations_from_episodes_to_batch': 0.00012535152879233162}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.0003693580619036392, 'listify_data_for_vector_env': 4.941215008440156e-05, 'remove_single_ts_time_rank_from_batch': 8.918108245052331e-06, 'get_actions': 0.0009576432995962586, 'module_to_agent_unmapping': 2.2777376435726387e-05, 'un_batch_to_individual_items': 0.00017704012802820162, 'tensor_to_numpy': 0.00032377548972350464}}, 'connector_pipeline_timer': 0.002244692227340976}, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 160000, 'servicer': 160000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 0.00013487145918666341, 'add_time_dim_to_batch_and_zero_pad': 5.056541517856448e-05, 'agent_to_module_mapping': 2.6921535121639124e-05, 'add_states_from_episodes_to_batch': 3.4003549278958254e-05, 'add_observations_from_episodes_to_batch': 9.936336964112523e-05, 'numpy_to_tensor': 0.0002173188877526533}}, 'connector_pipeline_timer': 0.0008309092686560917}, 'env_to_module_sum_episodes_length_in': 167.4497341725226, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'connector_pipeline_timer': 0.001179325138218701, 'env_step_timer': 0.0009866252151641962, 'sample': 1.8127629970628436, 'rlmodule_inference_timer': 0.001131770110929951, 'weights_seq_no': 39.0, 'env_to_module_sum_episodes_length_out': 167.4497341725226, 'num_env_steps_sampled_lifetime': 160000, 'env_reset_timer': 0.0006519301251197855, 'time_between_sampling': 4.363136438746613, 'episode_return_mean': -165.50698354950586, 'module_episode_returns_mean': {'target': -2.1210160134931404, 'servicer': -163.3859675360127}, 'episode_return_max': -160.52807771116292, 'episode_return_min': -169.90680701452698, 'agent_episode_returns_mean': {'servicer': -163.3859675360127, 'target': -2.1210160134931404}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 9.490450580406469, 'num_episodes_lifetime': 105, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'num_episodes': 15, 'num_env_steps_sampled_lifetime_throughput': 732.1111559264446}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 1.7733578369018756e-05, 'general_advantage_estimation': 0.1299429770478446, 'add_observations_from_episodes_to_batch': 0.0008141275387586862, 'add_one_ts_to_episodes_and_truncate': 0.01478396972555439, 'numpy_to_tensor': 0.0003663117541563182, 'add_columns_from_episodes_to_train_batch': 0.261623643004474, 'batch_individual_items': 0.5019658187438456, 'add_time_dim_to_batch_and_zero_pad': 5.482379878446799e-05, 'agent_to_module_mapping': 0.013808654481274784}}, 'connector_pipeline_timer': 0.9239864809900575}, 'num_env_steps_trained': 504000, 'num_module_steps_trained_lifetime': 1290240, 'num_non_trainable_parameters': 0.0, 'num_module_steps_trained': 32256, 'num_env_steps_trained_lifetime': 20160000, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'curr_entropy_coeff': 2e-06, 'vf_loss': 6.693458271911368e-05, 'curr_kl_coeff': 0.01875000074505806, 'entropy': 5.588146686553955, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 6.693458271911368e-05, 'gradients_default_optimizer_global_norm': 1.355878233909607, 'num_trainable_parameters': 142093.0, 'policy_loss': 0.12056872993707657, 'mean_kl_loss': 0.009136169217526913, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.10506433248519897, 'module_train_batch_size_mean': 128.0, 'total_loss': 0.12079578638076782, 'weights_seq_no': 40.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 645120}, 'servicer': {'mean_kl_loss': 0.007429925724864006, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.04301893711090088, 'total_loss': 0.3426823019981384, 'weights_seq_no': 40.0, 'curr_kl_coeff': 0.003515625139698386, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 2e-06, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 645120, 'vf_loss': 0.4151480197906494, 'entropy': 7.57484245300293, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 0.4151480197906494, 'gradients_default_optimizer_global_norm': 0.71403568983078, 'num_trainable_parameters': 142093.0, 'policy_loss': -0.07247668504714966}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_env_steps_sampled': 7500, 'num_module_steps_sampled_lifetime': {'target': 30000, 'servicer': 30000}, 'episode_return_mean': -176.8936057559163, 'timers': {'connectors': {'numpy_to_tensor': 0.00016521522368566306, 'add_time_dim_to_batch_and_zero_pad': 0.000215318639166581, 'agent_to_module_mapping': 3.166221770053438e-05, 'add_states_from_episodes_to_batch': 4.7475780674810524e-05, 'batch_individual_items': 0.0003348094077992363, 'add_observations_from_episodes_to_batch': 0.000993537554954036}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.00017672005559074593, 'listify_data_for_vector_env': 2.5348648093123406e-05, 'get_actions': 0.00019650623895495388, 'remove_single_ts_time_rank_from_batch': 3.528444300484841e-06, 'module_to_agent_unmapping': 1.0455396731578e-05, 'un_batch_to_individual_items': 6.810523791347124e-05, 'tensor_to_numpy': 0.00016957267926214463}}, 'connector_pipeline_timer': 0.0008100463532848161}, 'module_episode_returns_mean': {'target': -0.6413998385965827, 'servicer': -176.25220591731966}, 'num_module_steps_sampled': {'servicer': 7500, 'target': 7500}, 'episode_return_max': -162.11612620060325, 'num_agent_steps_sampled_lifetime': {'target': 30000, 'servicer': 30000}, 'episode_return_min': -181.47534854547595, 'agent_episode_returns_mean': {'servicer': -176.25220591731966, 'target': -0.6413998385965827}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 6.59381050016509e-05, 'add_time_dim_to_batch_and_zero_pad': 2.3158237967051796e-05, 'agent_to_module_mapping': 1.1099556029704416e-05, 'add_states_from_episodes_to_batch': 1.4106399030625606e-05, 'add_observations_from_episodes_to_batch': 4.9536602102883144e-05, 'numpy_to_tensor': 0.00010369923970797039}}, 'connector_pipeline_timer': 0.0003903504793284554}, 'env_to_module_sum_episodes_length_in': 1401.0004172977287, 'num_agent_steps_sampled': {'servicer': 7500, 'target': 7500}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 4.1074214203073645, 'connector_pipeline_timer': 0.003229918574820232, 'env_step_timer': 0.00048463062161270743, 'sample': 20.811447632100187, 'num_episodes_lifetime': 20, 'rlmodule_inference_timer': 0.0005015086736822321, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'weights_seq_no': 39.0, 'num_episodes': 5, 'env_to_module_sum_episodes_length_out': 1401.0004172977287, 'num_env_steps_sampled_lifetime': 30000, 'env_reset_timer': 0.007760937718012752, 'num_env_steps_sampled_per_second': 328.41699728493205, 'time_between_sampling': 70.0588692536433}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 160000, 'fault_tolerance': {'num_healthy_workers': 15, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 732.1111559264446, 'done': False, 'training_iteration': 40, 'trial_id': 'default', 'date': '2025-04-22_14-41-18', 'timestamp': 1745347278, 'time_this_iter_s': 20.79437017440796, 'time_total_s': 312.08163118362427, 'pid': 58263, 'hostname': 'Nathans-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 15, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 4, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x15acc7d80>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 2e-06, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 312.08163118362427, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': 39.00333333333332, 'ram_util_percent': 70.81999999999998}})
2025-04-22 14:41:23,880 [__main__] [INFO] Iter: 41/100, Ts(iter): 0, Ts(total): 164000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 4.89s
2025-04-22 14:41:28,919 [__main__] [INFO] Iter: 42/100, Ts(iter): 0, Ts(total): 168000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.04s
2025-04-22 14:41:33,708 [__main__] [INFO] Iter: 43/100, Ts(iter): 0, Ts(total): 172000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 4.79s
2025-04-22 14:41:38,682 [__main__] [INFO] Iter: 44/100, Ts(iter): 0, Ts(total): 176000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 4.97s
2025-04-22 14:41:43,248 [__main__] [INFO] Iter: 45/100, Ts(iter): 0, Ts(total): 180000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 4.57s
2025-04-22 14:41:48,071 [__main__] [INFO] Iter: 46/100, Ts(iter): 0, Ts(total): 184000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 4.82s
2025-04-22 14:41:52,935 [__main__] [INFO] Iter: 47/100, Ts(iter): 0, Ts(total): 188000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 4.86s
2025-04-22 14:41:57,443 [__main__] [INFO] Iter: 48/100, Ts(iter): 0, Ts(total): 192000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 4.51s
2025-04-22 14:42:02,411 [__main__] [INFO] Iter: 49/100, Ts(iter): 0, Ts(total): 196000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 4.97s
2025-04-22 14:42:23,145 [__main__] [INFO] Iter: 50/100, Ts(iter): 0, Ts(total): 200000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 20.73s
2025-04-22 14:42:23,147 [__main__] [DEBUG] Full result dict at iter 50: {'timers': {'training_iteration': 5.5684294913338, 'restore_env_runners': 6.240851120284576e-05, 'training_step': 5.567806136974068, 'env_runner_sampling_timer': 1.8630956644574659, 'learner_update_timer': 3.686772732394557, 'synch_weights': 0.014496777238515498, 'synch_env_connectors': 0.01544787996766706, 'restore_eval_env_runners': 1.2048698037060676e-05, 'evaluation_iteration': 22.83373200247457, 'synch_eval_env_connectors': 0.31410190791386866}, 'env_runners': {'num_env_steps_sampled': 4000, 'num_module_steps_sampled_lifetime': {'target': 200000, 'servicer': 200000}, 'timers': {'connectors': {'numpy_to_tensor': 0.00020103947026655077, 'batch_individual_items': 0.00015657127369195223, 'add_time_dim_to_batch_and_zero_pad': 7.04334699548781e-05, 'agent_to_module_mapping': 3.158980204413334e-05, 'add_states_from_episodes_to_batch': 3.829686902463436e-05, 'add_observations_from_episodes_to_batch': 0.00012535152879233162}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.00033276523654315914, 'listify_data_for_vector_env': 4.46451735713436e-05, 'remove_single_ts_time_rank_from_batch': 7.085652573551002e-06, 'get_actions': 0.000870057038527269, 'module_to_agent_unmapping': 1.9166588355848022e-05, 'un_batch_to_individual_items': 0.0001423174759377196, 'tensor_to_numpy': 0.00029324159048644925}}, 'connector_pipeline_timer': 0.00201220861065904}, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 200000, 'servicer': 200000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 0.00012039505983177989, 'add_time_dim_to_batch_and_zero_pad': 4.5409716644851154e-05, 'agent_to_module_mapping': 2.2190079456998458e-05, 'add_states_from_episodes_to_batch': 3.113498968633872e-05, 'add_observations_from_episodes_to_batch': 9.035786531026271e-05, 'numpy_to_tensor': 0.00019477953130097746}}, 'connector_pipeline_timer': 0.0007457773924040867}, 'env_to_module_sum_episodes_length_in': 180.06750466619985, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'connector_pipeline_timer': 0.001179325138218701, 'env_step_timer': 0.000898959645633363, 'sample': 1.7978643003177692, 'rlmodule_inference_timer': 0.0010023458283568685, 'weights_seq_no': 49.0, 'env_to_module_sum_episodes_length_out': 180.06750466619985, 'num_env_steps_sampled_lifetime': 200000, 'env_reset_timer': 0.0006519301251197855, 'time_between_sampling': 4.429093768678572, 'episode_return_mean': -166.84037560848265, 'module_episode_returns_mean': {'target': -2.0127095462918287, 'servicer': -164.82766606219084}, 'episode_return_max': -162.74627799484614, 'episode_return_min': -171.33608318014416, 'agent_episode_returns_mean': {'servicer': -164.82766606219084, 'target': -2.0127095462918287}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 8.665380429138894, 'num_episodes_lifetime': 120, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 787.6356717537495}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 1.7733413192960656e-05, 'general_advantage_estimation': 0.12764926562544485, 'add_observations_from_episodes_to_batch': 0.000815743288365675, 'add_one_ts_to_episodes_and_truncate': 0.014873651974052035, 'numpy_to_tensor': 0.0003683554828444643, 'add_columns_from_episodes_to_train_batch': 0.26272973562037016, 'batch_individual_items': 0.49726967186377835, 'add_time_dim_to_batch_and_zero_pad': 5.5730542943344225e-05, 'agent_to_module_mapping': 0.01390330532600001}}, 'connector_pipeline_timer': 0.9182863399755151}, 'num_env_steps_trained': 504000, 'num_module_steps_trained_lifetime': 1612800, 'num_non_trainable_parameters': 0.0, 'num_module_steps_trained': 32256, 'num_env_steps_trained_lifetime': 25200000, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'curr_entropy_coeff': 2e-06, 'vf_loss': 2.5485087462584488e-05, 'curr_kl_coeff': 0.00937500037252903, 'entropy': 4.543538570404053, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 2.5485087462584488e-05, 'gradients_default_optimizer_global_norm': 1.3194867372512817, 'num_trainable_parameters': 142093.0, 'policy_loss': 0.07595904916524887, 'mean_kl_loss': 0.005364384967833757, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.15637469291687012, 'module_train_batch_size_mean': 128.0, 'total_loss': 0.07602574676275253, 'weights_seq_no': 50.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 806400}, 'servicer': {'mean_kl_loss': 0.0029985932633280754, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.2908976674079895, 'total_loss': 0.2379753291606903, 'weights_seq_no': 50.0, 'curr_kl_coeff': 0.0008789062849245965, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 2e-06, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 806400, 'vf_loss': 0.208527073264122, 'entropy': 7.357682228088379, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 0.208527073264122, 'gradients_default_optimizer_global_norm': 1.3420299291610718, 'num_trainable_parameters': 142093.0, 'policy_loss': 0.02945766970515251}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_env_steps_sampled': 7500, 'num_module_steps_sampled_lifetime': {'target': 37500, 'servicer': 37500}, 'episode_return_mean': -175.58627979044635, 'timers': {'connectors': {'numpy_to_tensor': 0.0001652283218288961, 'add_time_dim_to_batch_and_zero_pad': 0.00021527177565451092, 'agent_to_module_mapping': 3.165763696914149e-05, 'add_states_from_episodes_to_batch': 4.746999348722552e-05, 'batch_individual_items': 0.0003347422249456573, 'add_observations_from_episodes_to_batch': 0.0009932234130275088}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.00017648382448176935, 'listify_data_for_vector_env': 2.5311454969546696e-05, 'get_actions': 0.00019618084474495442, 'remove_single_ts_time_rank_from_batch': 3.523606052340858e-06, 'module_to_agent_unmapping': 1.0443884328013115e-05, 'un_batch_to_individual_items': 6.805061891115472e-05, 'tensor_to_numpy': 0.00016923849094446417}}, 'connector_pipeline_timer': 0.0008088570091465823}, 'module_episode_returns_mean': {'target': -0.6286751307745776, 'servicer': -174.95760465967174}, 'num_module_steps_sampled': {'servicer': 7500, 'target': 7500}, 'episode_return_max': -162.11612620060325, 'num_agent_steps_sampled_lifetime': {'target': 37500, 'servicer': 37500}, 'episode_return_min': -181.47534854547595, 'agent_episode_returns_mean': {'servicer': -174.95760465967174, 'target': -0.6286751307745776}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 6.583915121418594e-05, 'add_time_dim_to_batch_and_zero_pad': 2.3119662072930307e-05, 'agent_to_module_mapping': 1.1085782542240242e-05, 'add_states_from_episodes_to_batch': 1.409114392748592e-05, 'add_observations_from_episodes_to_batch': 4.9468929580832e-05, 'numpy_to_tensor': 0.00010434189300134165}}, 'connector_pipeline_timer': 0.00039062596298357674}, 'env_to_module_sum_episodes_length_in': 1401.0004172977287, 'num_agent_steps_sampled': {'servicer': 7500, 'target': 7500}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 4.069127239659428, 'connector_pipeline_timer': 0.0032291063277477164, 'env_step_timer': 0.00048366978718766574, 'sample': 20.81134135088809, 'num_episodes_lifetime': 25, 'rlmodule_inference_timer': 0.0005005436437690473, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'weights_seq_no': 49.0, 'num_episodes': 5, 'env_to_module_sum_episodes_length_out': 1401.0004172977287, 'num_env_steps_sampled_lifetime': 37500, 'env_reset_timer': 0.00775835049922281, 'num_env_steps_sampled_per_second': 328.41744149568933, 'time_between_sampling': 70.05284993714216}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 200000, 'fault_tolerance': {'num_healthy_workers': 15, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 787.6356717537495, 'done': False, 'training_iteration': 50, 'trial_id': 'default', 'date': '2025-04-22_14-42-23', 'timestamp': 1745347343, 'time_this_iter_s': 20.687366008758545, 'time_total_s': 375.63424587249756, 'pid': 58263, 'hostname': 'Nathans-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 15, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 4, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x15acc7d80>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 2e-06, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 375.63424587249756, 'iterations_since_restore': 50, 'perf': {'cpu_util_percent': 37.834482758620695, 'ram_util_percent': 75.40689655172415}}
2025-04-22 14:42:27,857 [__main__] [INFO] Iter: 51/100, Ts(iter): 0, Ts(total): 204000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 4.71s
2025-04-22 14:42:33,032 [__main__] [INFO] Iter: 52/100, Ts(iter): 0, Ts(total): 208000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 5.17s
2025-04-22 14:42:34,608 [__main__] [WARNING] Training interrupted.
2025-04-22 14:42:34,610 [__main__] [INFO] 
--- Training Finished ---
2025-04-22 14:42:34,610 [__main__] [INFO] Total Training Time: 390.69 seconds
2025-04-22 14:42:34,685 [__main__] [INFO] Final checkpoint saved: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/leo/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 5.554124641735499, 'restore_env_runners': 6.157303547779274e-05, 'training_step': 5.553504856406604, 'env_runner_sampling_timer': 1.8605067315011667, 'learner_update_timer': 3.6751523145356075, 'synch_weights': 0.014391825361310857, 'synch_env_connectors': 0.015392814860985536, 'restore_eval_env_runners': 1.2048698037060676e-05, 'evaluation_iteration': 22.812062258319767, 'synch_eval_env_connectors': 0.31410190791386866}, 'env_runners': {'num_env_steps_sampled': 4000, 'num_module_steps_sampled_lifetime': {'target': 208000, 'servicer': 208000}, 'timers': {'connectors': {'numpy_to_tensor': 0.00020103947026655077, 'batch_individual_items': 0.00015657127369195223, 'add_time_dim_to_batch_and_zero_pad': 7.04334699548781e-05, 'agent_to_module_mapping': 3.158980204413334e-05, 'add_states_from_episodes_to_batch': 3.829686902463436e-05, 'add_observations_from_episodes_to_batch': 0.00012535152879233162}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.00034065073365351534, 'listify_data_for_vector_env': 4.6067979769582446e-05, 'remove_single_ts_time_rank_from_batch': 6.956535108080546e-06, 'get_actions': 0.0009000167293023936, 'module_to_agent_unmapping': 1.914349690645984e-05, 'un_batch_to_individual_items': 0.00014422704114609337, 'tensor_to_numpy': 0.00030501636684431986}}, 'connector_pipeline_timer': 0.0020689749571169997}, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 208000, 'servicer': 208000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 0.00012353088252532474, 'add_time_dim_to_batch_and_zero_pad': 5.139221863852019e-05, 'agent_to_module_mapping': 2.2836502690026882e-05, 'add_states_from_episodes_to_batch': 3.2487453802668826e-05, 'add_observations_from_episodes_to_batch': 9.138824033932509e-05, 'numpy_to_tensor': 0.00019922814277440484}}, 'connector_pipeline_timer': 0.0007695353923678234}, 'env_to_module_sum_episodes_length_in': 168.6169844635782, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'connector_pipeline_timer': 0.001179325138218701, 'env_step_timer': 0.0009227244034460088, 'sample': 1.7934673818502807, 'rlmodule_inference_timer': 0.0010503780559514117, 'weights_seq_no': 51.0, 'env_to_module_sum_episodes_length_out': 168.6169844635782, 'num_env_steps_sampled_lifetime': 208000, 'env_reset_timer': 0.0006519301251197855, 'time_between_sampling': 4.460704544025938, 'episode_return_mean': -168.82361584820728, 'module_episode_returns_mean': {'target': -1.8925206680258115, 'servicer': -166.93109518018147}, 'episode_return_max': -166.42724059205753, 'episode_return_min': -171.95176331903468, 'agent_episode_returns_mean': {'servicer': -166.93109518018147, 'target': -1.8925206680258115}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 8.316219551609054, 'num_episodes_lifetime': 135, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 773.0526533877903}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 1.7728925889921973e-05, 'general_advantage_estimation': 0.12715478224164592, 'add_observations_from_episodes_to_batch': 0.0008159105868120589, 'add_one_ts_to_episodes_and_truncate': 0.014891665656684625, 'numpy_to_tensor': 0.0003686586902040469, 'add_columns_from_episodes_to_train_batch': 0.2629300934935216, 'batch_individual_items': 0.4961992803663076, 'add_time_dim_to_batch_and_zero_pad': 5.586438775447079e-05, 'agent_to_module_mapping': 0.013918881567522105}}, 'connector_pipeline_timer': 0.916954762547717}, 'num_env_steps_trained': 504000, 'num_module_steps_trained_lifetime': 1677312, 'num_non_trainable_parameters': 0.0, 'num_module_steps_trained': 32256, 'num_env_steps_trained_lifetime': 26208000, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'curr_entropy_coeff': 2e-06, 'vf_loss': 3.162965367664583e-05, 'curr_kl_coeff': 0.00937500037252903, 'entropy': 4.343950271606445, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 3.162965367664583e-05, 'gradients_default_optimizer_global_norm': 1.7931195497512817, 'num_trainable_parameters': 142093.0, 'policy_loss': 0.07339342683553696, 'mean_kl_loss': 0.014468921348452568, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.04371905326843262, 'module_train_batch_size_mean': 128.0, 'total_loss': 0.07355202734470367, 'weights_seq_no': 52.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 838656}, 'servicer': {'mean_kl_loss': 0.010035415180027485, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': 0.002779662609100342, 'total_loss': 0.273965984582901, 'weights_seq_no': 52.0, 'curr_kl_coeff': 0.0008789062849245965, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 2e-06, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_module_steps_trained_lifetime': 838656, 'vf_loss': 0.24644982814788818, 'entropy': 7.191325664520264, 'num_module_steps_trained': 16128, 'vf_loss_unclipped': 0.24644982814788818, 'gradients_default_optimizer_global_norm': 1.10352623462677, 'num_trainable_parameters': 142093.0, 'policy_loss': 0.02752172201871872}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_env_steps_sampled': 0, 'num_module_steps_sampled_lifetime': {'target': 37500, 'servicer': 37500}, 'episode_return_mean': -175.58627979044635, 'timers': {'connectors': {'numpy_to_tensor': 0.0001652283218288961, 'add_time_dim_to_batch_and_zero_pad': 0.00021527177565451092, 'agent_to_module_mapping': 3.165763696914149e-05, 'add_states_from_episodes_to_batch': 4.746999348722552e-05, 'batch_individual_items': 0.0003347422249456573, 'add_observations_from_episodes_to_batch': 0.0009932234130275088}}, 'module_to_env_connector': {'timers': {'connectors': {'normalize_and_clip_actions': 0.00017648382448176935, 'listify_data_for_vector_env': 2.5311454969546696e-05, 'get_actions': 0.00019618084474495442, 'remove_single_ts_time_rank_from_batch': 3.523606052340858e-06, 'module_to_agent_unmapping': 1.0443884328013115e-05, 'un_batch_to_individual_items': 6.805061891115472e-05, 'tensor_to_numpy': 0.00016923849094446417}}, 'connector_pipeline_timer': 0.0008088570091465823}, 'module_episode_returns_mean': {'target': -0.6286751307745776, 'servicer': -174.95760465967174}, 'num_module_steps_sampled': {'servicer': 0, 'target': 0}, 'episode_return_max': -162.11612620060325, 'num_agent_steps_sampled_lifetime': {'target': 37500, 'servicer': 37500}, 'episode_return_min': -181.47534854547595, 'agent_episode_returns_mean': {'servicer': -174.95760465967174, 'target': -0.6286751307745776}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 6.583915121418594e-05, 'add_time_dim_to_batch_and_zero_pad': 2.3119662072930307e-05, 'agent_to_module_mapping': 1.1085782542240242e-05, 'add_states_from_episodes_to_batch': 1.409114392748592e-05, 'add_observations_from_episodes_to_batch': 4.9468929580832e-05, 'numpy_to_tensor': 0.00010434189300134165}}, 'connector_pipeline_timer': 0.00039062596298357674}, 'env_to_module_sum_episodes_length_in': 1401.0004172977287, 'num_agent_steps_sampled': {'servicer': 0, 'target': 0}, 'agent_steps': {'target': 1500.0, 'servicer': 1500.0}, 'episode_len_max': 1500, 'episode_duration_sec_mean': 4.069127239659428, 'connector_pipeline_timer': 0.0032291063277477164, 'env_step_timer': 0.00048366978718766574, 'sample': 20.81134135088809, 'num_episodes_lifetime': 25, 'rlmodule_inference_timer': 0.0005005436437690473, 'episode_len_min': 1500, 'episode_len_mean': 1500.0, 'weights_seq_no': 49.0, 'num_episodes': 0, 'env_to_module_sum_episodes_length_out': 1401.0004172977287, 'num_env_steps_sampled_lifetime': 37500, 'env_reset_timer': 0.00775835049922281, 'num_env_steps_sampled_per_second': 328.42100140087905, 'time_between_sampling': 70.05284993714216, 'num_env_steps_sampled_lifetime_throughput': 0.0}}, 'num_env_steps_sampled_lifetime': 208000, 'fault_tolerance': {'num_healthy_workers': 15, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 773.0526533877903, 'done': False, 'training_iteration': 52, 'trial_id': 'default', 'date': '2025-04-22_14-42-32', 'timestamp': 1745347352, 'time_this_iter_s': 5.114392042160034, 'time_total_s': 385.39893198013306, 'pid': 58263, 'hostname': 'Nathans-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 15, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 4, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x15acc7d80>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 2e-06, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 385.39893198013306, 'iterations_since_restore': 52, 'perf': {'cpu_util_percent': 72.51428571428572, 'ram_util_percent': 76.35714285714286}})
2025-04-22 14:42:34,687 [__main__] [INFO] 
--- Running Evaluation & Recording Video ---
2025-04-22 14:42:34,695 [__main__] [INFO] Successfully retrieved RLModules for evaluation.
2025-04-22 14:42:34,695 [__main__] [INFO] Evaluation Episode: 1/5
2025-04-22 14:42:36,090 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-22 14:42:36,100 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
