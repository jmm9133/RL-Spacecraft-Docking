2025-04-03 19:52:05,271 [__main__] [INFO] Initializing Ray...
2025-04-03 19:52:10,735 [__main__] [INFO] Creating temporary environment to get action/observation spaces...
2025-04-03 19:52:10,737 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 19:52:10,737 [__main__] [INFO] Spaces retrieved.
2025-04-03 19:52:10,737 [__main__] [INFO] Configuring RLlib PPO Algorithm...
2025-04-03 19:52:10,738 [__main__] [INFO] Building Algorithm...
2025-04-03 19:52:24,462 [__main__] [WARNING] Could not retrieve policy class name via standard methods.
2025-04-03 19:52:24,462 [__main__] [INFO] Algorithm Built. Using Policy Class: Unavailable (New API stack?)
2025-04-03 19:52:24,462 [__main__] [INFO] 
--- Starting Training for 100 iterations ---
2025-04-03 19:52:26,947 [__main__] [INFO] Iteration: 1/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.48s
2025-04-03 19:52:29,054 [__main__] [INFO] Iteration: 2/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.11s
2025-04-03 19:52:30,973 [__main__] [INFO] Iteration: 3/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 1.92s
2025-04-03 19:52:33,302 [__main__] [INFO] Iteration: 4/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.33s
2025-04-03 19:52:35,462 [__main__] [INFO] Iteration: 5/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.16s
2025-04-03 19:52:37,683 [__main__] [INFO] Iteration: 6/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.22s
2025-04-03 19:52:40,079 [__main__] [INFO] Iteration: 7/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.40s
2025-04-03 19:52:42,388 [__main__] [INFO] Iteration: 8/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.31s
2025-04-03 19:52:44,420 [__main__] [INFO] Iteration: 9/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.03s
2025-04-03 19:52:47,870 [__main__] [INFO] Iteration: 10/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 3.45s
2025-04-03 19:52:50,042 [__main__] [INFO] Iteration: 11/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.17s
2025-04-03 19:52:52,296 [__main__] [INFO] Iteration: 12/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.25s
2025-04-03 19:52:54,548 [__main__] [INFO] Iteration: 13/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.25s
2025-04-03 19:52:56,877 [__main__] [INFO] Iteration: 14/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.33s
2025-04-03 19:52:59,323 [__main__] [INFO] Iteration: 15/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.45s
2025-04-03 19:53:01,457 [__main__] [INFO] Iteration: 16/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.13s
2025-04-03 19:53:03,674 [__main__] [INFO] Iteration: 17/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.22s
2025-04-03 19:53:05,962 [__main__] [INFO] Iteration: 18/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.29s
2025-04-03 19:53:08,415 [__main__] [INFO] Iteration: 19/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.45s
2025-04-03 19:53:11,566 [__main__] [INFO] Iteration: 20/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 3.15s
2025-04-03 19:53:11,584 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.443946539071994, 'restore_env_runners': 1.6102541614594122e-05, 'training_step': 2.4438262813613014, 'env_runner_sampling_timer': 0.3231000089701637, 'learner_update_timer': 2.1141878830452296, 'synch_weights': 0.005237878475035624, 'synch_env_connectors': 0.007548166001067589, 'restore_eval_env_runners': 7.315921102417632e-06, 'evaluation_iteration': 2.8458268655100256, 'synch_eval_env_connectors': 0.00341841841902351}, 'env_runners': {'timers': {'connectors': {'agent_to_module_mapping': 6.623129593208432e-06, 'add_observations_from_episodes_to_batch': 4.0364173321944215e-05, 'add_time_dim_to_batch_and_zero_pad': 1.9498043516448334e-05, 'numpy_to_tensor': 5.5485477787442505e-05, 'add_states_from_episodes_to_batch': 7.369434688766689e-06, 'batch_individual_items': 3.549282732622131e-05}}, 'env_reset_timer': 0.00014764673845923465, 'env_to_module_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 4.140008966124707e-06, 'batch_individual_items': 1.932543218716246e-05, 'agent_to_module_mapping': 4.949759539031847e-06, 'add_observations_from_episodes_to_batch': 1.7203491363829153e-05, 'add_time_dim_to_batch_and_zero_pad': 7.391425582657937e-06, 'numpy_to_tensor': 3.4357005036409586e-05}}, 'connector_pipeline_timer': 0.0001275321517408638}, 'env_to_module_sum_episodes_length_in': 103.42885547936852, 'num_module_steps_sampled_lifetime': {'target': 80000, 'servicer': 80000}, 'num_agent_steps_sampled': {'target': 4000, 'servicer': 4000}, 'sample': 0.18936383222608322, 'num_agent_steps_sampled_lifetime': {'target': 80000, 'servicer': 80000}, 'weights_seq_no': 19.0, 'num_module_steps_sampled': {'target': 4000, 'servicer': 4000}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 1.0322777225821253e-05, 'module_to_agent_unmapping': 4.697303247925805e-06, 'tensor_to_numpy': 5.2607060540564376e-05, 'get_actions': 0.00015052918757560652, 'normalize_and_clip_actions': 5.807278847857387e-05, 'remove_single_ts_time_rank_from_batch': 1.390136329256307e-06, 'un_batch_to_individual_items': 2.2913470458997723e-05}}, 'connector_pipeline_timer': 0.0003483004120944107}, 'env_step_timer': 0.00011425213573182253, 'num_env_steps_sampled': 4000, 'connector_pipeline_timer': 0.00030690756482173407, 'num_env_steps_sampled_lifetime': 80000, 'rlmodule_inference_timer': 0.00016512002559784087, 'env_to_module_sum_episodes_length_out': 103.42885547936852, 'time_between_sampling': 2.2722260754298587, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_return_max': -1052.8520807622074, 'module_episode_returns_mean': {'target': 0.0, 'servicer': -1062.466387930077}, 'episode_duration_sec_mean': 0.9321696664777372, 'agent_episode_returns_mean': {'target': 0.0, 'servicer': -1062.466387930077}, 'episode_len_max': 1000, 'episode_return_min': -1072.7643624307743, 'episode_return_mean': -1062.466387930077, 'episode_len_min': 1000, 'num_episodes_lifetime': 69, 'episode_len_mean': 1000.0, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 1268.2211004754363}, 'learners': {'servicer': {'gradients_default_optimizer_global_norm': 1.0842974185943604, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 142093.0, 'total_loss': 9.657388687133789, 'mean_kl_loss': 0.006151366513222456, 'num_module_steps_trained_lifetime': 807168, 'default_optimizer_learning_rate': 5e-05, 'vf_explained_var': 7.295608520507812e-05, 'num_module_steps_trained': 40320, 'weights_seq_no': 20.0, 'vf_loss': 9.705241203308105, 'curr_kl_coeff': 4.882812572759576e-05, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'policy_loss': 0.035706959664821625, 'module_train_batch_size_mean': 128.0, 'entropy': 8.355887413024902, 'vf_loss_unclipped': 3525.8017578125}, 'target': {'vf_loss_unclipped': 4.439526435362495e-07, 'gradients_default_optimizer_global_norm': 0.9586474299430847, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.004511065315455198, 'total_loss': 0.006974691525101662, 'num_module_steps_trained_lifetime': 807168, 'default_optimizer_learning_rate': 5e-05, 'vf_explained_var': 0.995186448097229, 'num_module_steps_trained': 40320, 'weights_seq_no': 20.0, 'vf_loss': 4.439526435362495e-07, 'curr_kl_coeff': 9.765625145519152e-05, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'policy_loss': 0.09867408871650696, 'module_train_batch_size_mean': 128.0, 'entropy': 9.170072555541992}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.053233188931224244, 'add_time_dim_to_batch_and_zero_pad': 2.2864649858174722e-05, 'numpy_to_tensor': 0.00020851641102944058, 'add_states_from_episodes_to_batch': 5.234244526639932e-06, 'batch_individual_items': 0.0644151225990358, 'add_one_ts_to_episodes_and_truncate': 0.0056428077748049334, 'add_columns_from_episodes_to_train_batch': 0.0691527347702277, 'agent_to_module_mapping': 0.0033993262697405886, 'add_observations_from_episodes_to_batch': 0.00026617446261950113}}, 'connector_pipeline_timer': 0.19658539273759332}, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained_lifetime': 1614336, 'num_module_steps_trained': 80640, 'num_env_steps_trained_lifetime': 25224000, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'timers': {'connectors': {'agent_to_module_mapping': 5.374976372695528e-06, 'add_observations_from_episodes_to_batch': 3.5790777909278403e-05, 'add_time_dim_to_batch_and_zero_pad': 2.253981649846537e-05, 'numpy_to_tensor': 3.641772846895037e-05, 'add_states_from_episodes_to_batch': 7.499611400999129e-06, 'batch_individual_items': 2.7082414388132748e-05}}, 'env_reset_timer': 0.00016990955568908247, 'env_to_module_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 2.892919291421982e-06, 'batch_individual_items': 1.1870332088427105e-05, 'agent_to_module_mapping': 2.9161214384939155e-06, 'add_observations_from_episodes_to_batch': 1.1336396674483301e-05, 'add_time_dim_to_batch_and_zero_pad': 4.3130596261959265e-06, 'numpy_to_tensor': 2.0251714660574547e-05}}, 'connector_pipeline_timer': 7.868219459442464e-05}, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'num_module_steps_sampled_lifetime': {'target': 10000, 'servicer': 10000}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'num_agent_steps_sampled': {'target': 5000, 'servicer': 5000}, 'episode_return_max': -1075.574520532978, 'sample': 2.6857282252852572, 'num_agent_steps_sampled_lifetime': {'target': 10000, 'servicer': 10000}, 'module_episode_returns_mean': {'target': 0.0, 'servicer': -1075.7542849536678}, 'episode_duration_sec_mean': 0.522265719329395, 'weights_seq_no': 19.0, 'agent_episode_returns_mean': {'target': 0.0, 'servicer': -1075.7542849536678}, 'episode_len_max': 1000, 'num_module_steps_sampled': {'target': 5000, 'servicer': 5000}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 6.78782319844459e-06, 'module_to_agent_unmapping': 2.469858449196053e-06, 'tensor_to_numpy': 3.459103863773077e-05, 'get_actions': 3.537883751468424e-05, 'normalize_and_clip_actions': 3.5073934218927737e-05, 'remove_single_ts_time_rank_from_batch': 8.230930767912253e-07, 'un_batch_to_individual_items': 1.4284304916947893e-05}}, 'connector_pipeline_timer': 0.00016013095729057605}, 'env_step_timer': 6.799204435874784e-05, 'episode_return_min': -1075.8441671640126, 'num_env_steps_sampled': 5000, 'episode_return_mean': -1075.7542849536678, 'episode_len_min': 1000, 'connector_pipeline_timer': 0.0002504895970298094, 'num_env_steps_sampled_lifetime': 10000, 'num_episodes_lifetime': 10, 'episode_len_mean': 1000.0, 'num_episodes': 5, 'rlmodule_inference_timer': 0.00011127897617337784, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'num_env_steps_sampled_per_second': 1757.272850974008, 'time_between_sampling': 21.31688258399663}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 80000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1268.2211004754363, 'done': False, 'training_iteration': 20, 'trial_id': 'default', 'date': '2025-04-03_19-53-11', 'timestamp': 1743724391, 'time_this_iter_s': 3.1342320442199707, 'time_total_s': 46.85551977157593, 'pid': 71851, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35f1318a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 46.85551977157593, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 77.025, 'ram_util_percent': 55.6}})
2025-04-03 19:53:14,023 [__main__] [INFO] Iteration: 21/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.44s
2025-04-03 19:53:16,039 [__main__] [INFO] Iteration: 22/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.02s
2025-04-03 19:53:17,970 [__main__] [INFO] Iteration: 23/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 1.93s
2025-04-03 19:53:20,155 [__main__] [INFO] Iteration: 24/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.19s
2025-04-03 19:53:22,200 [__main__] [INFO] Iteration: 25/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.04s
2025-04-03 19:53:24,044 [__main__] [INFO] Iteration: 26/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 1.84s
2025-04-03 19:53:26,269 [__main__] [INFO] Iteration: 27/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.22s
2025-04-03 19:53:28,327 [__main__] [INFO] Iteration: 28/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.06s
2025-04-03 19:53:30,687 [__main__] [INFO] Iteration: 29/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.36s
2025-04-03 19:53:33,891 [__main__] [INFO] Iteration: 30/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 3.20s
2025-04-03 19:53:36,301 [__main__] [INFO] Iteration: 31/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.41s
2025-04-03 19:53:38,441 [__main__] [INFO] Iteration: 32/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.14s
2025-04-03 19:53:40,674 [__main__] [INFO] Iteration: 33/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.23s
2025-04-03 19:53:42,824 [__main__] [INFO] Iteration: 34/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.15s
2025-04-03 19:53:45,198 [__main__] [INFO] Iteration: 35/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.37s
2025-04-03 19:53:47,764 [__main__] [INFO] Iteration: 36/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.57s
2025-04-03 19:53:50,046 [__main__] [INFO] Iteration: 37/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.28s
2025-04-03 19:53:52,384 [__main__] [INFO] Iteration: 38/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.34s
2025-04-03 19:53:54,813 [__main__] [INFO] Iteration: 39/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.43s
2025-04-03 19:53:58,033 [__main__] [INFO] Iteration: 40/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 3.22s
2025-04-03 19:53:58,050 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.419183577695858, 'restore_env_runners': 1.4602747637351573e-05, 'training_step': 2.419062816745607, 'env_runner_sampling_timer': 0.30085445554983914, 'learner_update_timer': 2.111728752952085, 'synch_weights': 0.0050994506050864455, 'synch_env_connectors': 0.0074269080426125735, 'restore_eval_env_runners': 7.3052567099075515e-06, 'evaluation_iteration': 2.8462618114063925, 'synch_eval_env_connectors': 0.00337887511885786}, 'env_runners': {'timers': {'connectors': {'agent_to_module_mapping': 6.623129593208432e-06, 'add_observations_from_episodes_to_batch': 4.0364173321944215e-05, 'add_time_dim_to_batch_and_zero_pad': 1.9498043516448334e-05, 'numpy_to_tensor': 5.5485477787442505e-05, 'add_states_from_episodes_to_batch': 7.369434688766689e-06, 'batch_individual_items': 3.549282732622131e-05}}, 'env_reset_timer': 0.00014764673845923465, 'env_to_module_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 4.003856239109881e-06, 'batch_individual_items': 1.746911136151995e-05, 'agent_to_module_mapping': 4.1505813195534e-06, 'add_observations_from_episodes_to_batch': 1.5734022133669147e-05, 'add_time_dim_to_batch_and_zero_pad': 6.1713670518944735e-06, 'numpy_to_tensor': 2.8549862607016667e-05}}, 'connector_pipeline_timer': 0.00011136445264126038}, 'env_to_module_sum_episodes_length_in': 106.27241732416265, 'num_module_steps_sampled_lifetime': {'target': 160000, 'servicer': 160000}, 'num_agent_steps_sampled': {'target': 4000, 'servicer': 4000}, 'sample': 0.18250204887638372, 'num_agent_steps_sampled_lifetime': {'target': 160000, 'servicer': 160000}, 'weights_seq_no': 39.0, 'num_module_steps_sampled': {'target': 4000, 'servicer': 4000}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 9.195681806333035e-06, 'module_to_agent_unmapping': 3.542957143746354e-06, 'tensor_to_numpy': 4.732003593404871e-05, 'get_actions': 0.00012704308308799362, 'normalize_and_clip_actions': 5.190117966918049e-05, 'remove_single_ts_time_rank_from_batch': 1.1608616684990155e-06, 'un_batch_to_individual_items': 2.1163994057906916e-05}}, 'connector_pipeline_timer': 0.0003055346249158136}, 'env_step_timer': 9.996802258388659e-05, 'num_env_steps_sampled': 4000, 'connector_pipeline_timer': 0.00030690756482173407, 'num_env_steps_sampled_lifetime': 160000, 'rlmodule_inference_timer': 0.00014316163895754187, 'env_to_module_sum_episodes_length_out': 106.27241732416265, 'time_between_sampling': 2.252151454636339, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_return_max': -1068.34354167321, 'module_episode_returns_mean': {'target': 0.0, 'servicer': -1082.7140313177442}, 'episode_duration_sec_mean': 0.819929691960367, 'agent_episode_returns_mean': {'target': 0.0, 'servicer': -1082.7140313177442}, 'episode_len_max': 1000, 'episode_return_min': -1096.233640630816, 'episode_return_mean': -1082.7140313177442, 'episode_len_min': 1000, 'num_episodes_lifetime': 138, 'episode_len_mean': 1000.0, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 1240.8510339372067}, 'learners': {'servicer': {'gradients_default_optimizer_global_norm': 1.478651762008667, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 142093.0, 'total_loss': 9.656707763671875, 'mean_kl_loss': 0.003472736105322838, 'num_module_steps_trained_lifetime': 1614208, 'default_optimizer_learning_rate': 5e-05, 'vf_explained_var': -0.0006071329116821289, 'num_module_steps_trained': 40320, 'weights_seq_no': 40.0, 'vf_loss': 9.651410102844238, 'curr_kl_coeff': 1.1920929132713809e-08, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'policy_loss': 0.09225859493017197, 'module_train_batch_size_mean': 128.0, 'entropy': 8.696166038513184, 'vf_loss_unclipped': 3957.78564453125}, 'target': {'vf_loss_unclipped': 3.8695361581631005e-08, 'gradients_default_optimizer_global_norm': 0.39429736137390137, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.005160345695912838, 'total_loss': -0.07373537123203278, 'num_module_steps_trained_lifetime': 1614208, 'default_optimizer_learning_rate': 5e-05, 'vf_explained_var': 0.9983515739440918, 'num_module_steps_trained': 40320, 'weights_seq_no': 40.0, 'vf_loss': 3.8695361581631005e-08, 'curr_kl_coeff': 7.629394644936838e-07, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'policy_loss': 0.03545407950878143, 'module_train_batch_size_mean': 128.0, 'entropy': 10.91894817352295}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.05148802518498479, 'add_time_dim_to_batch_and_zero_pad': 2.2461949270646895e-05, 'numpy_to_tensor': 0.00020510400567364076, 'add_states_from_episodes_to_batch': 5.187285344096201e-06, 'batch_individual_items': 0.06532364946774455, 'add_one_ts_to_episodes_and_truncate': 0.005613744021967671, 'add_columns_from_episodes_to_train_batch': 0.06923702281864497, 'agent_to_module_mapping': 0.0034104935678546714, 'add_observations_from_episodes_to_batch': 0.0002659905831272195}}, 'connector_pipeline_timer': 0.19580525127832896}, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained_lifetime': 3228416, 'num_module_steps_trained': 80640, 'num_env_steps_trained_lifetime': 50444000, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'timers': {'connectors': {'agent_to_module_mapping': 5.374629508167563e-06, 'add_observations_from_episodes_to_batch': 3.578455761955367e-05, 'add_time_dim_to_batch_and_zero_pad': 2.2533745232804357e-05, 'numpy_to_tensor': 3.6419501816174157e-05, 'add_states_from_episodes_to_batch': 7.497676099641248e-06, 'batch_individual_items': 2.7079341783299605e-05}}, 'env_reset_timer': 0.00016987858345563026, 'env_to_module_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 2.8931455818796195e-06, 'batch_individual_items': 1.1863442412929411e-05, 'agent_to_module_mapping': 2.913484574017135e-06, 'add_observations_from_episodes_to_batch': 1.1322384743671222e-05, 'add_time_dim_to_batch_and_zero_pad': 4.31061992434689e-06, 'numpy_to_tensor': 2.0207531631755282e-05}}, 'connector_pipeline_timer': 7.860615045485574e-05}, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'num_module_steps_sampled_lifetime': {'target': 20000, 'servicer': 20000}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'num_agent_steps_sampled': {'target': 5000, 'servicer': 5000}, 'episode_return_max': -1075.574520532978, 'sample': 2.68574044895965, 'num_agent_steps_sampled_lifetime': {'target': 20000, 'servicer': 20000}, 'module_episode_returns_mean': {'target': 0.0, 'servicer': -1084.9867069566767}, 'episode_duration_sec_mean': 0.5230864448565989, 'weights_seq_no': 39.0, 'agent_episode_returns_mean': {'target': 0.0, 'servicer': -1084.9867069566767}, 'episode_len_max': 1000, 'num_module_steps_sampled': {'target': 5000, 'servicer': 5000}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 6.78639144971443e-06, 'module_to_agent_unmapping': 2.469105507450675e-06, 'tensor_to_numpy': 3.457677932226733e-05, 'get_actions': 3.5353268089587e-05, 'normalize_and_clip_actions': 3.505864063766764e-05, 'remove_single_ts_time_rank_from_batch': 8.224929929360873e-07, 'un_batch_to_individual_items': 1.4285584312247861e-05}}, 'connector_pipeline_timer': 0.000160072059998582}, 'env_step_timer': 6.796251432172885e-05, 'episode_return_min': -1148.4889439653775, 'num_env_steps_sampled': 5000, 'episode_return_mean': -1084.9867069566767, 'episode_len_min': 1000, 'connector_pipeline_timer': 0.0002504357076209375, 'num_env_steps_sampled_lifetime': 20000, 'num_episodes_lifetime': 20, 'episode_len_mean': 1000.0, 'num_episodes': 5, 'rlmodule_inference_timer': 0.00011109810130788345, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'num_env_steps_sampled_per_second': 1757.265609904529, 'time_between_sampling': 21.316543364752334}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 160000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1240.8510339372067, 'done': False, 'training_iteration': 40, 'trial_id': 'default', 'date': '2025-04-03_19-53-58', 'timestamp': 1743724438, 'time_this_iter_s': 3.207726001739502, 'time_total_s': 93.02898406982422, 'pid': 71851, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35f1318a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 93.02898406982422, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': 81.42500000000001, 'ram_util_percent': 55.9}})
2025-04-03 19:54:00,754 [__main__] [INFO] Iteration: 41/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.70s
2025-04-03 19:54:03,151 [__main__] [INFO] Iteration: 42/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.40s
2025-04-03 19:54:05,350 [__main__] [INFO] Iteration: 43/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.20s
2025-04-03 19:54:07,620 [__main__] [INFO] Iteration: 44/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.27s
2025-04-03 19:54:09,715 [__main__] [INFO] Iteration: 45/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.09s
2025-04-03 19:54:12,140 [__main__] [INFO] Iteration: 46/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.42s
2025-04-03 19:54:14,615 [__main__] [INFO] Iteration: 47/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.47s
2025-04-03 19:54:16,748 [__main__] [INFO] Iteration: 48/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.13s
2025-04-03 19:54:18,839 [__main__] [INFO] Iteration: 49/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.09s
2025-04-03 19:54:22,044 [__main__] [INFO] Iteration: 50/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 3.20s
2025-04-03 19:54:24,162 [__main__] [INFO] Iteration: 51/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.12s
2025-04-03 19:54:26,640 [__main__] [INFO] Iteration: 52/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.48s
2025-04-03 19:54:28,868 [__main__] [INFO] Iteration: 53/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.23s
2025-04-03 19:54:30,904 [__main__] [INFO] Iteration: 54/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.04s
2025-04-03 19:54:33,226 [__main__] [INFO] Iteration: 55/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.32s
2025-04-03 19:54:35,625 [__main__] [INFO] Iteration: 56/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.40s
2025-04-03 19:54:37,872 [__main__] [INFO] Iteration: 57/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.25s
2025-04-03 19:54:40,184 [__main__] [INFO] Iteration: 58/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.31s
2025-04-03 19:54:42,585 [__main__] [INFO] Iteration: 59/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.40s
2025-04-03 19:54:46,071 [__main__] [INFO] Iteration: 60/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 3.49s
2025-04-03 19:54:46,090 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.411841269543176, 'restore_env_runners': 1.3555471717621199e-05, 'training_step': 2.411718095741282, 'env_runner_sampling_timer': 0.28289862849743724, 'learner_update_timer': 2.1223075797808075, 'synch_weights': 0.005047443371097996, 'synch_env_connectors': 0.007429810413969627, 'restore_eval_env_runners': 7.303215331897264e-06, 'evaluation_iteration': 2.8468759568076085, 'synch_eval_env_connectors': 0.003337959317416685}, 'env_runners': {'timers': {'connectors': {'agent_to_module_mapping': 6.623129593208432e-06, 'add_observations_from_episodes_to_batch': 4.0364173321944215e-05, 'add_time_dim_to_batch_and_zero_pad': 1.9498043516448334e-05, 'numpy_to_tensor': 5.5485477787442505e-05, 'add_states_from_episodes_to_batch': 7.369434688766689e-06, 'batch_individual_items': 3.549282732622131e-05}}, 'env_reset_timer': 0.00014764673845923465, 'env_to_module_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 4.393712323634589e-06, 'batch_individual_items': 1.8393486846597272e-05, 'agent_to_module_mapping': 4.385360454540264e-06, 'add_observations_from_episodes_to_batch': 1.6168978410951282e-05, 'add_time_dim_to_batch_and_zero_pad': 6.54402240261282e-06, 'numpy_to_tensor': 3.11028073697155e-05}}, 'connector_pipeline_timer': 0.00011786594111318887}, 'env_to_module_sum_episodes_length_in': 101.27250081465326, 'num_module_steps_sampled_lifetime': {'target': 240000, 'servicer': 240000}, 'num_agent_steps_sampled': {'target': 4000, 'servicer': 4000}, 'sample': 0.177560674322606, 'num_agent_steps_sampled_lifetime': {'target': 240000, 'servicer': 240000}, 'weights_seq_no': 59.0, 'num_module_steps_sampled': {'target': 4000, 'servicer': 4000}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 9.835069220383137e-06, 'module_to_agent_unmapping': 3.823515855961883e-06, 'tensor_to_numpy': 5.0554546237590246e-05, 'get_actions': 0.00013369227281177673, 'normalize_and_clip_actions': 5.496323505413695e-05, 'remove_single_ts_time_rank_from_batch': 1.2923038397272652e-06, 'un_batch_to_individual_items': 2.2057545968439735e-05}}, 'connector_pipeline_timer': 0.0003236197462168022}, 'env_step_timer': 0.00010639802718795219, 'num_env_steps_sampled': 4000, 'connector_pipeline_timer': 0.00030690756482173407, 'num_env_steps_sampled_lifetime': 240000, 'rlmodule_inference_timer': 0.0001520892131874198, 'env_to_module_sum_episodes_length_out': 101.27250081465326, 'time_between_sampling': 2.24916625739215, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_return_max': -1071.189964353835, 'module_episode_returns_mean': {'target': 0.0, 'servicer': -1091.3982171163636}, 'episode_duration_sec_mean': 0.9053738751384156, 'agent_episode_returns_mean': {'target': 0.0, 'servicer': -1091.3982171163636}, 'episode_len_max': 1000, 'episode_return_min': -1104.8441978228716, 'episode_return_mean': -1091.3982171163636, 'episode_len_min': 1000, 'num_episodes_lifetime': 230, 'episode_len_mean': 1000.0, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 1136.7867958820227}, 'learners': {'servicer': {'gradients_default_optimizer_global_norm': 1.3338207006454468, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 142093.0, 'total_loss': 9.650665283203125, 'mean_kl_loss': 0.005250096786767244, 'num_module_steps_trained_lifetime': 2421376, 'default_optimizer_learning_rate': 5e-05, 'vf_explained_var': -0.00027489662170410156, 'num_module_steps_trained': 40320, 'weights_seq_no': 60.0, 'vf_loss': 9.798636436462402, 'curr_kl_coeff': 1.4551915445207286e-12, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'policy_loss': -0.05443012714385986, 'module_train_batch_size_mean': 128.0, 'entropy': 9.354007720947266, 'vf_loss_unclipped': 3265.958984375}, 'target': {'vf_loss_unclipped': 6.308036404334416e-08, 'gradients_default_optimizer_global_norm': 0.17296308279037476, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.034825317561626434, 'total_loss': -0.13597306609153748, 'num_module_steps_trained_lifetime': 2421376, 'default_optimizer_learning_rate': 5e-05, 'vf_explained_var': 0.9999204874038696, 'num_module_steps_trained': 40320, 'weights_seq_no': 60.0, 'vf_loss': 6.308036404334416e-08, 'curr_kl_coeff': 1.0728836485895954e-07, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'policy_loss': 0.00999663770198822, 'module_train_batch_size_mean': 128.0, 'entropy': 14.596977233886719}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.04904256599308653, 'add_time_dim_to_batch_and_zero_pad': 2.1905692076618834e-05, 'numpy_to_tensor': 0.00020029787279629433, 'add_states_from_episodes_to_batch': 5.125351736691707e-06, 'batch_individual_items': 0.06652483223358033, 'add_one_ts_to_episodes_and_truncate': 0.005575546646528012, 'add_columns_from_episodes_to_train_batch': 0.06929820662573158, 'agent_to_module_mapping': 0.003425598141429842, 'add_observations_from_episodes_to_batch': 0.00026556412852219276}}, 'connector_pipeline_timer': 0.19458496791882746}, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained_lifetime': 4842752, 'num_module_steps_trained': 80640, 'num_env_steps_trained_lifetime': 75668000, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'timers': {'connectors': {'agent_to_module_mapping': 5.373949700246508e-06, 'add_observations_from_episodes_to_batch': 3.5774026634700196e-05, 'add_time_dim_to_batch_and_zero_pad': 2.2522763946579975e-05, 'numpy_to_tensor': 3.642124871383016e-05, 'add_states_from_episodes_to_batch': 7.494291772284447e-06, 'batch_individual_items': 2.7073702627595534e-05}}, 'env_reset_timer': 0.000169819749247258, 'env_to_module_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 2.8932943362280154e-06, 'batch_individual_items': 1.185997194048953e-05, 'agent_to_module_mapping': 2.911717410461649e-06, 'add_observations_from_episodes_to_batch': 1.1314943478422242e-05, 'add_time_dim_to_batch_and_zero_pad': 4.309339111305905e-06, 'numpy_to_tensor': 2.0164943202178174e-05}}, 'connector_pipeline_timer': 7.855061387957384e-05}, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'num_module_steps_sampled_lifetime': {'target': 30000, 'servicer': 30000}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'num_agent_steps_sampled': {'target': 5000, 'servicer': 5000}, 'episode_return_max': -1075.574520532978, 'sample': 2.6857599202277487, 'num_agent_steps_sampled_lifetime': {'target': 30000, 'servicer': 30000}, 'module_episode_returns_mean': {'target': 0.0, 'servicer': -1098.427298073031}, 'episode_duration_sec_mean': 0.5241172919273959, 'weights_seq_no': 59.0, 'agent_episode_returns_mean': {'target': 0.0, 'servicer': -1098.427298073031}, 'episode_len_max': 1000, 'num_module_steps_sampled': {'target': 5000, 'servicer': 5000}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 6.784790736722183e-06, 'module_to_agent_unmapping': 2.4683357500499813e-06, 'tensor_to_numpy': 3.455954755984214e-05, 'get_actions': 3.533350111377865e-05, 'normalize_and_clip_actions': 3.50477413248415e-05, 'remove_single_ts_time_rank_from_batch': 8.219771225131536e-07, 'un_batch_to_individual_items': 1.4282168270640763e-05}}, 'connector_pipeline_timer': 0.00016001368821602876}, 'env_step_timer': 6.794769629786654e-05, 'episode_return_min': -1187.5216667738232, 'num_env_steps_sampled': 5000, 'episode_return_mean': -1098.427298073031, 'episode_len_min': 1000, 'connector_pipeline_timer': 0.00025033862935902113, 'num_env_steps_sampled_lifetime': 30000, 'num_episodes_lifetime': 30, 'episode_len_mean': 1000.0, 'num_episodes': 5, 'rlmodule_inference_timer': 0.00011098048432447875, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'num_env_steps_sampled_per_second': 1757.2529060823067, 'time_between_sampling': 21.316202959238936}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 240000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1136.7867958820227, 'done': False, 'training_iteration': 60, 'trial_id': 'default', 'date': '2025-04-03_19-54-46', 'timestamp': 1743724486, 'time_this_iter_s': 3.473067045211792, 'time_total_s': 140.752117395401, 'pid': 71851, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35f1318a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 140.752117395401, 'iterations_since_restore': 60, 'perf': {'cpu_util_percent': 80.22, 'ram_util_percent': 55.9}})
2025-04-03 19:54:48,555 [__main__] [INFO] Iteration: 61/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.46s
2025-04-03 19:54:51,071 [__main__] [INFO] Iteration: 62/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.52s
2025-04-03 19:54:53,529 [__main__] [INFO] Iteration: 63/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.46s
2025-04-03 19:54:56,193 [__main__] [INFO] Iteration: 64/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.66s
2025-04-03 19:54:58,354 [__main__] [INFO] Iteration: 65/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.16s
2025-04-03 19:55:00,674 [__main__] [INFO] Iteration: 66/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.32s
2025-04-03 19:55:03,119 [__main__] [INFO] Iteration: 67/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.45s
2025-04-03 19:55:05,479 [__main__] [INFO] Iteration: 68/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.36s
2025-04-03 19:55:08,211 [__main__] [INFO] Iteration: 69/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.73s
2025-04-03 19:55:11,400 [__main__] [INFO] Iteration: 70/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 3.19s
2025-04-03 19:55:13,846 [__main__] [INFO] Iteration: 71/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.45s
2025-04-03 19:55:16,355 [__main__] [INFO] Iteration: 72/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.51s
2025-04-03 19:55:19,156 [__main__] [INFO] Iteration: 73/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.80s
2025-04-03 19:55:21,664 [__main__] [INFO] Iteration: 74/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.51s
2025-04-03 19:55:24,480 [__main__] [INFO] Iteration: 75/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.82s
2025-04-03 19:55:27,004 [__main__] [INFO] Iteration: 76/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.52s
2025-04-03 19:55:29,551 [__main__] [INFO] Iteration: 77/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.55s
2025-04-03 19:55:32,040 [__main__] [INFO] Iteration: 78/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.49s
2025-04-03 19:55:34,674 [__main__] [INFO] Iteration: 79/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.63s
2025-04-03 19:55:38,035 [__main__] [INFO] Iteration: 80/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 3.36s
2025-04-03 19:55:38,053 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.4418673841901595, 'restore_env_runners': 1.2876464583166412e-05, 'training_step': 2.4417389590944376, 'env_runner_sampling_timer': 0.271880161779649, 'learner_update_timer': 2.1633128016322445, 'synch_weights': 0.005007542718860915, 'synch_env_connectors': 0.007449847559736345, 'restore_eval_env_runners': 7.258602289802456e-06, 'evaluation_iteration': 2.849209957156414, 'synch_eval_env_connectors': 0.003304422092708666}, 'env_runners': {'timers': {'connectors': {'agent_to_module_mapping': 6.623129593208432e-06, 'add_observations_from_episodes_to_batch': 4.0364173321944215e-05, 'add_time_dim_to_batch_and_zero_pad': 1.9498043516448334e-05, 'numpy_to_tensor': 5.5485477787442505e-05, 'add_states_from_episodes_to_batch': 7.369434688766689e-06, 'batch_individual_items': 3.549282732622131e-05}}, 'env_reset_timer': 0.00014764673845923465, 'env_to_module_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 4.354936362866591e-06, 'batch_individual_items': 2.0071492457530905e-05, 'agent_to_module_mapping': 4.671659464225514e-06, 'add_observations_from_episodes_to_batch': 1.82305580440184e-05, 'add_time_dim_to_batch_and_zero_pad': 7.1302841761790834e-06, 'numpy_to_tensor': 3.2604590893807844e-05}}, 'connector_pipeline_timer': 0.0001257969450846991}, 'env_to_module_sum_episodes_length_in': 106.95241103664021, 'num_module_steps_sampled_lifetime': {'target': 320000, 'servicer': 320000}, 'num_agent_steps_sampled': {'target': 4000, 'servicer': 4000}, 'sample': 0.17429621320743283, 'num_agent_steps_sampled_lifetime': {'target': 320000, 'servicer': 320000}, 'weights_seq_no': 79.0, 'num_module_steps_sampled': {'target': 4000, 'servicer': 4000}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 1.101084747614701e-05, 'module_to_agent_unmapping': 3.9155688114254035e-06, 'tensor_to_numpy': 5.3755147833575964e-05, 'get_actions': 0.00014504996754727048, 'normalize_and_clip_actions': 6.013465725169733e-05, 'remove_single_ts_time_rank_from_batch': 1.339028226638e-06, 'un_batch_to_individual_items': 2.3425823116659417e-05}}, 'connector_pipeline_timer': 0.0003492877739075613}, 'env_step_timer': 0.00011271764176067124, 'num_env_steps_sampled': 4000, 'connector_pipeline_timer': 0.00030690756482173407, 'num_env_steps_sampled_lifetime': 320000, 'rlmodule_inference_timer': 0.00016338738012779767, 'env_to_module_sum_episodes_length_out': 106.95241103664021, 'time_between_sampling': 2.2760744100396098, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_return_max': -1061.7324011252545, 'module_episode_returns_mean': {'target': 0.0, 'servicer': -1077.217940595527}, 'episode_duration_sec_mean': 0.8505727005609989, 'agent_episode_returns_mean': {'target': 0.0, 'servicer': -1077.217940595527}, 'episode_len_max': 1000, 'episode_return_min': -1089.255485267322, 'episode_return_mean': -1077.217940595527, 'episode_len_min': 1000, 'num_episodes_lifetime': 299, 'episode_len_mean': 1000.0, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 1189.8457521190442}, 'learners': {'servicer': {'gradients_default_optimizer_global_norm': 1.5745141506195068, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 142093.0, 'total_loss': 9.452756881713867, 'mean_kl_loss': 0.006768984254449606, 'num_module_steps_trained_lifetime': 3228288, 'default_optimizer_learning_rate': 5e-05, 'vf_explained_var': 0.0001226663589477539, 'num_module_steps_trained': 40320, 'weights_seq_no': 80.0, 'vf_loss': 9.549903869628906, 'curr_kl_coeff': 1.421085492696024e-15, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'policy_loss': 0.0028911009430885315, 'module_train_batch_size_mean': 128.0, 'entropy': 10.003862380981445, 'vf_loss_unclipped': 3520.689697265625}, 'target': {'vf_loss_unclipped': 4.230806371907647e-09, 'gradients_default_optimizer_global_norm': 0.32327160239219666, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.020337911322712898, 'total_loss': -0.8471393585205078, 'num_module_steps_trained_lifetime': 3228288, 'default_optimizer_learning_rate': 5e-05, 'vf_explained_var': 0.9998335242271423, 'num_module_steps_trained': 40320, 'weights_seq_no': 80.0, 'vf_loss': 4.230806371907647e-09, 'curr_kl_coeff': 4.6400909923249856e-06, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'policy_loss': 0.015518736094236374, 'module_train_batch_size_mean': 128.0, 'entropy': 86.26581573486328}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.04620405770077627, 'add_time_dim_to_batch_and_zero_pad': 2.129566392570652e-05, 'numpy_to_tensor': 0.00019468257935098136, 'add_states_from_episodes_to_batch': 5.063536771628336e-06, 'batch_individual_items': 0.06785779695937601, 'add_one_ts_to_episodes_and_truncate': 0.0055353096141596055, 'add_columns_from_episodes_to_train_batch': 0.06938536198173996, 'agent_to_module_mapping': 0.0034464906711459777, 'add_observations_from_episodes_to_batch': 0.00026532364963468316}}, 'connector_pipeline_timer': 0.19313158219700366}, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained_lifetime': 6456576, 'num_module_steps_trained': 80640, 'num_env_steps_trained_lifetime': 100884000, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'timers': {'connectors': {'agent_to_module_mapping': 5.372917946015893e-06, 'add_observations_from_episodes_to_batch': 3.5759281100176184e-05, 'add_time_dim_to_batch_and_zero_pad': 2.2507274595239982e-05, 'numpy_to_tensor': 3.642396165631146e-05, 'add_states_from_episodes_to_batch': 7.489529239033642e-06, 'batch_individual_items': 2.706597262668564e-05}}, 'env_reset_timer': 0.00016974162351263033, 'env_to_module_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 2.893746436881543e-06, 'batch_individual_items': 1.1857958996126591e-05, 'agent_to_module_mapping': 2.9117855442765824e-06, 'add_observations_from_episodes_to_batch': 1.1318990825193899e-05, 'add_time_dim_to_batch_and_zero_pad': 4.308360903980854e-06, 'numpy_to_tensor': 2.0135719715592915e-05}}, 'connector_pipeline_timer': 7.853099476671838e-05}, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'num_module_steps_sampled_lifetime': {'target': 40000, 'servicer': 40000}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'num_agent_steps_sampled': {'target': 5000, 'servicer': 5000}, 'episode_return_max': -1075.574520532978, 'sample': 2.685800995092701, 'num_agent_steps_sampled_lifetime': {'target': 40000, 'servicer': 40000}, 'module_episode_returns_mean': {'target': 0.0, 'servicer': -1144.6624332246083}, 'episode_duration_sec_mean': 0.5265571156682562, 'weights_seq_no': 79.0, 'agent_episode_returns_mean': {'target': 0.0, 'servicer': -1144.6624332246083}, 'episode_len_max': 1000, 'num_module_steps_sampled': {'target': 5000, 'servicer': 5000}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 6.785379602750106e-06, 'module_to_agent_unmapping': 2.4692458960045228e-06, 'tensor_to_numpy': 3.4551242315532184e-05, 'get_actions': 3.533039293028268e-05, 'normalize_and_clip_actions': 3.504988944589672e-05, 'remove_single_ts_time_rank_from_batch': 8.217760932713358e-07, 'un_batch_to_individual_items': 1.4285458400304384e-05}}, 'connector_pipeline_timer': 0.00016001374767710575}, 'env_step_timer': 6.795743424072518e-05, 'episode_return_min': -1371.7848080614137, 'num_env_steps_sampled': 5000, 'episode_return_mean': -1144.6624332246083, 'episode_len_min': 1000, 'connector_pipeline_timer': 0.0002502020293979719, 'num_env_steps_sampled_lifetime': 40000, 'num_episodes_lifetime': 40, 'episode_len_mean': 1000.0, 'num_episodes': 5, 'rlmodule_inference_timer': 0.00011093079746783197, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'num_env_steps_sampled_per_second': 1757.2311615225692, 'time_between_sampling': 21.31641206072794}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 320000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1189.8457521190442, 'done': False, 'training_iteration': 80, 'trial_id': 'default', 'date': '2025-04-03_19-55-38', 'timestamp': 1743724538, 'time_this_iter_s': 3.3474507331848145, 'time_total_s': 192.38609290122986, 'pid': 71851, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35f1318a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 192.38609290122986, 'iterations_since_restore': 80, 'perf': {'cpu_util_percent': 80.96, 'ram_util_percent': 56.0}})
2025-04-03 19:55:40,916 [__main__] [INFO] Iteration: 81/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.86s
2025-04-03 19:55:43,512 [__main__] [INFO] Iteration: 82/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.59s
2025-04-03 19:55:46,170 [__main__] [INFO] Iteration: 83/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.66s
2025-04-03 19:55:48,920 [__main__] [INFO] Iteration: 84/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.75s
2025-04-03 19:55:51,415 [__main__] [INFO] Iteration: 85/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.49s
2025-04-03 19:55:53,900 [__main__] [INFO] Iteration: 86/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.48s
2025-04-03 19:55:56,457 [__main__] [INFO] Iteration: 87/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.56s
2025-04-03 19:55:58,967 [__main__] [INFO] Iteration: 88/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.51s
2025-04-03 19:56:01,550 [__main__] [INFO] Iteration: 89/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.58s
2025-04-03 19:56:04,785 [__main__] [INFO] Iteration: 90/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 3.23s
2025-04-03 19:56:07,148 [__main__] [INFO] Iteration: 91/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.36s
2025-04-03 19:56:09,408 [__main__] [INFO] Iteration: 92/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.26s
2025-04-03 19:56:11,682 [__main__] [INFO] Iteration: 93/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.27s
2025-04-03 19:56:13,843 [__main__] [INFO] Iteration: 94/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.16s
2025-04-03 19:56:16,053 [__main__] [INFO] Iteration: 95/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.21s
2025-04-03 19:56:18,431 [__main__] [INFO] Iteration: 96/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.38s
2025-04-03 19:56:20,656 [__main__] [INFO] Iteration: 97/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.22s
2025-04-03 19:56:23,138 [__main__] [INFO] Iteration: 98/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.48s
2025-04-03 19:56:25,468 [__main__] [INFO] Iteration: 99/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 2.33s
2025-04-03 19:56:28,893 [__main__] [INFO] Iteration: 100/100, Timesteps: 0, Mean Reward (Eval/Sample): nan, Iter Time: 3.42s
2025-04-03 19:56:28,911 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.454766916044065, 'restore_env_runners': 1.2230685295435997e-05, 'training_step': 2.454635904554816, 'env_runner_sampling_timer': 0.26308751995360985, 'learner_update_timer': 2.184935863680346, 'synch_weights': 0.0049996237012277555, 'synch_env_connectors': 0.007449796667832883, 'restore_eval_env_runners': 7.209900268954167e-06, 'evaluation_iteration': 2.8498930605946735, 'synch_eval_env_connectors': 0.0032695065654714394}, 'env_runners': {'timers': {'connectors': {'agent_to_module_mapping': 6.623129593208432e-06, 'add_observations_from_episodes_to_batch': 4.0364173321944215e-05, 'add_time_dim_to_batch_and_zero_pad': 1.9498043516448334e-05, 'numpy_to_tensor': 5.5485477787442505e-05, 'add_states_from_episodes_to_batch': 7.369434688766689e-06, 'batch_individual_items': 3.549282732622131e-05}}, 'env_reset_timer': 0.00014764673845923465, 'env_to_module_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 4.845948099032907e-06, 'batch_individual_items': 2.0346691632485805e-05, 'agent_to_module_mapping': 4.2996079283285576e-06, 'add_observations_from_episodes_to_batch': 1.6637096442987914e-05, 'add_time_dim_to_batch_and_zero_pad': 6.9530059820192675e-06, 'numpy_to_tensor': 3.2722149839671164e-05}}, 'connector_pipeline_timer': 0.00012305367315482813}, 'env_to_module_sum_episodes_length_in': 101.95413642173257, 'num_module_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'num_agent_steps_sampled': {'target': 4000, 'servicer': 4000}, 'sample': 0.1722194892913846, 'num_agent_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'weights_seq_no': 99.0, 'num_module_steps_sampled': {'target': 4000, 'servicer': 4000}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 1.0883865925124826e-05, 'module_to_agent_unmapping': 3.894916987425382e-06, 'tensor_to_numpy': 5.4736691301013354e-05, 'get_actions': 0.000148631892029076, 'normalize_and_clip_actions': 5.9545792053453633e-05, 'remove_single_ts_time_rank_from_batch': 1.2192221225147389e-06, 'un_batch_to_individual_items': 2.2475879280336628e-05}}, 'connector_pipeline_timer': 0.0003574941915342452}, 'env_step_timer': 0.00011820800960869382, 'num_env_steps_sampled': 4000, 'connector_pipeline_timer': 0.00030690756482173407, 'num_env_steps_sampled_lifetime': 400000, 'rlmodule_inference_timer': 0.00016029499923088917, 'env_to_module_sum_episodes_length_out': 101.95413642173257, 'time_between_sampling': 2.3007881296935158, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_return_max': -1052.8070482572582, 'module_episode_returns_mean': {'target': 0.0, 'servicer': -1072.3829626523818}, 'episode_duration_sec_mean': 0.8889722410411037, 'agent_episode_returns_mean': {'target': 0.0, 'servicer': -1072.3829626523818}, 'episode_len_max': 1000, 'episode_return_min': -1094.4979730896366, 'episode_return_mean': -1072.3829626523818, 'episode_len_min': 1000, 'num_episodes_lifetime': 391, 'episode_len_mean': 1000.0, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 1168.906488118596}, 'learners': {'servicer': {'gradients_default_optimizer_global_norm': 1.3725669384002686, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 142093.0, 'total_loss': 9.736631393432617, 'mean_kl_loss': 0.005152207799255848, 'num_module_steps_trained_lifetime': 4035456, 'default_optimizer_learning_rate': 5e-05, 'vf_explained_var': 8.249282836914062e-05, 'num_module_steps_trained': 40320, 'weights_seq_no': 100.0, 'vf_loss': 9.826925277709961, 'curr_kl_coeff': 1.387778801460961e-18, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'policy_loss': 0.012838408350944519, 'module_train_batch_size_mean': 128.0, 'entropy': 10.313252449035645, 'vf_loss_unclipped': 3440.838623046875}, 'target': {'vf_loss_unclipped': 4.02697787649231e-06, 'gradients_default_optimizer_global_norm': 0.07154538482427597, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.03447910025715828, 'total_loss': -1.1427578926086426, 'num_module_steps_trained_lifetime': 4035456, 'default_optimizer_learning_rate': 5e-05, 'vf_explained_var': 0.9998474717140198, 'num_module_steps_trained': 40320, 'weights_seq_no': 100.0, 'vf_loss': 4.02697787649231e-06, 'curr_kl_coeff': 0.002031867392361164, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'policy_loss': 0.009141327813267708, 'module_train_batch_size_mean': 128.0, 'entropy': 115.19499969482422}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.043204304439961844, 'add_time_dim_to_batch_and_zero_pad': 2.0666655061607085e-05, 'numpy_to_tensor': 0.00018874279181646495, 'add_states_from_episodes_to_batch': 5.000518539389186e-06, 'batch_individual_items': 0.06912058288122516, 'add_one_ts_to_episodes_and_truncate': 0.0054960161412062345, 'add_columns_from_episodes_to_train_batch': 0.06944288265086877, 'agent_to_module_mapping': 0.0034702732706964603, 'add_observations_from_episodes_to_batch': 0.0002655659054447504}}, 'connector_pipeline_timer': 0.19142086653035054}, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained_lifetime': 8070912, 'num_module_steps_trained': 80640, 'num_env_steps_trained_lifetime': 126108000, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'timers': {'connectors': {'agent_to_module_mapping': 5.371548328126412e-06, 'add_observations_from_episodes_to_batch': 3.574016205888376e-05, 'add_time_dim_to_batch_and_zero_pad': 2.248766968621983e-05, 'numpy_to_tensor': 3.6428880166692375e-05, 'add_states_from_episodes_to_batch': 7.483403262378252e-06, 'batch_individual_items': 2.705670647694539e-05}}, 'env_reset_timer': 0.00016964826528666126, 'env_to_module_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 2.8949364231970835e-06, 'batch_individual_items': 1.1862938647621095e-05, 'agent_to_module_mapping': 2.9135792844763444e-06, 'add_observations_from_episodes_to_batch': 1.1315586396928357e-05, 'add_time_dim_to_batch_and_zero_pad': 4.309323871753385e-06, 'numpy_to_tensor': 2.0113489032211297e-05}}, 'connector_pipeline_timer': 7.853739157744814e-05}, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'num_module_steps_sampled_lifetime': {'target': 50000, 'servicer': 50000}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'num_agent_steps_sampled': {'target': 5000, 'servicer': 5000}, 'episode_return_max': -1075.574520532978, 'sample': 2.6858571736382033, 'num_agent_steps_sampled_lifetime': {'target': 50000, 'servicer': 50000}, 'module_episode_returns_mean': {'target': 0.0, 'servicer': -1206.6449146083355}, 'episode_duration_sec_mean': 0.5279355623590527, 'weights_seq_no': 99.0, 'agent_episode_returns_mean': {'target': 0.0, 'servicer': -1206.6449146083355}, 'episode_len_max': 1000, 'num_module_steps_sampled': {'target': 5000, 'servicer': 5000}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 6.790728253358682e-06, 'module_to_agent_unmapping': 2.469460346947635e-06, 'tensor_to_numpy': 3.455905218369354e-05, 'get_actions': 3.533133725971908e-05, 'normalize_and_clip_actions': 3.506856905799198e-05, 'remove_single_ts_time_rank_from_batch': 8.222037186810388e-07, 'un_batch_to_individual_items': 1.42947020504091e-05}}, 'connector_pipeline_timer': 0.00016010872629146426}, 'env_step_timer': 6.800506707613055e-05, 'episode_return_min': -1371.7848080614137, 'num_env_steps_sampled': 5000, 'episode_return_mean': -1206.6449146083355, 'episode_len_min': 1000, 'connector_pipeline_timer': 0.0002500287010364112, 'num_env_steps_sampled_lifetime': 50000, 'num_episodes_lifetime': 50, 'episode_len_mean': 1000.0, 'num_episodes': 5, 'rlmodule_inference_timer': 0.00011091575215685026, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'num_env_steps_sampled_per_second': 1757.1831722175118, 'time_between_sampling': 21.317383336112524}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 400000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1168.906488118596, 'done': False, 'training_iteration': 100, 'trial_id': 'default', 'date': '2025-04-03_19-56-28', 'timestamp': 1743724588, 'time_this_iter_s': 3.4096322059631348, 'time_total_s': 242.93655347824097, 'pid': 71851, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35f1318a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 242.93655347824097, 'iterations_since_restore': 100, 'perf': {'cpu_util_percent': 80.5, 'ram_util_percent': 56.05}})
2025-04-03 19:56:28,912 [__main__] [INFO] 
--- Training Finished ---
2025-04-03 19:56:28,912 [__main__] [INFO] Total Training Time: 244.45 seconds
2025-04-03 19:56:28,912 [__main__] [INFO] Using last saved checkpoint: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.454766916044065, 'restore_env_runners': 1.2230685295435997e-05, 'training_step': 2.454635904554816, 'env_runner_sampling_timer': 0.26308751995360985, 'learner_update_timer': 2.184935863680346, 'synch_weights': 0.0049996237012277555, 'synch_env_connectors': 0.007449796667832883, 'restore_eval_env_runners': 7.209900268954167e-06, 'evaluation_iteration': 2.8498930605946735, 'synch_eval_env_connectors': 0.0032695065654714394}, 'env_runners': {'timers': {'connectors': {'agent_to_module_mapping': 6.623129593208432e-06, 'add_observations_from_episodes_to_batch': 4.0364173321944215e-05, 'add_time_dim_to_batch_and_zero_pad': 1.9498043516448334e-05, 'numpy_to_tensor': 5.5485477787442505e-05, 'add_states_from_episodes_to_batch': 7.369434688766689e-06, 'batch_individual_items': 3.549282732622131e-05}}, 'env_reset_timer': 0.00014764673845923465, 'env_to_module_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 4.845948099032907e-06, 'batch_individual_items': 2.0346691632485805e-05, 'agent_to_module_mapping': 4.2996079283285576e-06, 'add_observations_from_episodes_to_batch': 1.6637096442987914e-05, 'add_time_dim_to_batch_and_zero_pad': 6.9530059820192675e-06, 'numpy_to_tensor': 3.2722149839671164e-05}}, 'connector_pipeline_timer': 0.00012305367315482813}, 'env_to_module_sum_episodes_length_in': 101.95413642173257, 'num_module_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'num_agent_steps_sampled': {'target': 4000, 'servicer': 4000}, 'sample': 0.1722194892913846, 'num_agent_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'weights_seq_no': 99.0, 'num_module_steps_sampled': {'target': 4000, 'servicer': 4000}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 1.0883865925124826e-05, 'module_to_agent_unmapping': 3.894916987425382e-06, 'tensor_to_numpy': 5.4736691301013354e-05, 'get_actions': 0.000148631892029076, 'normalize_and_clip_actions': 5.9545792053453633e-05, 'remove_single_ts_time_rank_from_batch': 1.2192221225147389e-06, 'un_batch_to_individual_items': 2.2475879280336628e-05}}, 'connector_pipeline_timer': 0.0003574941915342452}, 'env_step_timer': 0.00011820800960869382, 'num_env_steps_sampled': 4000, 'connector_pipeline_timer': 0.00030690756482173407, 'num_env_steps_sampled_lifetime': 400000, 'rlmodule_inference_timer': 0.00016029499923088917, 'env_to_module_sum_episodes_length_out': 101.95413642173257, 'time_between_sampling': 2.3007881296935158, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_return_max': -1052.8070482572582, 'module_episode_returns_mean': {'target': 0.0, 'servicer': -1072.3829626523818}, 'episode_duration_sec_mean': 0.8889722410411037, 'agent_episode_returns_mean': {'target': 0.0, 'servicer': -1072.3829626523818}, 'episode_len_max': 1000, 'episode_return_min': -1094.4979730896366, 'episode_return_mean': -1072.3829626523818, 'episode_len_min': 1000, 'num_episodes_lifetime': 391, 'episode_len_mean': 1000.0, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 1168.906488118596}, 'learners': {'servicer': {'gradients_default_optimizer_global_norm': 1.3725669384002686, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 142093.0, 'total_loss': 9.736631393432617, 'mean_kl_loss': 0.005152207799255848, 'num_module_steps_trained_lifetime': 4035456, 'default_optimizer_learning_rate': 5e-05, 'vf_explained_var': 8.249282836914062e-05, 'num_module_steps_trained': 40320, 'weights_seq_no': 100.0, 'vf_loss': 9.826925277709961, 'curr_kl_coeff': 1.387778801460961e-18, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'policy_loss': 0.012838408350944519, 'module_train_batch_size_mean': 128.0, 'entropy': 10.313252449035645, 'vf_loss_unclipped': 3440.838623046875}, 'target': {'vf_loss_unclipped': 4.02697787649231e-06, 'gradients_default_optimizer_global_norm': 0.07154538482427597, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.03447910025715828, 'total_loss': -1.1427578926086426, 'num_module_steps_trained_lifetime': 4035456, 'default_optimizer_learning_rate': 5e-05, 'vf_explained_var': 0.9998474717140198, 'num_module_steps_trained': 40320, 'weights_seq_no': 100.0, 'vf_loss': 4.02697787649231e-06, 'curr_kl_coeff': 0.002031867392361164, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'policy_loss': 0.009141327813267708, 'module_train_batch_size_mean': 128.0, 'entropy': 115.19499969482422}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.043204304439961844, 'add_time_dim_to_batch_and_zero_pad': 2.0666655061607085e-05, 'numpy_to_tensor': 0.00018874279181646495, 'add_states_from_episodes_to_batch': 5.000518539389186e-06, 'batch_individual_items': 0.06912058288122516, 'add_one_ts_to_episodes_and_truncate': 0.0054960161412062345, 'add_columns_from_episodes_to_train_batch': 0.06944288265086877, 'agent_to_module_mapping': 0.0034702732706964603, 'add_observations_from_episodes_to_batch': 0.0002655659054447504}}, 'connector_pipeline_timer': 0.19142086653035054}, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained_lifetime': 8070912, 'num_module_steps_trained': 80640, 'num_env_steps_trained_lifetime': 126108000, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'timers': {'connectors': {'agent_to_module_mapping': 5.371548328126412e-06, 'add_observations_from_episodes_to_batch': 3.574016205888376e-05, 'add_time_dim_to_batch_and_zero_pad': 2.248766968621983e-05, 'numpy_to_tensor': 3.6428880166692375e-05, 'add_states_from_episodes_to_batch': 7.483403262378252e-06, 'batch_individual_items': 2.705670647694539e-05}}, 'env_reset_timer': 0.00016964826528666126, 'env_to_module_connector': {'timers': {'connectors': {'add_states_from_episodes_to_batch': 2.8949364231970835e-06, 'batch_individual_items': 1.1862938647621095e-05, 'agent_to_module_mapping': 2.9135792844763444e-06, 'add_observations_from_episodes_to_batch': 1.1315586396928357e-05, 'add_time_dim_to_batch_and_zero_pad': 4.309323871753385e-06, 'numpy_to_tensor': 2.0113489032211297e-05}}, 'connector_pipeline_timer': 7.853739157744814e-05}, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'num_module_steps_sampled_lifetime': {'target': 50000, 'servicer': 50000}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'num_agent_steps_sampled': {'target': 5000, 'servicer': 5000}, 'episode_return_max': -1075.574520532978, 'sample': 2.6858571736382033, 'num_agent_steps_sampled_lifetime': {'target': 50000, 'servicer': 50000}, 'module_episode_returns_mean': {'target': 0.0, 'servicer': -1206.6449146083355}, 'episode_duration_sec_mean': 0.5279355623590527, 'weights_seq_no': 99.0, 'agent_episode_returns_mean': {'target': 0.0, 'servicer': -1206.6449146083355}, 'episode_len_max': 1000, 'num_module_steps_sampled': {'target': 5000, 'servicer': 5000}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 6.790728253358682e-06, 'module_to_agent_unmapping': 2.469460346947635e-06, 'tensor_to_numpy': 3.455905218369354e-05, 'get_actions': 3.533133725971908e-05, 'normalize_and_clip_actions': 3.506856905799198e-05, 'remove_single_ts_time_rank_from_batch': 8.222037186810388e-07, 'un_batch_to_individual_items': 1.42947020504091e-05}}, 'connector_pipeline_timer': 0.00016010872629146426}, 'env_step_timer': 6.800506707613055e-05, 'episode_return_min': -1371.7848080614137, 'num_env_steps_sampled': 5000, 'episode_return_mean': -1206.6449146083355, 'episode_len_min': 1000, 'connector_pipeline_timer': 0.0002500287010364112, 'num_env_steps_sampled_lifetime': 50000, 'num_episodes_lifetime': 50, 'episode_len_mean': 1000.0, 'num_episodes': 5, 'rlmodule_inference_timer': 0.00011091575215685026, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'num_env_steps_sampled_per_second': 1757.1831722175118, 'time_between_sampling': 21.317383336112524}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 400000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1168.906488118596, 'done': False, 'training_iteration': 100, 'trial_id': 'default', 'date': '2025-04-03_19-56-28', 'timestamp': 1743724588, 'time_this_iter_s': 3.4096322059631348, 'time_total_s': 242.93655347824097, 'pid': 71851, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35f1318a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 242.93655347824097, 'iterations_since_restore': 100, 'perf': {'cpu_util_percent': 80.5, 'ram_util_percent': 56.05}})
2025-04-03 19:56:28,913 [__main__] [INFO] 
--- Running Evaluation & Recording Video ---
2025-04-03 19:56:28,914 [__main__] [INFO] Evaluation Episode: 1/5
2025-04-03 19:56:29,005 [src.satellite_marl_env] [INFO] MuJoCo Renderer initialized.
2025-04-03 19:56:29,018 [__main__] [ERROR] Evaluation failed: algo.compute_single_action is deprecated and likely incompatible with the current RLlib API stack. Evaluation video generation needs update for newer RLlib.
2025-04-03 19:56:29,018 [__main__] [INFO] Evaluation Episode 1 Rewards: {'servicer': 0, 'target': 0}
2025-04-03 19:56:29,018 [__main__] [INFO] Evaluation Episode: 2/5
2025-04-03 19:56:29,020 [__main__] [ERROR] Evaluation failed: algo.compute_single_action is deprecated and likely incompatible with the current RLlib API stack. Evaluation video generation needs update for newer RLlib.
2025-04-03 19:56:29,020 [__main__] [INFO] Evaluation Episode 2 Rewards: {'servicer': 0, 'target': 0}
2025-04-03 19:56:29,021 [__main__] [INFO] Evaluation Episode: 3/5
2025-04-03 19:56:29,022 [__main__] [ERROR] Evaluation failed: algo.compute_single_action is deprecated and likely incompatible with the current RLlib API stack. Evaluation video generation needs update for newer RLlib.
2025-04-03 19:56:29,022 [__main__] [INFO] Evaluation Episode 3 Rewards: {'servicer': 0, 'target': 0}
2025-04-03 19:56:29,022 [__main__] [INFO] Evaluation Episode: 4/5
2025-04-03 19:56:29,024 [__main__] [ERROR] Evaluation failed: algo.compute_single_action is deprecated and likely incompatible with the current RLlib API stack. Evaluation video generation needs update for newer RLlib.
2025-04-03 19:56:29,024 [__main__] [INFO] Evaluation Episode 4 Rewards: {'servicer': 0, 'target': 0}
2025-04-03 19:56:29,024 [__main__] [INFO] Evaluation Episode: 5/5
2025-04-03 19:56:29,026 [__main__] [ERROR] Evaluation failed: algo.compute_single_action is deprecated and likely incompatible with the current RLlib API stack. Evaluation video generation needs update for newer RLlib.
2025-04-03 19:56:29,026 [__main__] [INFO] Evaluation Episode 5 Rewards: {'servicer': 0, 'target': 0}
2025-04-03 19:56:29,034 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 19:56:29,034 [__main__] [INFO] Saving evaluation video to: /Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results/evaluation_video.mp4
2025-04-03 19:56:29,201 [__main__] [INFO] Shutting down Ray...
2025-04-03 19:56:29,673 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 19:56:29,694 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 19:56:31,287 [__main__] [INFO] Script finished.
