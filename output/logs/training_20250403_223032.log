2025-04-03 22:30:32,546 [__main__] [INFO] Initializing Ray...
2025-04-03 22:30:37,960 [__main__] [INFO] Creating temporary environment to get action/observation spaces...
2025-04-03 22:30:37,962 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 22:30:37,962 [__main__] [INFO] Spaces retrieved.
2025-04-03 22:30:37,963 [__main__] [INFO] Configuring RLlib PPO Algorithm...
2025-04-03 22:30:37,963 [__main__] [INFO] Using 23 environment runners (workers).
2025-04-03 22:30:37,963 [__main__] [INFO] Setting train_batch_size to 4600 (min required estimate: 4600)
2025-04-03 22:30:37,963 [__main__] [INFO] Building Algorithm...
2025-04-03 22:30:52,689 [__main__] [INFO] Algorithm Built. Using Policy/Module Class: DefaultPPOTorchRLModule
2025-04-03 22:30:52,689 [__main__] [INFO] 
--- Starting Training for 100 iterations ---
2025-04-03 22:30:55,469 [__main__] [INFO] Iter: 1/100, Ts(iter): 0, Ts(total): 4600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.78s
2025-04-03 22:30:58,412 [__main__] [INFO] Iter: 2/100, Ts(iter): 0, Ts(total): 9200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.94s
2025-04-03 22:31:01,471 [__main__] [INFO] Iter: 3/100, Ts(iter): 0, Ts(total): 13800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.06s
2025-04-03 22:31:04,410 [__main__] [INFO] Iter: 4/100, Ts(iter): 0, Ts(total): 18400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.94s
2025-04-03 22:31:07,105 [__main__] [INFO] Iter: 5/100, Ts(iter): 0, Ts(total): 23000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.70s
2025-04-03 22:31:09,892 [__main__] [INFO] Iter: 6/100, Ts(iter): 0, Ts(total): 27600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.79s
2025-04-03 22:31:12,913 [__main__] [INFO] Iter: 7/100, Ts(iter): 0, Ts(total): 32200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.02s
2025-04-03 22:31:15,882 [__main__] [INFO] Iter: 8/100, Ts(iter): 0, Ts(total): 36800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.97s
2025-04-03 22:31:18,525 [__main__] [INFO] Iter: 9/100, Ts(iter): 0, Ts(total): 41400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.64s
2025-04-03 22:31:44,681 [__main__] [INFO] Iter: 10/100, Ts(iter): 0, Ts(total): 46000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 26.16s
2025-04-03 22:31:44,682 [__main__] [DEBUG] Full result dict at iter 10: {'timers': {'training_iteration': 2.787437049280456, 'restore_env_runners': 1.9090270787300184e-05, 'training_step': 2.787309295161186, 'env_runner_sampling_timer': 0.2916793594164308, 'learner_update_timer': 2.4890510204400234, 'synch_weights': 0.005435287393525654, 'synch_env_connectors': 0.007058822046858316, 'restore_eval_env_runners': 5.374997272156179e-06, 'evaluation_iteration': nan, 'synch_eval_env_connectors': 0.0018858749972423539}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 46000, 'servicer': 46000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.9083803594446293e-05, 'add_time_dim_to_batch_and_zero_pad': 7.3412196335629284e-06, 'numpy_to_tensor': 3.227702813967201e-05, 'agent_to_module_mapping': 4.293205829617416e-06, 'add_states_from_episodes_to_batch': 4.168047672485254e-06, 'add_observations_from_episodes_to_batch': 1.7427502828730538e-05}}, 'connector_pipeline_timer': 0.0001221980386927211}, 'weights_seq_no': 9.0, 'num_env_steps_sampled_lifetime': 46000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.213387799055088e-05, 'get_actions': 0.00013928691590890145, 'remove_single_ts_time_rank_from_batch': 2.05866387387293e-06, 'tensor_to_numpy': 5.17683828924636e-05, 'module_to_agent_unmapping': 3.8035732053542254e-06, 'listify_data_for_vector_env': 1.0199484329586404e-05, 'normalize_and_clip_actions': 5.694460542434966e-05}}, 'connector_pipeline_timer': 0.0003325372200152631}, 'env_to_module_sum_episodes_length_out': 129.6413995890854, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17493778049404426, 'num_module_steps_sampled_lifetime': {'servicer': 46000, 'target': 46000}, 'rlmodule_inference_timer': 0.00015965301095565354, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.00015225279919543682, 'env_to_module_sum_episodes_length_in': 129.6413995890854, 'time_between_sampling': 2.610529611353101, 'num_env_steps_sampled_lifetime_throughput': 1000.3512829227344}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.027618396854828024, 'agent_to_module_mapping': 0.003841427761203994, 'add_states_from_episodes_to_batch': 5.162029180785671e-06, 'add_one_ts_to_episodes_and_truncate': 0.005464134586195074, 'add_columns_from_episodes_to_train_batch': 0.07681877908776562, 'add_observations_from_episodes_to_batch': 0.00021244052160362555, 'batch_individual_items': 0.07066397565706328, 'add_time_dim_to_batch_and_zero_pad': 1.918736826241335e-05, 'numpy_to_tensor': 0.00015261959930704073}}, 'connector_pipeline_timer': 0.18498739933869512}, 'num_module_steps_trained_lifetime': 926720, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 16652000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 10.176054000854492, 'gradients_default_optimizer_global_norm': 3.822777509689331, 'vf_loss': 4.351120423962129e-06, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 463360, 'policy_loss': -0.15323404967784882, 'vf_loss_unclipped': 4.351120423962129e-06, 'total_loss': -0.356444776058197, 'weights_seq_no': 10.0, 'curr_kl_coeff': 0.05000000074505806, 'vf_explained_var': -0.8127918243408203, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.0061195348389446735}, 'servicer': {'num_module_steps_trained_lifetime': 463360, 'vf_loss': 4.924875736236572, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': -0.10712987929582596, 'vf_loss_unclipped': 42548.75390625, 'total_loss': 4.669014930725098, 'weights_seq_no': 10.0, 'curr_kl_coeff': 0.012500000186264515, 'vf_explained_var': 3.236532211303711e-05, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.004645331297069788, 'entropy': 7.442348480224609, 'gradients_default_optimizer_global_norm': 3.837287187576294}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 46000, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 50000, 'servicer': 50000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.0200379963768688e-05, 'add_time_dim_to_batch_and_zero_pad': 3.529657171931644e-06, 'numpy_to_tensor': 1.593664224208509e-05, 'agent_to_module_mapping': 2.434390885857085e-06, 'add_states_from_episodes_to_batch': 2.6157265098148966e-06, 'add_observations_from_episodes_to_batch': 9.113805738727374e-06}}, 'connector_pipeline_timer': 6.642967517892732e-05}, 'episode_return_min': -90262.75858117791, 'weights_seq_no': 9.0, 'num_env_steps_sampled_lifetime': 50000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90262.75858117791, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3072742817150593e-05, 'get_actions': 2.820288184693651e-05, 'remove_single_ts_time_rank_from_batch': 6.741096554211984e-07, 'tensor_to_numpy': 2.8687905883076924e-05, 'module_to_agent_unmapping': 2.183975369392996e-06, 'listify_data_for_vector_env': 6.025173926637661e-06, 'normalize_and_clip_actions': 3.092356656519193e-05}}, 'connector_pipeline_timer': 0.00013667196736714471}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3791999663226306e-05, 'numpy_to_tensor': 3.091699909418821e-05, 'agent_to_module_mapping': 5.207999492995441e-06, 'add_states_from_episodes_to_batch': 4.749992513097823e-06, 'add_observations_from_episodes_to_batch': 3.783300053328276e-05, 'batch_individual_items': 2.4999986635521054e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90262.75858117791, 'sample': 25.90940658301406, 'agent_episode_returns_mean': {'servicer': -90262.30288242361, 'target': -0.4556987543046452}, 'module_episode_returns_mean': {'servicer': -90262.30288242361, 'target': -0.4556987543046452}, 'num_module_steps_sampled_lifetime': {'servicer': 50000, 'target': 50000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.635449014461468e-05, 'connector_pipeline_timer': 0.000243417001911439, 'env_reset_timer': 0.00015233299927785993, 'episode_len_mean': 10000.0, 'env_step_timer': 8.793739059950074e-05, 'episode_duration_sec_mean': 4.99405236679595, 'num_episodes_lifetime': 5, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1000.3512829227344, 'done': False, 'training_iteration': 10, 'trial_id': 'default', 'date': '2025-04-03_22-31-44', 'timestamp': 1743733904, 'time_this_iter_s': 26.14642310142517, 'time_total_s': 51.89614796638489, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 51.89614796638489, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 24.889189189189185, 'ram_util_percent': 52.716216216216225}}
2025-04-03 22:31:47,535 [__main__] [INFO] Iter: 11/100, Ts(iter): 0, Ts(total): 50600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.85s
2025-04-03 22:31:50,328 [__main__] [INFO] Iter: 12/100, Ts(iter): 0, Ts(total): 55200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.79s
2025-04-03 22:31:53,394 [__main__] [INFO] Iter: 13/100, Ts(iter): 0, Ts(total): 59800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.07s
2025-04-03 22:31:56,424 [__main__] [INFO] Iter: 14/100, Ts(iter): 0, Ts(total): 64400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.03s
2025-04-03 22:31:59,292 [__main__] [INFO] Iter: 15/100, Ts(iter): 0, Ts(total): 69000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.87s
2025-04-03 22:32:02,388 [__main__] [INFO] Iter: 16/100, Ts(iter): 0, Ts(total): 73600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.10s
2025-04-03 22:32:05,381 [__main__] [INFO] Iter: 17/100, Ts(iter): 0, Ts(total): 78200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.99s
2025-04-03 22:32:08,437 [__main__] [INFO] Iter: 18/100, Ts(iter): 0, Ts(total): 82800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.06s
2025-04-03 22:32:11,440 [__main__] [INFO] Iter: 19/100, Ts(iter): 0, Ts(total): 87400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.00s
2025-04-03 22:32:37,278 [__main__] [INFO] Iter: 20/100, Ts(iter): 0, Ts(total): 92000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 25.84s
2025-04-03 22:32:37,278 [__main__] [DEBUG] Full result dict at iter 20: {'timers': {'training_iteration': 2.819851443981878, 'restore_env_runners': 1.8057251793141855e-05, 'training_step': 2.8197232979731273, 'env_runner_sampling_timer': 0.2854007905513484, 'learner_update_timer': 2.5277382703607176, 'synch_weights': 0.005394429361520944, 'synch_env_connectors': 0.00707480240157952, 'restore_eval_env_runners': 5.371247243601829e-06, 'evaluation_iteration': 26.138326125001186, 'synch_eval_env_connectors': 0.0018805799973779357}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 92000, 'servicer': 92000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.7771107405852773e-05, 'add_time_dim_to_batch_and_zero_pad': 6.682133632736491e-06, 'numpy_to_tensor': 3.0184269217946473e-05, 'agent_to_module_mapping': 4.341886464669179e-06, 'add_states_from_episodes_to_batch': 4.1239605721246624e-06, 'add_observations_from_episodes_to_batch': 1.6046407238976507e-05}}, 'connector_pipeline_timer': 0.00011474516098776659}, 'weights_seq_no': 19.0, 'num_env_steps_sampled_lifetime': 92000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.121150996563566e-05, 'get_actions': 0.00012816779499567833, 'remove_single_ts_time_rank_from_batch': 1.2219659209608464e-06, 'tensor_to_numpy': 4.808115736541818e-05, 'module_to_agent_unmapping': 3.6209393887705303e-06, 'listify_data_for_vector_env': 9.691567407588882e-06, 'normalize_and_clip_actions': 5.395162149450191e-05}}, 'connector_pipeline_timer': 0.0003097850187170415}, 'env_to_module_sum_episodes_length_out': 131.71351472764167, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.1761035337152318, 'num_module_steps_sampled_lifetime': {'servicer': 92000, 'target': 92000}, 'rlmodule_inference_timer': 0.00014592159133668437, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.00014571803575825994, 'env_to_module_sum_episodes_length_in': 131.71351472764167, 'time_between_sampling': 2.818269871532329, 'num_env_steps_sampled_lifetime_throughput': 989.5369286443378}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.027464154782025522, 'agent_to_module_mapping': 0.0038432422589475654, 'add_states_from_episodes_to_batch': 5.146814623347871e-06, 'add_one_ts_to_episodes_and_truncate': 0.00546118577813398, 'add_columns_from_episodes_to_train_batch': 0.07684532778320403, 'add_observations_from_episodes_to_batch': 0.0002125483189429298, 'batch_individual_items': 0.07102110403229399, 'add_time_dim_to_batch_and_zero_pad': 1.9123821779722294e-05, 'numpy_to_tensor': 0.00015245605288654863}}, 'connector_pipeline_timer': 0.18521456656729113}, 'num_module_steps_trained_lifetime': 1853440, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 33304000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 10.89738941192627, 'gradients_default_optimizer_global_norm': 3.613515853881836, 'vf_loss': 1.9446079022600316e-05, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 926720, 'policy_loss': -0.100058414041996, 'vf_loss_unclipped': 1.9446079022600316e-05, 'total_loss': -0.31793513894081116, 'weights_seq_no': 20.0, 'curr_kl_coeff': 0.0062500000931322575, 'vf_explained_var': -1.0, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.00412660650908947}, 'servicer': {'num_module_steps_trained_lifetime': 926720, 'vf_loss': 5.0, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': -0.06795729696750641, 'vf_loss_unclipped': 45237.95703125, 'total_loss': 4.777377605438232, 'weights_seq_no': 20.0, 'curr_kl_coeff': 0.0015625000232830644, 'vf_explained_var': -2.4437904357910156e-05, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.00565106887370348, 'entropy': 7.733688831329346, 'gradients_default_optimizer_global_norm': 4.617672443389893}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 100000, 'servicer': 100000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.0202142496526375e-05, 'add_time_dim_to_batch_and_zero_pad': 3.5312203974776562e-06, 'numpy_to_tensor': 1.5941227418664143e-05, 'agent_to_module_mapping': 2.4348761210875195e-06, 'add_states_from_episodes_to_batch': 2.616078739962213e-06, 'add_observations_from_episodes_to_batch': 9.114514908972239e-06}}, 'connector_pipeline_timer': 6.644207235178462e-05}, 'episode_return_min': -90386.3428525892, 'weights_seq_no': 19.0, 'num_env_steps_sampled_lifetime': 100000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90262.75858117791, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3073234334326056e-05, 'get_actions': 2.821003509794412e-05, 'remove_single_ts_time_rank_from_batch': 6.745636974283515e-07, 'tensor_to_numpy': 2.8689985376539424e-05, 'module_to_agent_unmapping': 2.184710697442229e-06, 'listify_data_for_vector_env': 6.026409572336151e-06, 'normalize_and_clip_actions': 3.0923904086076804e-05}}, 'connector_pipeline_timer': 0.00013669040571535605}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3791595463408156e-05, 'numpy_to_tensor': 3.0918903193378355e-05, 'agent_to_module_mapping': 5.2080286928685385e-06, 'add_states_from_episodes_to_batch': 4.749905013886746e-06, 'add_observations_from_episodes_to_batch': 3.78314922330901e-05, 'batch_individual_items': 2.5000169937266036e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90303.95333831501, 'sample': 25.90937812464746, 'agent_episode_returns_mean': {'servicer': -90303.4818206299, 'target': -0.471517685111362}, 'module_episode_returns_mean': {'servicer': -90303.4818206299, 'target': -0.471517685111362}, 'num_module_steps_sampled_lifetime': {'servicer': 100000, 'target': 100000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.637256665311957e-05, 'connector_pipeline_timer': 0.00024340885611163685, 'env_reset_timer': 0.0001523302243775106, 'episode_len_mean': 10000.0, 'env_step_timer': 8.795782725049716e-05, 'episode_duration_sec_mean': 4.981545641797129, 'num_episodes_lifetime': 10, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.8998452649664, 'time_between_sampling': 26.97176520799985}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 92000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 989.5369286443378, 'done': False, 'training_iteration': 20, 'trial_id': 'default', 'date': '2025-04-03_22-32-37', 'timestamp': 1743733957, 'time_this_iter_s': 25.82791781425476, 'time_total_s': 104.36743211746216, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 104.36743211746216, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 25.35675675675676, 'ram_util_percent': 52.79729729729729}}
2025-04-03 22:32:37,294 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.819851443981878, 'restore_env_runners': 1.8057251793141855e-05, 'training_step': 2.8197232979731273, 'env_runner_sampling_timer': 0.2854007905513484, 'learner_update_timer': 2.5277382703607176, 'synch_weights': 0.005394429361520944, 'synch_env_connectors': 0.00707480240157952, 'restore_eval_env_runners': 5.371247243601829e-06, 'evaluation_iteration': 26.138326125001186, 'synch_eval_env_connectors': 0.0018805799973779357}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 92000, 'servicer': 92000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.7771107405852773e-05, 'add_time_dim_to_batch_and_zero_pad': 6.682133632736491e-06, 'numpy_to_tensor': 3.0184269217946473e-05, 'agent_to_module_mapping': 4.341886464669179e-06, 'add_states_from_episodes_to_batch': 4.1239605721246624e-06, 'add_observations_from_episodes_to_batch': 1.6046407238976507e-05}}, 'connector_pipeline_timer': 0.00011474516098776659}, 'weights_seq_no': 19.0, 'num_env_steps_sampled_lifetime': 92000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.121150996563566e-05, 'get_actions': 0.00012816779499567833, 'remove_single_ts_time_rank_from_batch': 1.2219659209608464e-06, 'tensor_to_numpy': 4.808115736541818e-05, 'module_to_agent_unmapping': 3.6209393887705303e-06, 'listify_data_for_vector_env': 9.691567407588882e-06, 'normalize_and_clip_actions': 5.395162149450191e-05}}, 'connector_pipeline_timer': 0.0003097850187170415}, 'env_to_module_sum_episodes_length_out': 131.71351472764167, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.1761035337152318, 'num_module_steps_sampled_lifetime': {'servicer': 92000, 'target': 92000}, 'rlmodule_inference_timer': 0.00014592159133668437, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.00014571803575825994, 'env_to_module_sum_episodes_length_in': 131.71351472764167, 'time_between_sampling': 2.818269871532329, 'num_env_steps_sampled_lifetime_throughput': 989.5369286443378}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.027464154782025522, 'agent_to_module_mapping': 0.0038432422589475654, 'add_states_from_episodes_to_batch': 5.146814623347871e-06, 'add_one_ts_to_episodes_and_truncate': 0.00546118577813398, 'add_columns_from_episodes_to_train_batch': 0.07684532778320403, 'add_observations_from_episodes_to_batch': 0.0002125483189429298, 'batch_individual_items': 0.07102110403229399, 'add_time_dim_to_batch_and_zero_pad': 1.9123821779722294e-05, 'numpy_to_tensor': 0.00015245605288654863}}, 'connector_pipeline_timer': 0.18521456656729113}, 'num_module_steps_trained_lifetime': 1853440, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 33304000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 10.89738941192627, 'gradients_default_optimizer_global_norm': 3.613515853881836, 'vf_loss': 1.9446079022600316e-05, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 926720, 'policy_loss': -0.100058414041996, 'vf_loss_unclipped': 1.9446079022600316e-05, 'total_loss': -0.31793513894081116, 'weights_seq_no': 20.0, 'curr_kl_coeff': 0.0062500000931322575, 'vf_explained_var': -1.0, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.00412660650908947}, 'servicer': {'num_module_steps_trained_lifetime': 926720, 'vf_loss': 5.0, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': -0.06795729696750641, 'vf_loss_unclipped': 45237.95703125, 'total_loss': 4.777377605438232, 'weights_seq_no': 20.0, 'curr_kl_coeff': 0.0015625000232830644, 'vf_explained_var': -2.4437904357910156e-05, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.00565106887370348, 'entropy': 7.733688831329346, 'gradients_default_optimizer_global_norm': 4.617672443389893}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 100000, 'servicer': 100000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.0202142496526375e-05, 'add_time_dim_to_batch_and_zero_pad': 3.5312203974776562e-06, 'numpy_to_tensor': 1.5941227418664143e-05, 'agent_to_module_mapping': 2.4348761210875195e-06, 'add_states_from_episodes_to_batch': 2.616078739962213e-06, 'add_observations_from_episodes_to_batch': 9.114514908972239e-06}}, 'connector_pipeline_timer': 6.644207235178462e-05}, 'episode_return_min': -90386.3428525892, 'weights_seq_no': 19.0, 'num_env_steps_sampled_lifetime': 100000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90262.75858117791, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3073234334326056e-05, 'get_actions': 2.821003509794412e-05, 'remove_single_ts_time_rank_from_batch': 6.745636974283515e-07, 'tensor_to_numpy': 2.8689985376539424e-05, 'module_to_agent_unmapping': 2.184710697442229e-06, 'listify_data_for_vector_env': 6.026409572336151e-06, 'normalize_and_clip_actions': 3.0923904086076804e-05}}, 'connector_pipeline_timer': 0.00013669040571535605}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3791595463408156e-05, 'numpy_to_tensor': 3.0918903193378355e-05, 'agent_to_module_mapping': 5.2080286928685385e-06, 'add_states_from_episodes_to_batch': 4.749905013886746e-06, 'add_observations_from_episodes_to_batch': 3.78314922330901e-05, 'batch_individual_items': 2.5000169937266036e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90303.95333831501, 'sample': 25.90937812464746, 'agent_episode_returns_mean': {'servicer': -90303.4818206299, 'target': -0.471517685111362}, 'module_episode_returns_mean': {'servicer': -90303.4818206299, 'target': -0.471517685111362}, 'num_module_steps_sampled_lifetime': {'servicer': 100000, 'target': 100000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.637256665311957e-05, 'connector_pipeline_timer': 0.00024340885611163685, 'env_reset_timer': 0.0001523302243775106, 'episode_len_mean': 10000.0, 'env_step_timer': 8.795782725049716e-05, 'episode_duration_sec_mean': 4.981545641797129, 'num_episodes_lifetime': 10, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.8998452649664, 'time_between_sampling': 26.97176520799985}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 92000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 989.5369286443378, 'done': False, 'training_iteration': 20, 'trial_id': 'default', 'date': '2025-04-03_22-32-37', 'timestamp': 1743733957, 'time_this_iter_s': 25.82791781425476, 'time_total_s': 104.36743211746216, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 104.36743211746216, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 25.35675675675676, 'ram_util_percent': 52.79729729729729}})
2025-04-03 22:32:40,066 [__main__] [INFO] Iter: 21/100, Ts(iter): 0, Ts(total): 96600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.77s
2025-04-03 22:32:42,959 [__main__] [INFO] Iter: 22/100, Ts(iter): 0, Ts(total): 101200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.89s
2025-04-03 22:32:46,006 [__main__] [INFO] Iter: 23/100, Ts(iter): 0, Ts(total): 105800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.05s
2025-04-03 22:32:48,901 [__main__] [INFO] Iter: 24/100, Ts(iter): 0, Ts(total): 110400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.90s
2025-04-03 22:32:51,877 [__main__] [INFO] Iter: 25/100, Ts(iter): 0, Ts(total): 115000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.98s
2025-04-03 22:32:54,686 [__main__] [INFO] Iter: 26/100, Ts(iter): 0, Ts(total): 119600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.81s
2025-04-03 22:32:57,627 [__main__] [INFO] Iter: 27/100, Ts(iter): 0, Ts(total): 124200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.94s
2025-04-03 22:33:00,439 [__main__] [INFO] Iter: 28/100, Ts(iter): 0, Ts(total): 128800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.81s
2025-04-03 22:33:03,611 [__main__] [INFO] Iter: 29/100, Ts(iter): 0, Ts(total): 133400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.17s
2025-04-03 22:33:29,535 [__main__] [INFO] Iter: 30/100, Ts(iter): 0, Ts(total): 138000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 25.92s
2025-04-03 22:33:29,536 [__main__] [DEBUG] Full result dict at iter 30: {'timers': {'training_iteration': 2.8422285919960704, 'restore_env_runners': 1.704567207143451e-05, 'training_step': 2.8421003396084354, 'env_runner_sampling_timer': 0.27916047469351796, 'learner_update_timer': 2.556363403092398, 'synch_weights': 0.005341460087831381, 'synch_env_connectors': 0.007081252433813933, 'restore_eval_env_runners': 5.368374797399156e-06, 'evaluation_iteration': 26.135147934581184, 'synch_eval_env_connectors': 0.001876975867289002}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 138000, 'servicer': 138000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.6765945277178018e-05, 'add_time_dim_to_batch_and_zero_pad': 6.408615391166226e-06, 'numpy_to_tensor': 2.8231648446624387e-05, 'agent_to_module_mapping': 4.153188701184565e-06, 'add_states_from_episodes_to_batch': 3.957943053501868e-06, 'add_observations_from_episodes_to_batch': 1.555484092286628e-05}}, 'connector_pipeline_timer': 0.00010940878126605214}, 'weights_seq_no': 29.0, 'num_env_steps_sampled_lifetime': 138000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.0345951760282307e-05, 'get_actions': 0.00012395929514929304, 'remove_single_ts_time_rank_from_batch': 1.14462328508641e-06, 'tensor_to_numpy': 4.5863074133904207e-05, 'module_to_agent_unmapping': 3.5174846344736864e-06, 'listify_data_for_vector_env': 9.475530276854596e-06, 'normalize_and_clip_actions': 5.1239675986023954e-05}}, 'connector_pipeline_timer': 0.00029800492716509263}, 'env_to_module_sum_episodes_length_out': 131.9188713172039, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17638522433130915, 'num_module_steps_sampled_lifetime': {'servicer': 138000, 'target': 138000}, 'rlmodule_inference_timer': 0.0001413630117602697, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.0001409265990291165, 'env_to_module_sum_episodes_length_in': 131.9188713172039, 'time_between_sampling': 3.0256898617610593, 'num_env_steps_sampled_lifetime_throughput': 1052.4685103898285}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.027223475152574835, 'agent_to_module_mapping': 0.0038460700472366825, 'add_states_from_episodes_to_batch': 5.124685464706082e-06, 'add_one_ts_to_episodes_and_truncate': 0.005455665281612525, 'add_columns_from_episodes_to_train_batch': 0.07688157361498935, 'add_observations_from_episodes_to_batch': 0.0002126567146229651, 'batch_individual_items': 0.07151388534321419, 'add_time_dim_to_batch_and_zero_pad': 1.9032358982339016e-05, 'numpy_to_tensor': 0.00015209089243516826}}, 'connector_pipeline_timer': 0.18549822903002466}, 'num_module_steps_trained_lifetime': 2780160, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 49956000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 10.855626106262207, 'gradients_default_optimizer_global_norm': 4.234655380249023, 'vf_loss': 6.639528237428749e-06, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 1390080, 'policy_loss': 0.08674827218055725, 'vf_loss_unclipped': 6.639528237428749e-06, 'total_loss': -0.13033419847488403, 'weights_seq_no': 30.0, 'curr_kl_coeff': 0.0031250000465661287, 'vf_explained_var': -1.0, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.007490175310522318}, 'servicer': {'num_module_steps_trained_lifetime': 1390080, 'vf_loss': 4.960629940032959, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': 0.004098986275494099, 'vf_loss_unclipped': 46783.10546875, 'total_loss': 4.795365333557129, 'weights_seq_no': 30.0, 'curr_kl_coeff': 4.882812572759576e-05, 'vf_explained_var': 0.0001684427261352539, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.004898624494671822, 'entropy': 8.468186378479004, 'gradients_default_optimizer_global_norm': 5.059436321258545}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 150000, 'servicer': 150000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.0208460325980643e-05, 'add_time_dim_to_batch_and_zero_pad': 3.5331570742117475e-06, 'numpy_to_tensor': 1.5954308139001003e-05, 'agent_to_module_mapping': 2.4392312459814724e-06, 'add_states_from_episodes_to_batch': 2.61701452095587e-06, 'add_observations_from_episodes_to_batch': 9.125813040479791e-06}}, 'connector_pipeline_timer': 6.649216535990787e-05}, 'episode_return_min': -90396.28279005623, 'weights_seq_no': 29.0, 'num_env_steps_sampled_lifetime': 150000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90262.75858117791, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3077441361120146e-05, 'get_actions': 2.8227027472770413e-05, 'remove_single_ts_time_rank_from_batch': 6.748124321750993e-07, 'tensor_to_numpy': 2.870008363235346e-05, 'module_to_agent_unmapping': 2.185179318196198e-06, 'listify_data_for_vector_env': 6.028615050609179e-06, 'normalize_and_clip_actions': 3.092920390850892e-05}}, 'connector_pipeline_timer': 0.0001367409475353067}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3790786847355774e-05, 'numpy_to_tensor': 3.092177331019775e-05, 'agent_to_module_mapping': 5.207953208708204e-06, 'add_states_from_episodes_to_batch': 4.749673466110836e-06, 'add_observations_from_episodes_to_batch': 3.782843079813756e-05, 'batch_individual_items': 2.4999941174930427e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90326.2073731281, 'sample': 25.90932964828569, 'agent_episode_returns_mean': {'servicer': -90325.71833326208, 'target': -0.4890398659537219}, 'module_episode_returns_mean': {'servicer': -90325.71833326208, 'target': -0.4890398659537219}, 'num_module_steps_sampled_lifetime': {'servicer': 150000, 'target': 150000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.641916714309605e-05, 'connector_pipeline_timer': 0.00024339048572731553, 'env_reset_timer': 0.00015232417997604352, 'episode_len_mean': 10000.0, 'env_step_timer': 8.799212175327865e-05, 'episode_duration_sec_mean': 4.974541293131187, 'num_episodes_lifetime': 15, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.9021714656742, 'time_between_sampling': 26.971723451479054}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 138000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1052.4685103898285, 'done': False, 'training_iteration': 30, 'trial_id': 'default', 'date': '2025-04-03_22-33-29', 'timestamp': 1743734009, 'time_this_iter_s': 25.914005041122437, 'time_total_s': 156.49028491973877, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 156.49028491973877, 'iterations_since_restore': 30, 'perf': {'cpu_util_percent': 25.13783783783784, 'ram_util_percent': 52.87567567567568}}
2025-04-03 22:33:32,167 [__main__] [INFO] Iter: 31/100, Ts(iter): 0, Ts(total): 142600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.63s
2025-04-03 22:33:35,145 [__main__] [INFO] Iter: 32/100, Ts(iter): 0, Ts(total): 147200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.98s
2025-04-03 22:33:37,669 [__main__] [INFO] Iter: 33/100, Ts(iter): 0, Ts(total): 151800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.52s
2025-04-03 22:33:40,621 [__main__] [INFO] Iter: 34/100, Ts(iter): 0, Ts(total): 156400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.95s
2025-04-03 22:33:43,563 [__main__] [INFO] Iter: 35/100, Ts(iter): 0, Ts(total): 161000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.94s
2025-04-03 22:33:46,555 [__main__] [INFO] Iter: 36/100, Ts(iter): 0, Ts(total): 165600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.99s
2025-04-03 22:33:49,513 [__main__] [INFO] Iter: 37/100, Ts(iter): 0, Ts(total): 170200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.96s
2025-04-03 22:33:52,613 [__main__] [INFO] Iter: 38/100, Ts(iter): 0, Ts(total): 174800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.10s
2025-04-03 22:33:55,522 [__main__] [INFO] Iter: 39/100, Ts(iter): 0, Ts(total): 179400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.91s
2025-04-03 22:34:21,473 [__main__] [INFO] Iter: 40/100, Ts(iter): 0, Ts(total): 184000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 25.95s
2025-04-03 22:34:21,474 [__main__] [DEBUG] Full result dict at iter 40: {'timers': {'training_iteration': 2.8621210976677394, 'restore_env_runners': 1.624108505366194e-05, 'training_step': 2.8619921505028127, 'env_runner_sampling_timer': 0.2736527304066046, 'learner_update_timer': 2.5817585705806154, 'synch_weights': 0.005313731135388099, 'synch_env_connectors': 0.007115512038307815, 'restore_eval_env_runners': 5.404281079681823e-06, 'evaluation_iteration': 26.132861755655416, 'synch_eval_env_connectors': 0.0018697052786845307}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 184000, 'servicer': 184000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.7580910141219576e-05, 'add_time_dim_to_batch_and_zero_pad': 6.498898756642342e-06, 'numpy_to_tensor': 2.906816320819944e-05, 'agent_to_module_mapping': 4.2391891762717186e-06, 'add_states_from_episodes_to_batch': 4.058873925405823e-06, 'add_observations_from_episodes_to_batch': 1.6283689706565365e-05}}, 'connector_pipeline_timer': 0.00011345732718534923}, 'weights_seq_no': 39.0, 'num_env_steps_sampled_lifetime': 184000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.1389332260958254e-05, 'get_actions': 0.00012754094867016306, 'remove_single_ts_time_rank_from_batch': 1.1844848936133586e-06, 'tensor_to_numpy': 4.732254390328695e-05, 'module_to_agent_unmapping': 3.648225591198824e-06, 'listify_data_for_vector_env': 9.490114795123979e-06, 'normalize_and_clip_actions': 5.186188708010664e-05}}, 'connector_pipeline_timer': 0.0003059251284204026}, 'env_to_module_sum_episodes_length_out': 131.93922314412805, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17665850857735893, 'num_module_steps_sampled_lifetime': {'servicer': 184000, 'target': 184000}, 'rlmodule_inference_timer': 0.0001439982624400786, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.00014450469681552376, 'env_to_module_sum_episodes_length_in': 131.93922314412805, 'time_between_sampling': 3.212196820448886, 'num_env_steps_sampled_lifetime_throughput': 989.4860475713515}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.026913759216097274, 'agent_to_module_mapping': 0.003849942866287223, 'add_states_from_episodes_to_batch': 5.096512796390919e-06, 'add_one_ts_to_episodes_and_truncate': 0.005449726288433201, 'add_columns_from_episodes_to_train_batch': 0.07693546990900316, 'add_observations_from_episodes_to_batch': 0.00021278368905227056, 'batch_individual_items': 0.07216840429818369, 'add_time_dim_to_batch_and_zero_pad': 1.892184003604239e-05, 'numpy_to_tensor': 0.00015158485167435457}}, 'connector_pipeline_timer': 0.18589230143540303}, 'num_module_steps_trained_lifetime': 3706880, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 66608000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 12.557683944702148, 'gradients_default_optimizer_global_norm': 5.264414310455322, 'vf_loss': 2.260525980091188e-05, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 1853440, 'policy_loss': -0.08437012881040573, 'vf_loss_unclipped': 2.260525980091188e-05, 'total_loss': -0.33546188473701477, 'weights_seq_no': 40.0, 'curr_kl_coeff': 0.0031250000465661287, 'vf_explained_var': -1.0, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.012585963122546673}, 'servicer': {'num_module_steps_trained_lifetime': 1853440, 'vf_loss': 4.960317611694336, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': 0.03195161744952202, 'vf_loss_unclipped': 47316.93359375, 'total_loss': 4.821905612945557, 'weights_seq_no': 40.0, 'curr_kl_coeff': 7.629394644936838e-07, 'vf_explained_var': -9.012222290039062e-05, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.0036794226616621017, 'entropy': 8.51816463470459, 'gradients_default_optimizer_global_norm': 3.827544689178467}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 200000, 'servicer': 200000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.021733112079044e-05, 'add_time_dim_to_batch_and_zero_pad': 3.540278824325335e-06, 'numpy_to_tensor': 1.597253048470875e-05, 'agent_to_module_mapping': 2.441548365249982e-06, 'add_states_from_episodes_to_batch': 2.6183151927136185e-06, 'add_observations_from_episodes_to_batch': 9.140985856432438e-06}}, 'connector_pipeline_timer': 6.656296286393724e-05}, 'episode_return_min': -90401.70479021194, 'weights_seq_no': 39.0, 'num_env_steps_sampled_lifetime': 200000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90262.75858117791, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3083476930389899e-05, 'get_actions': 2.8265186573883443e-05, 'remove_single_ts_time_rank_from_batch': 6.756300792408914e-07, 'tensor_to_numpy': 2.871695881414876e-05, 'module_to_agent_unmapping': 2.186988791817897e-06, 'listify_data_for_vector_env': 6.032501629067285e-06, 'normalize_and_clip_actions': 3.095411300656273e-05}}, 'connector_pipeline_timer': 0.00013684632033698048}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3789669444480093e-05, 'numpy_to_tensor': 3.0925710735152975e-05, 'agent_to_module_mapping': 5.2077917306448206e-06, 'add_states_from_episodes_to_batch': 4.749304858765827e-06, 'add_observations_from_episodes_to_batch': 3.782405154274776e-05, 'batch_individual_items': 2.4999362871937335e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90340.43332528036, 'sample': 25.909261552567795, 'agent_episode_returns_mean': {'servicer': -90339.92932282097, 'target': -0.5040024593871819}, 'module_episode_returns_mean': {'servicer': -90339.92932282097, 'target': -0.5040024593871819}, 'num_module_steps_sampled_lifetime': {'servicer': 200000, 'target': 200000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.651154594743294e-05, 'connector_pipeline_timer': 0.0002433626168661499, 'env_reset_timer': 0.00015231524844012295, 'episode_len_mean': 10000.0, 'env_step_timer': 8.805581399457278e-05, 'episode_duration_sec_mean': 4.969748079218261, 'num_episodes_lifetime': 20, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.906148068425, 'time_between_sampling': 26.97160862598037}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 184000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 989.4860475713515, 'done': False, 'training_iteration': 40, 'trial_id': 'default', 'date': '2025-04-03_22-34-21', 'timestamp': 1743734061, 'time_this_iter_s': 25.94062113761902, 'time_total_s': 208.3050332069397, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 208.3050332069397, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': 24.289189189189187, 'ram_util_percent': 52.910810810810815}}
2025-04-03 22:34:21,489 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.8621210976677394, 'restore_env_runners': 1.624108505366194e-05, 'training_step': 2.8619921505028127, 'env_runner_sampling_timer': 0.2736527304066046, 'learner_update_timer': 2.5817585705806154, 'synch_weights': 0.005313731135388099, 'synch_env_connectors': 0.007115512038307815, 'restore_eval_env_runners': 5.404281079681823e-06, 'evaluation_iteration': 26.132861755655416, 'synch_eval_env_connectors': 0.0018697052786845307}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 184000, 'servicer': 184000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.7580910141219576e-05, 'add_time_dim_to_batch_and_zero_pad': 6.498898756642342e-06, 'numpy_to_tensor': 2.906816320819944e-05, 'agent_to_module_mapping': 4.2391891762717186e-06, 'add_states_from_episodes_to_batch': 4.058873925405823e-06, 'add_observations_from_episodes_to_batch': 1.6283689706565365e-05}}, 'connector_pipeline_timer': 0.00011345732718534923}, 'weights_seq_no': 39.0, 'num_env_steps_sampled_lifetime': 184000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.1389332260958254e-05, 'get_actions': 0.00012754094867016306, 'remove_single_ts_time_rank_from_batch': 1.1844848936133586e-06, 'tensor_to_numpy': 4.732254390328695e-05, 'module_to_agent_unmapping': 3.648225591198824e-06, 'listify_data_for_vector_env': 9.490114795123979e-06, 'normalize_and_clip_actions': 5.186188708010664e-05}}, 'connector_pipeline_timer': 0.0003059251284204026}, 'env_to_module_sum_episodes_length_out': 131.93922314412805, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17665850857735893, 'num_module_steps_sampled_lifetime': {'servicer': 184000, 'target': 184000}, 'rlmodule_inference_timer': 0.0001439982624400786, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.00014450469681552376, 'env_to_module_sum_episodes_length_in': 131.93922314412805, 'time_between_sampling': 3.212196820448886, 'num_env_steps_sampled_lifetime_throughput': 989.4860475713515}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.026913759216097274, 'agent_to_module_mapping': 0.003849942866287223, 'add_states_from_episodes_to_batch': 5.096512796390919e-06, 'add_one_ts_to_episodes_and_truncate': 0.005449726288433201, 'add_columns_from_episodes_to_train_batch': 0.07693546990900316, 'add_observations_from_episodes_to_batch': 0.00021278368905227056, 'batch_individual_items': 0.07216840429818369, 'add_time_dim_to_batch_and_zero_pad': 1.892184003604239e-05, 'numpy_to_tensor': 0.00015158485167435457}}, 'connector_pipeline_timer': 0.18589230143540303}, 'num_module_steps_trained_lifetime': 3706880, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 66608000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 12.557683944702148, 'gradients_default_optimizer_global_norm': 5.264414310455322, 'vf_loss': 2.260525980091188e-05, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 1853440, 'policy_loss': -0.08437012881040573, 'vf_loss_unclipped': 2.260525980091188e-05, 'total_loss': -0.33546188473701477, 'weights_seq_no': 40.0, 'curr_kl_coeff': 0.0031250000465661287, 'vf_explained_var': -1.0, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.012585963122546673}, 'servicer': {'num_module_steps_trained_lifetime': 1853440, 'vf_loss': 4.960317611694336, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': 0.03195161744952202, 'vf_loss_unclipped': 47316.93359375, 'total_loss': 4.821905612945557, 'weights_seq_no': 40.0, 'curr_kl_coeff': 7.629394644936838e-07, 'vf_explained_var': -9.012222290039062e-05, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.0036794226616621017, 'entropy': 8.51816463470459, 'gradients_default_optimizer_global_norm': 3.827544689178467}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 200000, 'servicer': 200000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.021733112079044e-05, 'add_time_dim_to_batch_and_zero_pad': 3.540278824325335e-06, 'numpy_to_tensor': 1.597253048470875e-05, 'agent_to_module_mapping': 2.441548365249982e-06, 'add_states_from_episodes_to_batch': 2.6183151927136185e-06, 'add_observations_from_episodes_to_batch': 9.140985856432438e-06}}, 'connector_pipeline_timer': 6.656296286393724e-05}, 'episode_return_min': -90401.70479021194, 'weights_seq_no': 39.0, 'num_env_steps_sampled_lifetime': 200000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90262.75858117791, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3083476930389899e-05, 'get_actions': 2.8265186573883443e-05, 'remove_single_ts_time_rank_from_batch': 6.756300792408914e-07, 'tensor_to_numpy': 2.871695881414876e-05, 'module_to_agent_unmapping': 2.186988791817897e-06, 'listify_data_for_vector_env': 6.032501629067285e-06, 'normalize_and_clip_actions': 3.095411300656273e-05}}, 'connector_pipeline_timer': 0.00013684632033698048}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3789669444480093e-05, 'numpy_to_tensor': 3.0925710735152975e-05, 'agent_to_module_mapping': 5.2077917306448206e-06, 'add_states_from_episodes_to_batch': 4.749304858765827e-06, 'add_observations_from_episodes_to_batch': 3.782405154274776e-05, 'batch_individual_items': 2.4999362871937335e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90340.43332528036, 'sample': 25.909261552567795, 'agent_episode_returns_mean': {'servicer': -90339.92932282097, 'target': -0.5040024593871819}, 'module_episode_returns_mean': {'servicer': -90339.92932282097, 'target': -0.5040024593871819}, 'num_module_steps_sampled_lifetime': {'servicer': 200000, 'target': 200000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.651154594743294e-05, 'connector_pipeline_timer': 0.0002433626168661499, 'env_reset_timer': 0.00015231524844012295, 'episode_len_mean': 10000.0, 'env_step_timer': 8.805581399457278e-05, 'episode_duration_sec_mean': 4.969748079218261, 'num_episodes_lifetime': 20, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.906148068425, 'time_between_sampling': 26.97160862598037}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 184000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 989.4860475713515, 'done': False, 'training_iteration': 40, 'trial_id': 'default', 'date': '2025-04-03_22-34-21', 'timestamp': 1743734061, 'time_this_iter_s': 25.94062113761902, 'time_total_s': 208.3050332069397, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 208.3050332069397, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': 24.289189189189187, 'ram_util_percent': 52.910810810810815}})
2025-04-03 22:34:24,270 [__main__] [INFO] Iter: 41/100, Ts(iter): 0, Ts(total): 188600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.78s
2025-04-03 22:34:27,293 [__main__] [INFO] Iter: 42/100, Ts(iter): 0, Ts(total): 193200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.02s
2025-04-03 22:34:30,263 [__main__] [INFO] Iter: 43/100, Ts(iter): 0, Ts(total): 197800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.97s
2025-04-03 22:34:33,288 [__main__] [INFO] Iter: 44/100, Ts(iter): 0, Ts(total): 202400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.02s
2025-04-03 22:34:36,091 [__main__] [INFO] Iter: 45/100, Ts(iter): 0, Ts(total): 207000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.80s
2025-04-03 22:34:39,146 [__main__] [INFO] Iter: 46/100, Ts(iter): 0, Ts(total): 211600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.05s
2025-04-03 22:34:42,094 [__main__] [INFO] Iter: 47/100, Ts(iter): 0, Ts(total): 216200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.95s
2025-04-03 22:34:45,095 [__main__] [INFO] Iter: 48/100, Ts(iter): 0, Ts(total): 220800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.00s
2025-04-03 22:34:48,152 [__main__] [INFO] Iter: 49/100, Ts(iter): 0, Ts(total): 225400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.06s
2025-04-03 22:35:13,979 [__main__] [INFO] Iter: 50/100, Ts(iter): 0, Ts(total): 230000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 25.83s
2025-04-03 22:35:13,979 [__main__] [DEBUG] Full result dict at iter 50: {'timers': {'training_iteration': 2.8858479486006448, 'restore_env_runners': 1.5541431563051804e-05, 'training_step': 2.885717621283288, 'env_runner_sampling_timer': 0.2705818544776129, 'learner_update_timer': 2.6085531505789277, 'synch_weights': 0.00529013543115199, 'synch_env_connectors': 0.007134211076935769, 'restore_eval_env_runners': 5.420658188096422e-06, 'evaluation_iteration': 26.13086194559885, 'synch_eval_env_connectors': 0.0018675969759019881}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 230000, 'servicer': 230000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.830937722474537e-05, 'add_time_dim_to_batch_and_zero_pad': 6.496576308222482e-06, 'numpy_to_tensor': 2.9235897424347377e-05, 'agent_to_module_mapping': 4.2155867207143715e-06, 'add_states_from_episodes_to_batch': 3.976474982215383e-06, 'add_observations_from_episodes_to_batch': 1.608384309971787e-05}}, 'connector_pipeline_timer': 0.00011391340117973859}, 'weights_seq_no': 49.0, 'num_env_steps_sampled_lifetime': 230000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.176882323063421e-05, 'get_actions': 0.00012880958281195695, 'remove_single_ts_time_rank_from_batch': 1.198812704571928e-06, 'tensor_to_numpy': 4.701015882249122e-05, 'module_to_agent_unmapping': 3.595630503735803e-06, 'listify_data_for_vector_env': 9.734661471586092e-06, 'normalize_and_clip_actions': 5.321752185522327e-05}}, 'connector_pipeline_timer': 0.0003091421609253886}, 'env_to_module_sum_episodes_length_out': 131.52846867546788, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17754035384671757, 'num_module_steps_sampled_lifetime': {'servicer': 230000, 'target': 230000}, 'rlmodule_inference_timer': 0.0001460888462740558, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.0001438833926091694, 'env_to_module_sum_episodes_length_in': 131.52846867546788, 'time_between_sampling': 3.3851944799176534, 'episode_return_min': -88740.47016086392, 'episode_return_max': -86471.61061003555, 'episode_len_max': 10000, 'episode_return_mean': -87538.92175166441, 'agent_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'module_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'episode_len_mean': 10000.0, 'episode_duration_sec_mean': 8.93253737207535, 'num_episodes_lifetime': 23, 'num_episodes': 23, 'num_env_steps_sampled_lifetime_throughput': 996.9227415740042}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.0265490111058781, 'agent_to_module_mapping': 0.003854875153214626, 'add_states_from_episodes_to_batch': 5.063709502717008e-06, 'add_one_ts_to_episodes_and_truncate': 0.005444506943191531, 'add_columns_from_episodes_to_train_batch': 0.07699876901984015, 'add_observations_from_episodes_to_batch': 0.0002142896498757121, 'batch_individual_items': 0.0729057570221532, 'add_time_dim_to_batch_and_zero_pad': 1.879506220505204e-05, 'numpy_to_tensor': 0.00015100376000123589}}, 'connector_pipeline_timer': 0.18632646418713786}, 'num_module_steps_trained_lifetime': 4633600, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 83260000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 12.588769912719727, 'gradients_default_optimizer_global_norm': 4.307939529418945, 'vf_loss': 1.6291327483486384e-05, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 2316800, 'policy_loss': 0.06585773825645447, 'vf_loss_unclipped': 1.6291327483486384e-05, 'total_loss': -0.1858779489994049, 'weights_seq_no': 50.0, 'curr_kl_coeff': 0.0031250000465661287, 'vf_explained_var': -1.0, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.007497875485569239}, 'servicer': {'num_module_steps_trained_lifetime': 2316800, 'vf_loss': 5.0, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': 0.11484507471323013, 'vf_loss_unclipped': 48182.69140625, 'total_loss': 4.9328718185424805, 'weights_seq_no': 50.0, 'curr_kl_coeff': 2.3841858265427618e-08, 'vf_explained_var': 7.092952728271484e-06, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.006399135105311871, 'entropy': 9.098655700683594, 'gradients_default_optimizer_global_norm': 3.9258360862731934}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 250000, 'servicer': 250000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.0218823771631352e-05, 'add_time_dim_to_batch_and_zero_pad': 3.5405092035060567e-06, 'numpy_to_tensor': 1.597396525362586e-05, 'agent_to_module_mapping': 2.441509912116971e-06, 'add_states_from_episodes_to_batch': 2.618414145716633e-06, 'add_observations_from_episodes_to_batch': 9.142673970681749e-06}}, 'connector_pipeline_timer': 6.657118568542115e-05}, 'episode_return_min': -90401.70479021194, 'weights_seq_no': 49.0, 'num_env_steps_sampled_lifetime': 250000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90262.75858117791, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3082469992403407e-05, 'get_actions': 2.826736241135934e-05, 'remove_single_ts_time_rank_from_batch': 6.75642121104301e-07, 'tensor_to_numpy': 2.8718635950135165e-05, 'module_to_agent_unmapping': 2.18656512515326e-06, 'listify_data_for_vector_env': 6.031999311042327e-06, 'normalize_and_clip_actions': 3.094614476736951e-05}}, 'connector_pipeline_timer': 0.0001368389230719496}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3788011910617721e-05, 'numpy_to_tensor': 3.092962723352547e-05, 'agent_to_module_mapping': 5.207495985724142e-06, 'add_states_from_episodes_to_batch': 4.748822855658533e-06, 'add_observations_from_episodes_to_batch': 3.7818156129214886e-05, 'batch_individual_items': 2.499823364108778e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90345.11879755992, 'sample': 25.909163032070325, 'agent_episode_returns_mean': {'servicer': -90344.60689268223, 'target': -0.5119048777091492}, 'module_episode_returns_mean': {'servicer': -90344.60689268223, 'target': -0.5119048777091492}, 'num_module_steps_sampled_lifetime': {'servicer': 250000, 'target': 250000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.651861062108054e-05, 'connector_pipeline_timer': 0.00024332358723445067, 'env_reset_timer': 0.00015230334221646565, 'episode_len_mean': 10000.0, 'env_step_timer': 8.805161727207092e-05, 'episode_duration_sec_mean': 4.965835755572189, 'num_episodes_lifetime': 25, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.911549164633, 'time_between_sampling': 26.97149029237561}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 230000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 996.9227415740042, 'done': False, 'training_iteration': 50, 'trial_id': 'default', 'date': '2025-04-03_22-35-13', 'timestamp': 1743734113, 'time_this_iter_s': 25.815566062927246, 'time_total_s': 260.6522240638733, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 260.6522240638733, 'iterations_since_restore': 50, 'perf': {'cpu_util_percent': 24.37777777777778, 'ram_util_percent': 53.04722222222222}}
2025-04-03 22:35:17,062 [__main__] [INFO] Iter: 51/100, Ts(iter): 0, Ts(total): 234600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.08s
2025-04-03 22:35:19,785 [__main__] [INFO] Iter: 52/100, Ts(iter): 0, Ts(total): 239200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.72s
2025-04-03 22:35:22,636 [__main__] [INFO] Iter: 53/100, Ts(iter): 0, Ts(total): 243800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.85s
2025-04-03 22:35:25,782 [__main__] [INFO] Iter: 54/100, Ts(iter): 0, Ts(total): 248400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.15s
2025-04-03 22:35:28,694 [__main__] [INFO] Iter: 55/100, Ts(iter): 0, Ts(total): 253000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.91s
2025-04-03 22:35:31,757 [__main__] [INFO] Iter: 56/100, Ts(iter): 0, Ts(total): 257600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.06s
2025-04-03 22:35:34,806 [__main__] [INFO] Iter: 57/100, Ts(iter): 0, Ts(total): 262200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.05s
2025-04-03 22:35:37,693 [__main__] [INFO] Iter: 58/100, Ts(iter): 0, Ts(total): 266800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.89s
2025-04-03 22:35:40,465 [__main__] [INFO] Iter: 59/100, Ts(iter): 0, Ts(total): 271400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.77s
2025-04-03 22:36:06,483 [__main__] [INFO] Iter: 60/100, Ts(iter): 0, Ts(total): 276000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 26.02s
2025-04-03 22:36:06,483 [__main__] [DEBUG] Full result dict at iter 60: {'timers': {'training_iteration': 2.9059386073847016, 'restore_env_runners': 1.4767317174708956e-05, 'training_step': 2.905808206692657, 'env_runner_sampling_timer': 0.26624904829915613, 'learner_update_timer': 2.6329691337207963, 'synch_weights': 0.005256781014866055, 'synch_env_connectors': 0.007140131637908756, 'restore_eval_env_runners': 5.4543715131613565e-06, 'evaluation_iteration': 26.127629307392862, 'synch_eval_env_connectors': 0.0018650451760672646}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 276000, 'servicer': 276000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.8069531061266146e-05, 'add_time_dim_to_batch_and_zero_pad': 6.648378588078719e-06, 'numpy_to_tensor': 3.116173340475162e-05, 'agent_to_module_mapping': 4.276799136875946e-06, 'add_states_from_episodes_to_batch': 4.03387994075938e-06, 'add_observations_from_episodes_to_batch': 1.6889217685864198e-05}}, 'connector_pipeline_timer': 0.00011703173722855118}, 'weights_seq_no': 59.0, 'num_env_steps_sampled_lifetime': 276000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.1044063932001478e-05, 'get_actions': 0.00012965154659758986, 'remove_single_ts_time_rank_from_batch': 1.3283034978045948e-06, 'tensor_to_numpy': 4.771954862574187e-05, 'module_to_agent_unmapping': 3.6506903444046236e-06, 'listify_data_for_vector_env': 9.343313871028689e-06, 'normalize_and_clip_actions': 5.324732985890924e-05}}, 'connector_pipeline_timer': 0.0003097662148831721}, 'env_to_module_sum_episodes_length_out': 131.88682522491874, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17793131551262828, 'num_module_steps_sampled_lifetime': {'servicer': 276000, 'target': 276000}, 'rlmodule_inference_timer': 0.00014956844523270646, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.0001457062424460314, 'env_to_module_sum_episodes_length_in': 131.88682522491874, 'time_between_sampling': 3.5424473168368693, 'episode_return_min': -88740.47016086392, 'episode_return_max': -86471.61061003555, 'episode_len_max': 10000, 'episode_return_mean': -87538.92175166441, 'agent_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'module_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'episode_len_mean': 10000.0, 'episode_duration_sec_mean': 8.93253737207535, 'num_episodes_lifetime': 23, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 989.662047692689}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.026134062967997453, 'agent_to_module_mapping': 0.0038608235664947957, 'add_states_from_episodes_to_batch': 5.029891041530367e-06, 'add_one_ts_to_episodes_and_truncate': 0.005439286135148623, 'add_columns_from_episodes_to_train_batch': 0.07706992528329812, 'add_observations_from_episodes_to_batch': 0.00021554974737737396, 'batch_individual_items': 0.07371313309744301, 'add_time_dim_to_batch_and_zero_pad': 1.8663149961485897e-05, 'numpy_to_tensor': 0.00015037617413932834}}, 'connector_pipeline_timer': 0.18678871692015156}, 'num_module_steps_trained_lifetime': 5560320, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 99912000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 14.587288856506348, 'gradients_default_optimizer_global_norm': 2.8113865852355957, 'vf_loss': 2.259327175124781e-06, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 2780160, 'policy_loss': 0.01482786238193512, 'vf_loss_unclipped': 2.259327175124781e-06, 'total_loss': -0.2769135534763336, 'weights_seq_no': 60.0, 'curr_kl_coeff': 0.0003906250058207661, 'vf_explained_var': -0.11547636985778809, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.0053992136381566525}, 'servicer': {'num_module_steps_trained_lifetime': 2780160, 'vf_loss': 5.0, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': 0.07129782438278198, 'vf_loss_unclipped': 42960.63671875, 'total_loss': 4.894953727722168, 'weights_seq_no': 60.0, 'curr_kl_coeff': 2.9802322831784522e-09, 'vf_explained_var': -0.0004994869232177734, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.004967689048498869, 'entropy': 8.81721019744873, 'gradients_default_optimizer_global_norm': 3.4034183025360107}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 300000, 'servicer': 300000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.021808211295658e-05, 'add_time_dim_to_batch_and_zero_pad': 3.540091787819183e-06, 'numpy_to_tensor': 1.5977034600277504e-05, 'agent_to_module_mapping': 2.4418288729198966e-06, 'add_states_from_episodes_to_batch': 2.6180559549364043e-06, 'add_observations_from_episodes_to_batch': 9.14165415997642e-06}}, 'connector_pipeline_timer': 6.657164098850237e-05}, 'episode_return_min': -90401.70479021194, 'weights_seq_no': 59.0, 'num_env_steps_sampled_lifetime': 300000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90262.75858117791, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3083490837554356e-05, 'get_actions': 2.8268247589671968e-05, 'remove_single_ts_time_rank_from_batch': 6.75685277581546e-07, 'tensor_to_numpy': 2.871820378336886e-05, 'module_to_agent_unmapping': 2.1860683698980257e-06, 'listify_data_for_vector_env': 6.032185090449831e-06, 'normalize_and_clip_actions': 3.093941250074868e-05}}, 'connector_pipeline_timer': 0.0001368347678036975}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3786146060418485e-05, 'numpy_to_tensor': 3.093441863145394e-05, 'agent_to_module_mapping': 5.207152075367675e-06, 'add_states_from_episodes_to_batch': 4.748271362580187e-06, 'add_observations_from_episodes_to_batch': 3.781132951813246e-05, 'batch_individual_items': 2.499683955940798e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90347.81436783427, 'sample': 25.909053077835846, 'agent_episode_returns_mean': {'servicer': -90347.29228073277, 'target': -0.5220871014977985}, 'module_episode_returns_mean': {'servicer': -90347.29228073277, 'target': -0.5220871014977985}, 'num_module_steps_sampled_lifetime': {'servicer': 300000, 'target': 300000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.65154951872766e-05, 'connector_pipeline_timer': 0.00024327622273353141, 'env_reset_timer': 0.00015228904259233746, 'episode_len_mean': 10000.0, 'env_step_timer': 8.804936125276362e-05, 'episode_duration_sec_mean': 4.962246582079242, 'num_episodes_lifetime': 30, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.9192636592618, 'time_between_sampling': 26.97135000828035}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 276000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 989.662047692689, 'done': False, 'training_iteration': 60, 'trial_id': 'default', 'date': '2025-04-03_22-36-06', 'timestamp': 1743734166, 'time_this_iter_s': 26.006635904312134, 'time_total_s': 313.02727150917053, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 313.02727150917053, 'iterations_since_restore': 60, 'perf': {'cpu_util_percent': 26.10810810810811, 'ram_util_percent': 53.0162162162162}}
2025-04-03 22:36:06,501 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.9059386073847016, 'restore_env_runners': 1.4767317174708956e-05, 'training_step': 2.905808206692657, 'env_runner_sampling_timer': 0.26624904829915613, 'learner_update_timer': 2.6329691337207963, 'synch_weights': 0.005256781014866055, 'synch_env_connectors': 0.007140131637908756, 'restore_eval_env_runners': 5.4543715131613565e-06, 'evaluation_iteration': 26.127629307392862, 'synch_eval_env_connectors': 0.0018650451760672646}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 276000, 'servicer': 276000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.8069531061266146e-05, 'add_time_dim_to_batch_and_zero_pad': 6.648378588078719e-06, 'numpy_to_tensor': 3.116173340475162e-05, 'agent_to_module_mapping': 4.276799136875946e-06, 'add_states_from_episodes_to_batch': 4.03387994075938e-06, 'add_observations_from_episodes_to_batch': 1.6889217685864198e-05}}, 'connector_pipeline_timer': 0.00011703173722855118}, 'weights_seq_no': 59.0, 'num_env_steps_sampled_lifetime': 276000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.1044063932001478e-05, 'get_actions': 0.00012965154659758986, 'remove_single_ts_time_rank_from_batch': 1.3283034978045948e-06, 'tensor_to_numpy': 4.771954862574187e-05, 'module_to_agent_unmapping': 3.6506903444046236e-06, 'listify_data_for_vector_env': 9.343313871028689e-06, 'normalize_and_clip_actions': 5.324732985890924e-05}}, 'connector_pipeline_timer': 0.0003097662148831721}, 'env_to_module_sum_episodes_length_out': 131.88682522491874, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17793131551262828, 'num_module_steps_sampled_lifetime': {'servicer': 276000, 'target': 276000}, 'rlmodule_inference_timer': 0.00014956844523270646, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.0001457062424460314, 'env_to_module_sum_episodes_length_in': 131.88682522491874, 'time_between_sampling': 3.5424473168368693, 'episode_return_min': -88740.47016086392, 'episode_return_max': -86471.61061003555, 'episode_len_max': 10000, 'episode_return_mean': -87538.92175166441, 'agent_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'module_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'episode_len_mean': 10000.0, 'episode_duration_sec_mean': 8.93253737207535, 'num_episodes_lifetime': 23, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 989.662047692689}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.026134062967997453, 'agent_to_module_mapping': 0.0038608235664947957, 'add_states_from_episodes_to_batch': 5.029891041530367e-06, 'add_one_ts_to_episodes_and_truncate': 0.005439286135148623, 'add_columns_from_episodes_to_train_batch': 0.07706992528329812, 'add_observations_from_episodes_to_batch': 0.00021554974737737396, 'batch_individual_items': 0.07371313309744301, 'add_time_dim_to_batch_and_zero_pad': 1.8663149961485897e-05, 'numpy_to_tensor': 0.00015037617413932834}}, 'connector_pipeline_timer': 0.18678871692015156}, 'num_module_steps_trained_lifetime': 5560320, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 99912000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 14.587288856506348, 'gradients_default_optimizer_global_norm': 2.8113865852355957, 'vf_loss': 2.259327175124781e-06, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 2780160, 'policy_loss': 0.01482786238193512, 'vf_loss_unclipped': 2.259327175124781e-06, 'total_loss': -0.2769135534763336, 'weights_seq_no': 60.0, 'curr_kl_coeff': 0.0003906250058207661, 'vf_explained_var': -0.11547636985778809, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.0053992136381566525}, 'servicer': {'num_module_steps_trained_lifetime': 2780160, 'vf_loss': 5.0, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': 0.07129782438278198, 'vf_loss_unclipped': 42960.63671875, 'total_loss': 4.894953727722168, 'weights_seq_no': 60.0, 'curr_kl_coeff': 2.9802322831784522e-09, 'vf_explained_var': -0.0004994869232177734, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.004967689048498869, 'entropy': 8.81721019744873, 'gradients_default_optimizer_global_norm': 3.4034183025360107}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 300000, 'servicer': 300000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.021808211295658e-05, 'add_time_dim_to_batch_and_zero_pad': 3.540091787819183e-06, 'numpy_to_tensor': 1.5977034600277504e-05, 'agent_to_module_mapping': 2.4418288729198966e-06, 'add_states_from_episodes_to_batch': 2.6180559549364043e-06, 'add_observations_from_episodes_to_batch': 9.14165415997642e-06}}, 'connector_pipeline_timer': 6.657164098850237e-05}, 'episode_return_min': -90401.70479021194, 'weights_seq_no': 59.0, 'num_env_steps_sampled_lifetime': 300000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90262.75858117791, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3083490837554356e-05, 'get_actions': 2.8268247589671968e-05, 'remove_single_ts_time_rank_from_batch': 6.75685277581546e-07, 'tensor_to_numpy': 2.871820378336886e-05, 'module_to_agent_unmapping': 2.1860683698980257e-06, 'listify_data_for_vector_env': 6.032185090449831e-06, 'normalize_and_clip_actions': 3.093941250074868e-05}}, 'connector_pipeline_timer': 0.0001368347678036975}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3786146060418485e-05, 'numpy_to_tensor': 3.093441863145394e-05, 'agent_to_module_mapping': 5.207152075367675e-06, 'add_states_from_episodes_to_batch': 4.748271362580187e-06, 'add_observations_from_episodes_to_batch': 3.781132951813246e-05, 'batch_individual_items': 2.499683955940798e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90347.81436783427, 'sample': 25.909053077835846, 'agent_episode_returns_mean': {'servicer': -90347.29228073277, 'target': -0.5220871014977985}, 'module_episode_returns_mean': {'servicer': -90347.29228073277, 'target': -0.5220871014977985}, 'num_module_steps_sampled_lifetime': {'servicer': 300000, 'target': 300000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.65154951872766e-05, 'connector_pipeline_timer': 0.00024327622273353141, 'env_reset_timer': 0.00015228904259233746, 'episode_len_mean': 10000.0, 'env_step_timer': 8.804936125276362e-05, 'episode_duration_sec_mean': 4.962246582079242, 'num_episodes_lifetime': 30, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.9192636592618, 'time_between_sampling': 26.97135000828035}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 276000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 989.662047692689, 'done': False, 'training_iteration': 60, 'trial_id': 'default', 'date': '2025-04-03_22-36-06', 'timestamp': 1743734166, 'time_this_iter_s': 26.006635904312134, 'time_total_s': 313.02727150917053, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 313.02727150917053, 'iterations_since_restore': 60, 'perf': {'cpu_util_percent': 26.10810810810811, 'ram_util_percent': 53.0162162162162}})
2025-04-03 22:36:09,568 [__main__] [INFO] Iter: 61/100, Ts(iter): 0, Ts(total): 280600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.07s
2025-04-03 22:36:12,561 [__main__] [INFO] Iter: 62/100, Ts(iter): 0, Ts(total): 285200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.99s
2025-04-03 22:36:15,575 [__main__] [INFO] Iter: 63/100, Ts(iter): 0, Ts(total): 289800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.01s
2025-04-03 22:36:18,524 [__main__] [INFO] Iter: 64/100, Ts(iter): 0, Ts(total): 294400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.95s
2025-04-03 22:36:21,611 [__main__] [INFO] Iter: 65/100, Ts(iter): 0, Ts(total): 299000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.09s
2025-04-03 22:36:24,591 [__main__] [INFO] Iter: 66/100, Ts(iter): 0, Ts(total): 303600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.98s
2025-04-03 22:36:27,548 [__main__] [INFO] Iter: 67/100, Ts(iter): 0, Ts(total): 308200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.96s
2025-04-03 22:36:30,542 [__main__] [INFO] Iter: 68/100, Ts(iter): 0, Ts(total): 312800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.99s
2025-04-03 22:36:33,395 [__main__] [INFO] Iter: 69/100, Ts(iter): 0, Ts(total): 317400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.85s
2025-04-03 22:36:59,180 [__main__] [INFO] Iter: 70/100, Ts(iter): 0, Ts(total): 322000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 25.78s
2025-04-03 22:36:59,180 [__main__] [DEBUG] Full result dict at iter 70: {'timers': {'training_iteration': 2.928129963343765, 'restore_env_runners': 1.4200321332792012e-05, 'training_step': 2.9279987342460907, 'env_runner_sampling_timer': 0.26151002107760085, 'learner_update_timer': 2.6598934332574027, 'synch_weights': 0.00521481288722786, 'synch_env_connectors': 0.007138072373779925, 'restore_eval_env_runners': 5.46441778344322e-06, 'evaluation_iteration': 26.12633547348892, 'synch_eval_env_connectors': 0.001863357644214702}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 322000, 'servicer': 322000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.6709748400744276e-05, 'add_time_dim_to_batch_and_zero_pad': 6.3000279478809825e-06, 'numpy_to_tensor': 2.801243990297456e-05, 'agent_to_module_mapping': 3.9801638108295445e-06, 'add_states_from_episodes_to_batch': 3.9427622052120934e-06, 'add_observations_from_episodes_to_batch': 1.5292941130562688e-05}}, 'connector_pipeline_timer': 0.0001082131778335059}, 'weights_seq_no': 69.0, 'num_env_steps_sampled_lifetime': 322000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.004770569020775e-05, 'get_actions': 0.0001212075305972611, 'remove_single_ts_time_rank_from_batch': 1.1892625026600215e-06, 'tensor_to_numpy': 4.5502208589352665e-05, 'module_to_agent_unmapping': 3.433938871940649e-06, 'listify_data_for_vector_env': 9.202333700556402e-06, 'normalize_and_clip_actions': 4.972989092468902e-05}}, 'connector_pipeline_timer': 0.00029136641099640216}, 'env_to_module_sum_episodes_length_out': 131.93604722203835, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17801771161599933, 'num_module_steps_sampled_lifetime': {'servicer': 322000, 'target': 322000}, 'rlmodule_inference_timer': 0.0001386730137651469, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.00013914875998121594, 'env_to_module_sum_episodes_length_in': 131.93604722203835, 'time_between_sampling': 3.6875162043139302, 'episode_return_min': -88740.47016086392, 'episode_return_max': -86471.61061003555, 'episode_len_max': 10000, 'episode_return_mean': -87538.92175166441, 'agent_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'module_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'episode_len_mean': 10000.0, 'episode_duration_sec_mean': 8.93253737207535, 'num_episodes_lifetime': 23, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 984.6531198438051}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.025688207063306254, 'agent_to_module_mapping': 0.0038684189835762025, 'add_states_from_episodes_to_batch': 4.999683606972228e-06, 'add_one_ts_to_episodes_and_truncate': 0.005432597559245253, 'add_columns_from_episodes_to_train_batch': 0.07714500680077825, 'add_observations_from_episodes_to_batch': 0.00021664693752780612, 'batch_individual_items': 0.07458708828048757, 'add_time_dim_to_batch_and_zero_pad': 1.85294594664517e-05, 'numpy_to_tensor': 0.00014973834029666518}}, 'connector_pipeline_timer': 0.18729040574497322}, 'num_module_steps_trained_lifetime': 6487040, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 116564000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 16.0240421295166, 'gradients_default_optimizer_global_norm': 3.964317798614502, 'vf_loss': 2.9447523957060184e-06, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 3243520, 'policy_loss': -0.024455277249217033, 'vf_loss_unclipped': 2.9447523957060184e-06, 'total_loss': -0.34493309259414673, 'weights_seq_no': 70.0, 'curr_kl_coeff': 1.220703143189894e-05, 'vf_explained_var': -0.12478983402252197, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.006475630681961775}, 'servicer': {'num_module_steps_trained_lifetime': 3243520, 'vf_loss': 5.0, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': 0.05562473461031914, 'vf_loss_unclipped': 47226.609375, 'total_loss': 4.876876354217529, 'weights_seq_no': 70.0, 'curr_kl_coeff': 3.7252903539730653e-10, 'vf_explained_var': 0.00015866756439208984, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.004618178587406874, 'entropy': 8.937403678894043, 'gradients_default_optimizer_global_norm': 4.507468223571777}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 350000, 'servicer': 350000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.021805582860305e-05, 'add_time_dim_to_batch_and_zero_pad': 3.540226647024323e-06, 'numpy_to_tensor': 1.598009633084819e-05, 'agent_to_module_mapping': 2.4419384189419566e-06, 'add_states_from_episodes_to_batch': 2.6178590120121362e-06, 'add_observations_from_episodes_to_batch': 9.14168649198618e-06}}, 'connector_pipeline_timer': 6.657504520495852e-05}, 'episode_return_min': -90401.70479021194, 'weights_seq_no': 69.0, 'num_env_steps_sampled_lifetime': 350000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90221.32842312189, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3085674326498107e-05, 'get_actions': 2.8270494686703793e-05, 'remove_single_ts_time_rank_from_batch': 6.758785144322198e-07, 'tensor_to_numpy': 2.872075079070059e-05, 'module_to_agent_unmapping': 2.185799416292261e-06, 'listify_data_for_vector_env': 6.03215405911136e-06, 'normalize_and_clip_actions': 3.093273417485225e-05}}, 'connector_pipeline_timer': 0.00013683601613822746}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3783930325550046e-05, 'numpy_to_tensor': 3.094030464005889e-05, 'agent_to_module_mapping': 5.206744292680712e-06, 'add_states_from_episodes_to_batch': 4.747601817149797e-06, 'add_observations_from_episodes_to_batch': 3.780326182415398e-05, 'batch_individual_items': 2.499505273547337e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90343.81463314571, 'sample': 25.90891102362875, 'agent_episode_returns_mean': {'servicer': -90343.27351996006, 'target': -0.5411131856398278}, 'module_episode_returns_mean': {'servicer': -90343.27351996006, 'target': -0.5411131856398278}, 'num_module_steps_sampled_lifetime': {'servicer': 350000, 'target': 350000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.652907377483361e-05, 'connector_pipeline_timer': 0.000243219819063306, 'env_reset_timer': 0.00015227271112583932, 'episode_len_mean': 10000.0, 'env_step_timer': 8.804989567107626e-05, 'episode_duration_sec_mean': 4.955721563719999, 'num_episodes_lifetime': 35, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.9278487070812, 'time_between_sampling': 26.971228378316855}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 322000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 984.6531198438051, 'done': False, 'training_iteration': 70, 'trial_id': 'default', 'date': '2025-04-03_22-36-59', 'timestamp': 1743734219, 'time_this_iter_s': 25.773382902145386, 'time_total_s': 365.5698893070221, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 365.5698893070221, 'iterations_since_restore': 70, 'perf': {'cpu_util_percent': 29.327777777777783, 'ram_util_percent': 53.26111111111111}}
2025-04-03 22:37:02,244 [__main__] [INFO] Iter: 71/100, Ts(iter): 0, Ts(total): 326600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.06s
2025-04-03 22:37:05,195 [__main__] [INFO] Iter: 72/100, Ts(iter): 0, Ts(total): 331200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.95s
2025-04-03 22:37:08,232 [__main__] [INFO] Iter: 73/100, Ts(iter): 0, Ts(total): 335800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.04s
2025-04-03 22:37:11,252 [__main__] [INFO] Iter: 74/100, Ts(iter): 0, Ts(total): 340400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.02s
2025-04-03 22:37:14,129 [__main__] [INFO] Iter: 75/100, Ts(iter): 0, Ts(total): 345000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.88s
2025-04-03 22:37:17,186 [__main__] [INFO] Iter: 76/100, Ts(iter): 0, Ts(total): 349600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.06s
2025-04-03 22:37:20,062 [__main__] [INFO] Iter: 77/100, Ts(iter): 0, Ts(total): 354200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.88s
2025-04-03 22:37:23,295 [__main__] [INFO] Iter: 78/100, Ts(iter): 0, Ts(total): 358800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.23s
2025-04-03 22:37:26,128 [__main__] [INFO] Iter: 79/100, Ts(iter): 0, Ts(total): 363400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.83s
2025-04-03 22:37:51,877 [__main__] [INFO] Iter: 80/100, Ts(iter): 0, Ts(total): 368000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 25.75s
2025-04-03 22:37:51,877 [__main__] [DEBUG] Full result dict at iter 80: {'timers': {'training_iteration': 2.94788782897477, 'restore_env_runners': 1.3569826096986373e-05, 'training_step': 2.9477567592223113, 'env_runner_sampling_timer': 0.25860181323591436, 'learner_update_timer': 2.6825578281101623, 'synch_weights': 0.005166730473431045, 'synch_env_connectors': 0.007158520212176214, 'restore_eval_env_runners': 5.457693499013257e-06, 'evaluation_iteration': 26.12272741667402, 'synch_eval_env_connectors': 0.0018578073977497899}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 368000, 'servicer': 368000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.811682864893505e-05, 'add_time_dim_to_batch_and_zero_pad': 6.414663976377259e-06, 'numpy_to_tensor': 2.9176448463302894e-05, 'agent_to_module_mapping': 4.434638323480134e-06, 'add_states_from_episodes_to_batch': 3.997802482212815e-06, 'add_observations_from_episodes_to_batch': 1.5921521187924906e-05}}, 'connector_pipeline_timer': 0.00011354476362652334}, 'weights_seq_no': 79.0, 'num_env_steps_sampled_lifetime': 368000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.1572356259817192e-05, 'get_actions': 0.00012877998285710452, 'remove_single_ts_time_rank_from_batch': 1.1288698249625586e-06, 'tensor_to_numpy': 4.846412372503526e-05, 'module_to_agent_unmapping': 3.5903000134590873e-06, 'listify_data_for_vector_env': 9.595781240568294e-06, 'normalize_and_clip_actions': 5.1397756966583866e-05}}, 'connector_pipeline_timer': 0.0003089247582289588}, 'env_to_module_sum_episodes_length_out': 131.94092535900796, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17811888697561568, 'num_module_steps_sampled_lifetime': {'servicer': 368000, 'target': 368000}, 'rlmodule_inference_timer': 0.00014703143697184504, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.00014395684270896624, 'env_to_module_sum_episodes_length_in': 131.94092535900796, 'time_between_sampling': 3.817645333892836, 'episode_return_min': -88740.47016086392, 'episode_return_max': -86471.61061003555, 'episode_len_max': 10000, 'episode_return_mean': -87538.92175166441, 'agent_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'module_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'episode_len_mean': 10000.0, 'episode_duration_sec_mean': 8.93253737207535, 'num_episodes_lifetime': 23, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 1003.9531657672088}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.02522295252697793, 'agent_to_module_mapping': 0.0038758114537390965, 'add_states_from_episodes_to_batch': 4.965239417886738e-06, 'add_one_ts_to_episodes_and_truncate': 0.005424134863181516, 'add_columns_from_episodes_to_train_batch': 0.07721642601890215, 'add_observations_from_episodes_to_batch': 0.00021754935411315396, 'batch_individual_items': 0.07551424286078337, 'add_time_dim_to_batch_and_zero_pad': 1.8380980092797177e-05, 'numpy_to_tensor': 0.00014902288774923457}}, 'connector_pipeline_timer': 0.1878197560528254}, 'num_module_steps_trained_lifetime': 7413760, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 133216000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 16.633895874023438, 'gradients_default_optimizer_global_norm': 3.594876766204834, 'vf_loss': 2.866173872462241e-06, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 3706880, 'policy_loss': 0.05679188668727875, 'vf_loss_unclipped': 2.866173872462241e-06, 'total_loss': -0.27588310837745667, 'weights_seq_no': 80.0, 'curr_kl_coeff': 6.10351571594947e-06, 'vf_explained_var': -0.22091543674468994, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.008861441165208817}, 'servicer': {'num_module_steps_trained_lifetime': 3706880, 'vf_loss': 4.960317611694336, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': -0.02651355043053627, 'vf_loss_unclipped': 46424.58203125, 'total_loss': 4.747470378875732, 'weights_seq_no': 80.0, 'curr_kl_coeff': 4.6566129424663316e-11, 'vf_explained_var': 7.510185241699219e-05, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.006042228080332279, 'entropy': 9.316689491271973, 'gradients_default_optimizer_global_norm': 6.774783611297607}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.0219427697007555e-05, 'add_time_dim_to_batch_and_zero_pad': 3.540098557209365e-06, 'numpy_to_tensor': 1.5981592820192273e-05, 'agent_to_module_mapping': 2.442231655310768e-06, 'add_states_from_episodes_to_batch': 2.6179693394719863e-06, 'add_observations_from_episodes_to_batch': 9.141625754535688e-06}}, 'connector_pipeline_timer': 6.658355128996575e-05}, 'episode_return_min': -90401.70479021194, 'weights_seq_no': 79.0, 'num_env_steps_sampled_lifetime': 400000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90112.67346572112, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3087839475596074e-05, 'get_actions': 2.8273113830996382e-05, 'remove_single_ts_time_rank_from_batch': 6.758805652642826e-07, 'tensor_to_numpy': 2.8720740239213282e-05, 'module_to_agent_unmapping': 2.185368234087819e-06, 'listify_data_for_vector_env': 6.0320668410420955e-06, 'normalize_and_clip_actions': 3.092536294035276e-05}}, 'connector_pipeline_timer': 0.0001368351641618933}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3781213692054788e-05, 'numpy_to_tensor': 3.0945783687259234e-05, 'agent_to_module_mapping': 5.206236450670547e-06, 'add_states_from_episodes_to_batch': 4.746829135658893e-06, 'add_observations_from_episodes_to_batch': 3.77938743511543e-05, 'batch_individual_items': 2.499273536498816e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90320.968182709, 'sample': 25.908732687539715, 'agent_episode_returns_mean': {'servicer': -90320.40400084932, 'target': -0.564181859693527}, 'module_episode_returns_mean': {'servicer': -90320.40400084932, 'target': -0.564181859693527}, 'num_module_steps_sampled_lifetime': {'servicer': 400000, 'target': 400000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.653325037278006e-05, 'connector_pipeline_timer': 0.00024315263254382193, 'env_reset_timer': 0.00015225440658501413, 'episode_len_mean': 10000.0, 'env_step_timer': 8.804574303128742e-05, 'episode_duration_sec_mean': 4.951344323320518, 'num_episodes_lifetime': 40, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.938991203803, 'time_between_sampling': 26.971129988156004}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 368000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1003.9531657672088, 'done': False, 'training_iteration': 80, 'trial_id': 'default', 'date': '2025-04-03_22-37-51', 'timestamp': 1743734271, 'time_this_iter_s': 25.737723112106323, 'time_total_s': 418.13475465774536, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 418.13475465774536, 'iterations_since_restore': 80, 'perf': {'cpu_util_percent': 29.089189189189195, 'ram_util_percent': 53.30270270270269}}
2025-04-03 22:37:51,896 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.94788782897477, 'restore_env_runners': 1.3569826096986373e-05, 'training_step': 2.9477567592223113, 'env_runner_sampling_timer': 0.25860181323591436, 'learner_update_timer': 2.6825578281101623, 'synch_weights': 0.005166730473431045, 'synch_env_connectors': 0.007158520212176214, 'restore_eval_env_runners': 5.457693499013257e-06, 'evaluation_iteration': 26.12272741667402, 'synch_eval_env_connectors': 0.0018578073977497899}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 368000, 'servicer': 368000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.811682864893505e-05, 'add_time_dim_to_batch_and_zero_pad': 6.414663976377259e-06, 'numpy_to_tensor': 2.9176448463302894e-05, 'agent_to_module_mapping': 4.434638323480134e-06, 'add_states_from_episodes_to_batch': 3.997802482212815e-06, 'add_observations_from_episodes_to_batch': 1.5921521187924906e-05}}, 'connector_pipeline_timer': 0.00011354476362652334}, 'weights_seq_no': 79.0, 'num_env_steps_sampled_lifetime': 368000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.1572356259817192e-05, 'get_actions': 0.00012877998285710452, 'remove_single_ts_time_rank_from_batch': 1.1288698249625586e-06, 'tensor_to_numpy': 4.846412372503526e-05, 'module_to_agent_unmapping': 3.5903000134590873e-06, 'listify_data_for_vector_env': 9.595781240568294e-06, 'normalize_and_clip_actions': 5.1397756966583866e-05}}, 'connector_pipeline_timer': 0.0003089247582289588}, 'env_to_module_sum_episodes_length_out': 131.94092535900796, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17811888697561568, 'num_module_steps_sampled_lifetime': {'servicer': 368000, 'target': 368000}, 'rlmodule_inference_timer': 0.00014703143697184504, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.00014395684270896624, 'env_to_module_sum_episodes_length_in': 131.94092535900796, 'time_between_sampling': 3.817645333892836, 'episode_return_min': -88740.47016086392, 'episode_return_max': -86471.61061003555, 'episode_len_max': 10000, 'episode_return_mean': -87538.92175166441, 'agent_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'module_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'episode_len_mean': 10000.0, 'episode_duration_sec_mean': 8.93253737207535, 'num_episodes_lifetime': 23, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 1003.9531657672088}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.02522295252697793, 'agent_to_module_mapping': 0.0038758114537390965, 'add_states_from_episodes_to_batch': 4.965239417886738e-06, 'add_one_ts_to_episodes_and_truncate': 0.005424134863181516, 'add_columns_from_episodes_to_train_batch': 0.07721642601890215, 'add_observations_from_episodes_to_batch': 0.00021754935411315396, 'batch_individual_items': 0.07551424286078337, 'add_time_dim_to_batch_and_zero_pad': 1.8380980092797177e-05, 'numpy_to_tensor': 0.00014902288774923457}}, 'connector_pipeline_timer': 0.1878197560528254}, 'num_module_steps_trained_lifetime': 7413760, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 133216000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 16.633895874023438, 'gradients_default_optimizer_global_norm': 3.594876766204834, 'vf_loss': 2.866173872462241e-06, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 3706880, 'policy_loss': 0.05679188668727875, 'vf_loss_unclipped': 2.866173872462241e-06, 'total_loss': -0.27588310837745667, 'weights_seq_no': 80.0, 'curr_kl_coeff': 6.10351571594947e-06, 'vf_explained_var': -0.22091543674468994, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.008861441165208817}, 'servicer': {'num_module_steps_trained_lifetime': 3706880, 'vf_loss': 4.960317611694336, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': -0.02651355043053627, 'vf_loss_unclipped': 46424.58203125, 'total_loss': 4.747470378875732, 'weights_seq_no': 80.0, 'curr_kl_coeff': 4.6566129424663316e-11, 'vf_explained_var': 7.510185241699219e-05, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.006042228080332279, 'entropy': 9.316689491271973, 'gradients_default_optimizer_global_norm': 6.774783611297607}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.0219427697007555e-05, 'add_time_dim_to_batch_and_zero_pad': 3.540098557209365e-06, 'numpy_to_tensor': 1.5981592820192273e-05, 'agent_to_module_mapping': 2.442231655310768e-06, 'add_states_from_episodes_to_batch': 2.6179693394719863e-06, 'add_observations_from_episodes_to_batch': 9.141625754535688e-06}}, 'connector_pipeline_timer': 6.658355128996575e-05}, 'episode_return_min': -90401.70479021194, 'weights_seq_no': 79.0, 'num_env_steps_sampled_lifetime': 400000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90112.67346572112, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3087839475596074e-05, 'get_actions': 2.8273113830996382e-05, 'remove_single_ts_time_rank_from_batch': 6.758805652642826e-07, 'tensor_to_numpy': 2.8720740239213282e-05, 'module_to_agent_unmapping': 2.185368234087819e-06, 'listify_data_for_vector_env': 6.0320668410420955e-06, 'normalize_and_clip_actions': 3.092536294035276e-05}}, 'connector_pipeline_timer': 0.0001368351641618933}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3781213692054788e-05, 'numpy_to_tensor': 3.0945783687259234e-05, 'agent_to_module_mapping': 5.206236450670547e-06, 'add_states_from_episodes_to_batch': 4.746829135658893e-06, 'add_observations_from_episodes_to_batch': 3.77938743511543e-05, 'batch_individual_items': 2.499273536498816e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90320.968182709, 'sample': 25.908732687539715, 'agent_episode_returns_mean': {'servicer': -90320.40400084932, 'target': -0.564181859693527}, 'module_episode_returns_mean': {'servicer': -90320.40400084932, 'target': -0.564181859693527}, 'num_module_steps_sampled_lifetime': {'servicer': 400000, 'target': 400000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.653325037278006e-05, 'connector_pipeline_timer': 0.00024315263254382193, 'env_reset_timer': 0.00015225440658501413, 'episode_len_mean': 10000.0, 'env_step_timer': 8.804574303128742e-05, 'episode_duration_sec_mean': 4.951344323320518, 'num_episodes_lifetime': 40, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.938991203803, 'time_between_sampling': 26.971129988156004}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 368000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1003.9531657672088, 'done': False, 'training_iteration': 80, 'trial_id': 'default', 'date': '2025-04-03_22-37-51', 'timestamp': 1743734271, 'time_this_iter_s': 25.737723112106323, 'time_total_s': 418.13475465774536, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 418.13475465774536, 'iterations_since_restore': 80, 'perf': {'cpu_util_percent': 29.089189189189195, 'ram_util_percent': 53.30270270270269}})
2025-04-03 22:37:54,970 [__main__] [INFO] Iter: 81/100, Ts(iter): 0, Ts(total): 372600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.07s
2025-04-03 22:37:57,757 [__main__] [INFO] Iter: 82/100, Ts(iter): 0, Ts(total): 377200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.79s
2025-04-03 22:38:00,889 [__main__] [INFO] Iter: 83/100, Ts(iter): 0, Ts(total): 381800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.13s
2025-04-03 22:38:03,943 [__main__] [INFO] Iter: 84/100, Ts(iter): 0, Ts(total): 386400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.05s
2025-04-03 22:38:06,923 [__main__] [INFO] Iter: 85/100, Ts(iter): 0, Ts(total): 391000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.98s
2025-04-03 22:38:09,654 [__main__] [INFO] Iter: 86/100, Ts(iter): 0, Ts(total): 395600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.73s
2025-04-03 22:38:12,657 [__main__] [INFO] Iter: 87/100, Ts(iter): 0, Ts(total): 400200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.00s
2025-04-03 22:38:15,643 [__main__] [INFO] Iter: 88/100, Ts(iter): 0, Ts(total): 404800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.99s
2025-04-03 22:38:18,534 [__main__] [INFO] Iter: 89/100, Ts(iter): 0, Ts(total): 409400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.89s
2025-04-03 22:38:44,462 [__main__] [INFO] Iter: 90/100, Ts(iter): 0, Ts(total): 414000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 25.93s
2025-04-03 22:38:44,463 [__main__] [DEBUG] Full result dict at iter 90: {'timers': {'training_iteration': 2.9626703973490187, 'restore_env_runners': 1.3036594058847768e-05, 'training_step': 2.962540013707187, 'env_runner_sampling_timer': 0.25623469041523966, 'learner_update_timer': 2.699690389142216, 'synch_weights': 0.005146757374914795, 'synch_env_connectors': 0.0071637043158782185, 'restore_eval_env_runners': 5.453946549434962e-06, 'evaluation_iteration': 26.118795623757322, 'synch_eval_env_connectors': 0.0018506855738398594}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 414000, 'servicer': 414000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.6772591263519412e-05, 'add_time_dim_to_batch_and_zero_pad': 6.463537133758055e-06, 'numpy_to_tensor': 2.7812490898705394e-05, 'agent_to_module_mapping': 4.108923186237865e-06, 'add_states_from_episodes_to_batch': 3.887860982226515e-06, 'add_observations_from_episodes_to_batch': 1.5572381234407933e-05}}, 'connector_pipeline_timer': 0.0001086758335469437}, 'weights_seq_no': 89.0, 'num_env_steps_sampled_lifetime': 414000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.063304672941735e-05, 'get_actions': 0.0001210337318183219, 'remove_single_ts_time_rank_from_batch': 1.0865394827942513e-06, 'tensor_to_numpy': 4.574606715717839e-05, 'module_to_agent_unmapping': 3.636899765811059e-06, 'listify_data_for_vector_env': 9.15170176978941e-06, 'normalize_and_clip_actions': 5.020126477288504e-05}}, 'connector_pipeline_timer': 0.0002937022008499087}, 'env_to_module_sum_episodes_length_out': 131.94140880587247, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17819239325427938, 'num_module_steps_sampled_lifetime': {'servicer': 414000, 'target': 414000}, 'rlmodule_inference_timer': 0.00013856056627235624, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.00013876373972626868, 'env_to_module_sum_episodes_length_in': 131.94140880587247, 'time_between_sampling': 3.933989797401701, 'episode_return_min': -88740.47016086392, 'episode_return_max': -86471.61061003555, 'episode_len_max': 10000, 'episode_return_mean': -87538.92175166441, 'agent_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'module_episode_returns_mean': {'servicer': -87536.9697799986, 'target': -1.9519716658186652}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'episode_len_mean': 10000.0, 'episode_duration_sec_mean': 8.93253737207535, 'num_episodes_lifetime': 23, 'num_episodes': 0, 'num_env_steps_sampled_lifetime_throughput': 1006.391892233225}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.024740045258270265, 'agent_to_module_mapping': 0.0038834966242351334, 'add_states_from_episodes_to_batch': 4.9284493496224255e-06, 'add_one_ts_to_episodes_and_truncate': 0.005414974826316706, 'add_columns_from_episodes_to_train_batch': 0.07729210559786989, 'add_observations_from_episodes_to_batch': 0.00021831981134830798, 'batch_individual_items': 0.07641792706257836, 'add_time_dim_to_batch_and_zero_pad': 1.8227477613337165e-05, 'numpy_to_tensor': 0.0001482792613919803}}, 'connector_pipeline_timer': 0.18831158754842164}, 'num_module_steps_trained_lifetime': 8340480, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 149868000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 16.84789276123047, 'gradients_default_optimizer_global_norm': 2.6622464656829834, 'vf_loss': 2.3107031665858813e-06, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 4170240, 'policy_loss': -0.08322210609912872, 'vf_loss_unclipped': 2.3107031665858813e-06, 'total_loss': -0.4201776385307312, 'weights_seq_no': 90.0, 'curr_kl_coeff': 1.5258789289873675e-06, 'vf_explained_var': -0.12924325466156006, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.009274860844016075}, 'servicer': {'num_module_steps_trained_lifetime': 4170240, 'vf_loss': 4.9609375, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': 0.01480141095817089, 'vf_loss_unclipped': 46555.08984375, 'total_loss': 4.778413772583008, 'weights_seq_no': 90.0, 'curr_kl_coeff': 1.1641532356165829e-11, 'vf_explained_var': 1.6868114471435547e-05, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.004204196389764547, 'entropy': 9.866255760192871, 'gradients_default_optimizer_global_norm': 2.8343796730041504}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 450000, 'servicer': 450000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.0219760494909722e-05, 'add_time_dim_to_batch_and_zero_pad': 3.5396557163829644e-06, 'numpy_to_tensor': 1.5984675498989238e-05, 'agent_to_module_mapping': 2.4422106869194514e-06, 'add_states_from_episodes_to_batch': 2.617760000054049e-06, 'add_observations_from_episodes_to_batch': 9.14129797455239e-06}}, 'connector_pipeline_timer': 6.658909885694822e-05}, 'episode_return_min': -90401.70479021194, 'weights_seq_no': 89.0, 'num_env_steps_sampled_lifetime': 450000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90112.67346572112, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3088239529804019e-05, 'get_actions': 2.8278614012758538e-05, 'remove_single_ts_time_rank_from_batch': 6.758607633762508e-07, 'tensor_to_numpy': 2.8720647724526815e-05, 'module_to_agent_unmapping': 2.184929760650954e-06, 'listify_data_for_vector_env': 6.032187486378959e-06, 'normalize_and_clip_actions': 3.092012914944373e-05}}, 'connector_pipeline_timer': 0.00013683956242274304}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3778097997964328e-05, 'numpy_to_tensor': 3.095190912326354e-05, 'agent_to_module_mapping': 5.20563889171436e-06, 'add_states_from_episodes_to_batch': 4.745955548191442e-06, 'add_observations_from_episodes_to_batch': 3.778315260005976e-05, 'batch_individual_items': 2.4990031536019625e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90291.06192657325, 'sample': 25.908538923420096, 'agent_episode_returns_mean': {'servicer': -90290.44958090282, 'target': -0.6123456704455612}, 'module_episode_returns_mean': {'servicer': -90290.44958090282, 'target': -0.6123456704455612}, 'num_module_steps_sampled_lifetime': {'servicer': 450000, 'target': 450000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.65439135883546e-05, 'connector_pipeline_timer': 0.0002430760469725521, 'env_reset_timer': 0.00015223494916385006, 'episode_len_mean': 10000.0, 'env_step_timer': 8.804813530361936e-05, 'episode_duration_sec_mean': 4.948284540850873, 'num_episodes_lifetime': 45, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.952903578843, 'time_between_sampling': 26.971023012531337}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 414000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1006.391892233225, 'done': False, 'training_iteration': 90, 'trial_id': 'default', 'date': '2025-04-03_22-38-44', 'timestamp': 1743734324, 'time_this_iter_s': 25.917713165283203, 'time_total_s': 470.5687165260315, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 470.5687165260315, 'iterations_since_restore': 90, 'perf': {'cpu_util_percent': 30.0891891891892, 'ram_util_percent': 53.35135135135135}}
2025-04-03 22:38:47,418 [__main__] [INFO] Iter: 91/100, Ts(iter): 0, Ts(total): 418600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.96s
2025-04-03 22:38:50,406 [__main__] [INFO] Iter: 92/100, Ts(iter): 0, Ts(total): 423200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.99s
2025-04-03 22:38:53,304 [__main__] [INFO] Iter: 93/100, Ts(iter): 0, Ts(total): 427800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.90s
2025-04-03 22:38:56,407 [__main__] [INFO] Iter: 94/100, Ts(iter): 0, Ts(total): 432400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.10s
2025-04-03 22:38:59,339 [__main__] [INFO] Iter: 95/100, Ts(iter): 0, Ts(total): 437000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.93s
2025-04-03 22:39:02,345 [__main__] [INFO] Iter: 96/100, Ts(iter): 0, Ts(total): 441600, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.01s
2025-04-03 22:39:05,342 [__main__] [INFO] Iter: 97/100, Ts(iter): 0, Ts(total): 446200, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.00s
2025-04-03 22:39:08,023 [__main__] [INFO] Iter: 98/100, Ts(iter): 0, Ts(total): 450800, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.68s
2025-04-03 22:39:10,612 [__main__] [INFO] Iter: 99/100, Ts(iter): 0, Ts(total): 455400, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.59s
2025-04-03 22:39:36,582 [__main__] [INFO] Iter: 100/100, Ts(iter): 0, Ts(total): 460000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 25.97s
2025-04-03 22:39:36,582 [__main__] [DEBUG] Full result dict at iter 100: {'timers': {'training_iteration': 2.9728569701574483, 'restore_env_runners': 1.2619276205908887e-05, 'training_step': 2.9727264213019082, 'env_runner_sampling_timer': 0.2546250020976511, 'learner_update_timer': 2.711462230349233, 'synch_weights': 0.005123671153569194, 'synch_env_connectors': 0.007149271281219212, 'restore_eval_env_runners': 5.454407066180291e-06, 'evaluation_iteration': 26.11670122876965, 'synch_eval_env_connectors': 0.001848218298033573}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 460000, 'servicer': 460000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.7932398937712838e-05, 'add_time_dim_to_batch_and_zero_pad': 6.868712801951246e-06, 'numpy_to_tensor': 2.974763748640729e-05, 'agent_to_module_mapping': 4.102287029794216e-06, 'add_states_from_episodes_to_batch': 4.068168320713701e-06, 'add_observations_from_episodes_to_batch': 1.5952479670171237e-05}}, 'connector_pipeline_timer': 0.0001148708899379172}, 'weights_seq_no': 99.0, 'num_env_steps_sampled_lifetime': 460000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.1328727767191983e-05, 'get_actions': 0.0001292532968664353, 'remove_single_ts_time_rank_from_batch': 1.145243972001606e-06, 'tensor_to_numpy': 4.757601985929339e-05, 'module_to_agent_unmapping': 3.6984145552466894e-06, 'listify_data_for_vector_env': 1.003375505153098e-05, 'normalize_and_clip_actions': 5.3045270604851763e-05}}, 'connector_pipeline_timer': 0.0003092483078503107}, 'env_to_module_sum_episodes_length_out': 131.52868528507187, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17836916841036182, 'num_module_steps_sampled_lifetime': {'servicer': 460000, 'target': 460000}, 'rlmodule_inference_timer': 0.00014839370678589877, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.00014623027874616123, 'env_to_module_sum_episodes_length_in': 131.52868528507187, 'time_between_sampling': 4.038161258717428, 'episode_return_min': -89194.10179660811, 'episode_return_max': -86767.4340663288, 'episode_len_max': 10000, 'episode_return_mean': -87846.28008955572, 'agent_episode_returns_mean': {'servicer': -87844.08919979943, 'target': -2.190889756272928}, 'module_episode_returns_mean': {'servicer': -87844.08919979943, 'target': -2.190889756272928}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'episode_len_mean': 10000.0, 'episode_duration_sec_mean': 8.727388898426991, 'num_episodes_lifetime': 46, 'num_episodes': 23, 'num_env_steps_sampled_lifetime_throughput': 971.4065941085784}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.024247809002106786, 'agent_to_module_mapping': 0.003891727611958139, 'add_states_from_episodes_to_batch': 4.890703655912086e-06, 'add_one_ts_to_episodes_and_truncate': 0.005405410307243709, 'add_columns_from_episodes_to_train_batch': 0.07737080095902207, 'add_observations_from_episodes_to_batch': 0.00021911590421108682, 'batch_individual_items': 0.07732572842867191, 'add_time_dim_to_batch_and_zero_pad': 1.80747855041105e-05, 'numpy_to_tensor': 0.00014754762221047462}}, 'connector_pipeline_timer': 0.188801408233407}, 'num_module_steps_trained_lifetime': 9267200, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 166520000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 16.910154342651367, 'gradients_default_optimizer_global_norm': 3.641533136367798, 'vf_loss': 1.8966578636536724e-06, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 4633600, 'policy_loss': 0.06886684894561768, 'vf_loss_unclipped': 1.8966578636536724e-06, 'total_loss': -0.2693343758583069, 'weights_seq_no': 100.0, 'curr_kl_coeff': 3.814697322468419e-07, 'vf_explained_var': 0.27143508195877075, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.009378152899444103}, 'servicer': {'num_module_steps_trained_lifetime': 4633600, 'vf_loss': 4.960937976837158, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': 0.02852305956184864, 'vf_loss_unclipped': 47162.4921875, 'total_loss': 4.783108234405518, 'weights_seq_no': 100.0, 'curr_kl_coeff': 7.275957722603643e-13, 'vf_explained_var': 2.1755695343017578e-05, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.006440537050366402, 'entropy': 10.317626953125, 'gradients_default_optimizer_global_norm': 3.3753318786621094}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 500000, 'servicer': 500000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.0219067085545059e-05, 'add_time_dim_to_batch_and_zero_pad': 3.538770024434226e-06, 'numpy_to_tensor': 1.5983038356599217e-05, 'agent_to_module_mapping': 2.4418206397801073e-06, 'add_states_from_episodes_to_batch': 2.6172868330929757e-06, 'add_observations_from_episodes_to_batch': 9.140214783960044e-06}}, 'connector_pipeline_timer': 6.65837970711773e-05}, 'episode_return_min': -90401.70479021194, 'weights_seq_no': 99.0, 'num_env_steps_sampled_lifetime': 500000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90112.67346572112, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3087756771086442e-05, 'get_actions': 2.8280325904248294e-05, 'remove_single_ts_time_rank_from_batch': 6.758211307868043e-07, 'tensor_to_numpy': 2.8724844058751083e-05, 'module_to_agent_unmapping': 2.1842192197067043e-06, 'listify_data_for_vector_env': 6.032178786211177e-06, 'normalize_and_clip_actions': 3.091420032878046e-05}}, 'connector_pipeline_timer': 0.00013683897105879923}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3774891495527886e-05, 'numpy_to_tensor': 3.0958950771987044e-05, 'agent_to_module_mapping': 5.205020161093911e-06, 'add_states_from_episodes_to_batch': 4.745037249790371e-06, 'add_observations_from_episodes_to_batch': 3.77714366961039e-05, 'batch_individual_items': 2.4987199109514696e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90275.24054432832, 'sample': 25.908328131480815, 'agent_episode_returns_mean': {'servicer': -90274.54608528697, 'target': -0.6944590413382643}, 'module_episode_returns_mean': {'servicer': -90274.54608528697, 'target': -0.6944590413382643}, 'num_module_steps_sampled_lifetime': {'servicer': 500000, 'target': 500000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.654798220864635e-05, 'connector_pipeline_timer': 0.00024299206124947628, 'env_reset_timer': 0.00015221365125080342, 'episode_len_mean': 10000.0, 'env_step_timer': 8.804818784161941e-05, 'episode_duration_sec_mean': 4.9483996317004495, 'num_episodes_lifetime': 50, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.9682120024352, 'time_between_sampling': 26.97086308517865}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 460000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 971.4065941085784, 'done': False, 'training_iteration': 100, 'trial_id': 'default', 'date': '2025-04-03_22-39-36', 'timestamp': 1743734376, 'time_this_iter_s': 25.958432912826538, 'time_total_s': 522.5529038906097, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 522.5529038906097, 'iterations_since_restore': 100, 'perf': {'cpu_util_percent': 28.883783783783773, 'ram_util_percent': 53.31351351351352}}
2025-04-03 22:39:36,600 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.9728569701574483, 'restore_env_runners': 1.2619276205908887e-05, 'training_step': 2.9727264213019082, 'env_runner_sampling_timer': 0.2546250020976511, 'learner_update_timer': 2.711462230349233, 'synch_weights': 0.005123671153569194, 'synch_env_connectors': 0.007149271281219212, 'restore_eval_env_runners': 5.454407066180291e-06, 'evaluation_iteration': 26.11670122876965, 'synch_eval_env_connectors': 0.001848218298033573}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 460000, 'servicer': 460000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.7932398937712838e-05, 'add_time_dim_to_batch_and_zero_pad': 6.868712801951246e-06, 'numpy_to_tensor': 2.974763748640729e-05, 'agent_to_module_mapping': 4.102287029794216e-06, 'add_states_from_episodes_to_batch': 4.068168320713701e-06, 'add_observations_from_episodes_to_batch': 1.5952479670171237e-05}}, 'connector_pipeline_timer': 0.0001148708899379172}, 'weights_seq_no': 99.0, 'num_env_steps_sampled_lifetime': 460000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.1328727767191983e-05, 'get_actions': 0.0001292532968664353, 'remove_single_ts_time_rank_from_batch': 1.145243972001606e-06, 'tensor_to_numpy': 4.757601985929339e-05, 'module_to_agent_unmapping': 3.6984145552466894e-06, 'listify_data_for_vector_env': 1.003375505153098e-05, 'normalize_and_clip_actions': 5.3045270604851763e-05}}, 'connector_pipeline_timer': 0.0003092483078503107}, 'env_to_module_sum_episodes_length_out': 131.52868528507187, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17836916841036182, 'num_module_steps_sampled_lifetime': {'servicer': 460000, 'target': 460000}, 'rlmodule_inference_timer': 0.00014839370678589877, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.00014623027874616123, 'env_to_module_sum_episodes_length_in': 131.52868528507187, 'time_between_sampling': 4.038161258717428, 'episode_return_min': -89194.10179660811, 'episode_return_max': -86767.4340663288, 'episode_len_max': 10000, 'episode_return_mean': -87846.28008955572, 'agent_episode_returns_mean': {'servicer': -87844.08919979943, 'target': -2.190889756272928}, 'module_episode_returns_mean': {'servicer': -87844.08919979943, 'target': -2.190889756272928}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'episode_len_mean': 10000.0, 'episode_duration_sec_mean': 8.727388898426991, 'num_episodes_lifetime': 46, 'num_episodes': 23, 'num_env_steps_sampled_lifetime_throughput': 971.4065941085784}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.024247809002106786, 'agent_to_module_mapping': 0.003891727611958139, 'add_states_from_episodes_to_batch': 4.890703655912086e-06, 'add_one_ts_to_episodes_and_truncate': 0.005405410307243709, 'add_columns_from_episodes_to_train_batch': 0.07737080095902207, 'add_observations_from_episodes_to_batch': 0.00021911590421108682, 'batch_individual_items': 0.07732572842867191, 'add_time_dim_to_batch_and_zero_pad': 1.80747855041105e-05, 'numpy_to_tensor': 0.00014754762221047462}}, 'connector_pipeline_timer': 0.188801408233407}, 'num_module_steps_trained_lifetime': 9267200, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 166520000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 16.910154342651367, 'gradients_default_optimizer_global_norm': 3.641533136367798, 'vf_loss': 1.8966578636536724e-06, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 4633600, 'policy_loss': 0.06886684894561768, 'vf_loss_unclipped': 1.8966578636536724e-06, 'total_loss': -0.2693343758583069, 'weights_seq_no': 100.0, 'curr_kl_coeff': 3.814697322468419e-07, 'vf_explained_var': 0.27143508195877075, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.009378152899444103}, 'servicer': {'num_module_steps_trained_lifetime': 4633600, 'vf_loss': 4.960937976837158, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': 0.02852305956184864, 'vf_loss_unclipped': 47162.4921875, 'total_loss': 4.783108234405518, 'weights_seq_no': 100.0, 'curr_kl_coeff': 7.275957722603643e-13, 'vf_explained_var': 2.1755695343017578e-05, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.006440537050366402, 'entropy': 10.317626953125, 'gradients_default_optimizer_global_norm': 3.3753318786621094}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 500000, 'servicer': 500000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.0219067085545059e-05, 'add_time_dim_to_batch_and_zero_pad': 3.538770024434226e-06, 'numpy_to_tensor': 1.5983038356599217e-05, 'agent_to_module_mapping': 2.4418206397801073e-06, 'add_states_from_episodes_to_batch': 2.6172868330929757e-06, 'add_observations_from_episodes_to_batch': 9.140214783960044e-06}}, 'connector_pipeline_timer': 6.65837970711773e-05}, 'episode_return_min': -90401.70479021194, 'weights_seq_no': 99.0, 'num_env_steps_sampled_lifetime': 500000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90112.67346572112, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3087756771086442e-05, 'get_actions': 2.8280325904248294e-05, 'remove_single_ts_time_rank_from_batch': 6.758211307868043e-07, 'tensor_to_numpy': 2.8724844058751083e-05, 'module_to_agent_unmapping': 2.1842192197067043e-06, 'listify_data_for_vector_env': 6.032178786211177e-06, 'normalize_and_clip_actions': 3.091420032878046e-05}}, 'connector_pipeline_timer': 0.00013683897105879923}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3774891495527886e-05, 'numpy_to_tensor': 3.0958950771987044e-05, 'agent_to_module_mapping': 5.205020161093911e-06, 'add_states_from_episodes_to_batch': 4.745037249790371e-06, 'add_observations_from_episodes_to_batch': 3.77714366961039e-05, 'batch_individual_items': 2.4987199109514696e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90275.24054432832, 'sample': 25.908328131480815, 'agent_episode_returns_mean': {'servicer': -90274.54608528697, 'target': -0.6944590413382643}, 'module_episode_returns_mean': {'servicer': -90274.54608528697, 'target': -0.6944590413382643}, 'num_module_steps_sampled_lifetime': {'servicer': 500000, 'target': 500000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.654798220864635e-05, 'connector_pipeline_timer': 0.00024299206124947628, 'env_reset_timer': 0.00015221365125080342, 'episode_len_mean': 10000.0, 'env_step_timer': 8.804818784161941e-05, 'episode_duration_sec_mean': 4.9483996317004495, 'num_episodes_lifetime': 50, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.9682120024352, 'time_between_sampling': 26.97086308517865}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 460000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 971.4065941085784, 'done': False, 'training_iteration': 100, 'trial_id': 'default', 'date': '2025-04-03_22-39-36', 'timestamp': 1743734376, 'time_this_iter_s': 25.958432912826538, 'time_total_s': 522.5529038906097, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 522.5529038906097, 'iterations_since_restore': 100, 'perf': {'cpu_util_percent': 28.883783783783773, 'ram_util_percent': 53.31351351351352}})
2025-04-03 22:39:36,601 [__main__] [INFO] 
--- Training Finished ---
2025-04-03 22:39:36,601 [__main__] [INFO] Total Training Time: 523.91 seconds
2025-04-03 22:39:36,601 [__main__] [INFO] Using last checkpoint: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.9728569701574483, 'restore_env_runners': 1.2619276205908887e-05, 'training_step': 2.9727264213019082, 'env_runner_sampling_timer': 0.2546250020976511, 'learner_update_timer': 2.711462230349233, 'synch_weights': 0.005123671153569194, 'synch_env_connectors': 0.007149271281219212, 'restore_eval_env_runners': 5.454407066180291e-06, 'evaluation_iteration': 26.11670122876965, 'synch_eval_env_connectors': 0.001848218298033573}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 460000, 'servicer': 460000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.7932398937712838e-05, 'add_time_dim_to_batch_and_zero_pad': 6.868712801951246e-06, 'numpy_to_tensor': 2.974763748640729e-05, 'agent_to_module_mapping': 4.102287029794216e-06, 'add_states_from_episodes_to_batch': 4.068168320713701e-06, 'add_observations_from_episodes_to_batch': 1.5952479670171237e-05}}, 'connector_pipeline_timer': 0.0001148708899379172}, 'weights_seq_no': 99.0, 'num_env_steps_sampled_lifetime': 460000, 'num_module_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_agent_steps_sampled': {'target': 4600, 'servicer': 4600}, 'num_env_steps_sampled': 4600, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 2.1328727767191983e-05, 'get_actions': 0.0001292532968664353, 'remove_single_ts_time_rank_from_batch': 1.145243972001606e-06, 'tensor_to_numpy': 4.757601985929339e-05, 'module_to_agent_unmapping': 3.6984145552466894e-06, 'listify_data_for_vector_env': 1.003375505153098e-05, 'normalize_and_clip_actions': 5.3045270604851763e-05}}, 'connector_pipeline_timer': 0.0003092483078503107}, 'env_to_module_sum_episodes_length_out': 131.52868528507187, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 4.5246347840672925e-05, 'numpy_to_tensor': 0.00012070113355192639, 'agent_to_module_mapping': 6.621478267175996e-06, 'add_states_from_episodes_to_batch': 7.139477732024439e-06, 'add_observations_from_episodes_to_batch': 4.109239165225755e-05, 'batch_individual_items': 3.375913112667268e-05}}, 'sample': 0.17836916841036182, 'num_module_steps_sampled_lifetime': {'servicer': 460000, 'target': 460000}, 'rlmodule_inference_timer': 0.00014839370678589877, 'connector_pipeline_timer': 0.00041102352185154575, 'env_reset_timer': 0.0002487752613176227, 'env_step_timer': 0.00014623027874616123, 'env_to_module_sum_episodes_length_in': 131.52868528507187, 'time_between_sampling': 4.038161258717428, 'episode_return_min': -89194.10179660811, 'episode_return_max': -86767.4340663288, 'episode_len_max': 10000, 'episode_return_mean': -87846.28008955572, 'agent_episode_returns_mean': {'servicer': -87844.08919979943, 'target': -2.190889756272928}, 'module_episode_returns_mean': {'servicer': -87844.08919979943, 'target': -2.190889756272928}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'episode_len_mean': 10000.0, 'episode_duration_sec_mean': 8.727388898426991, 'num_episodes_lifetime': 46, 'num_episodes': 23, 'num_env_steps_sampled_lifetime_throughput': 971.4065941085784}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'general_advantage_estimation': 0.024247809002106786, 'agent_to_module_mapping': 0.003891727611958139, 'add_states_from_episodes_to_batch': 4.890703655912086e-06, 'add_one_ts_to_episodes_and_truncate': 0.005405410307243709, 'add_columns_from_episodes_to_train_batch': 0.07737080095902207, 'add_observations_from_episodes_to_batch': 0.00021911590421108682, 'batch_individual_items': 0.07732572842867191, 'add_time_dim_to_batch_and_zero_pad': 1.80747855041105e-05, 'numpy_to_tensor': 0.00014754762221047462}}, 'connector_pipeline_timer': 0.188801408233407}, 'num_module_steps_trained_lifetime': 9267200, 'num_module_steps_trained': 92672, 'learner_connector_sum_episodes_length_out': 4600.0, 'num_env_steps_trained_lifetime': 166520000, 'num_trainable_parameters': 284186.0, 'learner_connector_sum_episodes_length_in': 4600.0, 'num_env_steps_trained': 1665200, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 16.910154342651367, 'gradients_default_optimizer_global_norm': 3.641533136367798, 'vf_loss': 1.8966578636536724e-06, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'num_module_steps_trained_lifetime': 4633600, 'policy_loss': 0.06886684894561768, 'vf_loss_unclipped': 1.8966578636536724e-06, 'total_loss': -0.2693343758583069, 'weights_seq_no': 100.0, 'curr_kl_coeff': 3.814697322468419e-07, 'vf_explained_var': 0.27143508195877075, 'curr_entropy_coeff': 0.02, 'module_train_batch_size_mean': 128.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'num_trainable_parameters': 142093.0, 'mean_kl_loss': 0.009378152899444103}, 'servicer': {'num_module_steps_trained_lifetime': 4633600, 'vf_loss': 4.960937976837158, 'num_module_steps_trained': 46336, 'default_optimizer_learning_rate': 1e-05, 'policy_loss': 0.02852305956184864, 'vf_loss_unclipped': 47162.4921875, 'total_loss': 4.783108234405518, 'weights_seq_no': 100.0, 'curr_kl_coeff': 7.275957722603643e-13, 'vf_explained_var': 2.1755695343017578e-05, 'module_train_batch_size_mean': 128.0, 'curr_entropy_coeff': 0.02, 'num_trainable_parameters': 142093.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.006440537050366402, 'entropy': 10.317626953125, 'gradients_default_optimizer_global_norm': 3.3753318786621094}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_agent_steps_sampled_lifetime': {'target': 500000, 'servicer': 500000}, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': 1.0219067085545059e-05, 'add_time_dim_to_batch_and_zero_pad': 3.538770024434226e-06, 'numpy_to_tensor': 1.5983038356599217e-05, 'agent_to_module_mapping': 2.4418206397801073e-06, 'add_states_from_episodes_to_batch': 2.6172868330929757e-06, 'add_observations_from_episodes_to_batch': 9.140214783960044e-06}}, 'connector_pipeline_timer': 6.65837970711773e-05}, 'episode_return_min': -90401.70479021194, 'weights_seq_no': 99.0, 'num_env_steps_sampled_lifetime': 500000, 'num_module_steps_sampled': {'target': 50000, 'servicer': 50000}, 'episode_return_max': -90112.67346572112, 'num_agent_steps_sampled': {'target': 50000, 'servicer': 50000}, 'num_env_steps_sampled': 50000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': 1.3087756771086442e-05, 'get_actions': 2.8280325904248294e-05, 'remove_single_ts_time_rank_from_batch': 6.758211307868043e-07, 'tensor_to_numpy': 2.8724844058751083e-05, 'module_to_agent_unmapping': 2.1842192197067043e-06, 'listify_data_for_vector_env': 6.032178786211177e-06, 'normalize_and_clip_actions': 3.091420032878046e-05}}, 'connector_pipeline_timer': 0.00013683897105879923}, 'env_to_module_sum_episodes_length_out': 9900.999999999995, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.3774891495527886e-05, 'numpy_to_tensor': 3.0958950771987044e-05, 'agent_to_module_mapping': 5.205020161093911e-06, 'add_states_from_episodes_to_batch': 4.745037249790371e-06, 'add_observations_from_episodes_to_batch': 3.77714366961039e-05, 'batch_individual_items': 2.4987199109514696e-05}}, 'episode_len_max': 10000, 'episode_return_mean': -90275.24054432832, 'sample': 25.908328131480815, 'agent_episode_returns_mean': {'servicer': -90274.54608528697, 'target': -0.6944590413382643}, 'module_episode_returns_mean': {'servicer': -90274.54608528697, 'target': -0.6944590413382643}, 'num_module_steps_sampled_lifetime': {'servicer': 500000, 'target': 500000}, 'agent_steps': {'servicer': 10000.0, 'target': 10000.0}, 'episode_len_min': 10000, 'rlmodule_inference_timer': 8.654798220864635e-05, 'connector_pipeline_timer': 0.00024299206124947628, 'env_reset_timer': 0.00015221365125080342, 'episode_len_mean': 10000.0, 'env_step_timer': 8.804818784161941e-05, 'episode_duration_sec_mean': 4.9483996317004495, 'num_episodes_lifetime': 50, 'env_to_module_sum_episodes_length_in': 9900.999999999995, 'num_episodes': 5, 'num_env_steps_sampled_per_second': 1912.9682120024352, 'time_between_sampling': 26.97086308517865}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 460000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 971.4065941085784, 'done': False, 'training_iteration': 100, 'trial_id': 'default', 'date': '2025-04-03_22-39-36', 'timestamp': 1743734376, 'time_this_iter_s': 25.958432912826538, 'time_total_s': 522.5529038906097, 'pid': 85181, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.96, 'lr': 1e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4600, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x35e8d8360>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'INFO', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 5.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 522.5529038906097, 'iterations_since_restore': 100, 'perf': {'cpu_util_percent': 28.883783783783773, 'ram_util_percent': 53.31351351351352}})
2025-04-03 22:39:36,602 [__main__] [INFO] 
--- Running Evaluation & Recording Video ---
2025-04-03 22:39:36,603 [__main__] [INFO] Successfully retrieved RLModules for evaluation.
2025-04-03 22:39:36,603 [__main__] [INFO] Evaluation Episode: 1/5
2025-04-03 22:39:36,683 [src.satellite_marl_env] [INFO] MuJoCo Renderer initialized for rgb_array.
2025-04-03 22:40:04,647 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 22:40:04,651 [__main__] [INFO] Evaluation Episode 1 Rewards: {'servicer': -3111477.134472071, 'target': -1.4012876635700522}
2025-04-03 22:40:04,651 [__main__] [INFO] Evaluation Episode: 2/5
2025-04-03 22:40:33,110 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 22:40:33,114 [__main__] [INFO] Evaluation Episode 2 Rewards: {'servicer': -3111477.134472071, 'target': -1.4012876635700522}
2025-04-03 22:40:33,114 [__main__] [INFO] Evaluation Episode: 3/5
2025-04-03 22:41:01,625 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 22:41:01,628 [__main__] [INFO] Evaluation Episode 3 Rewards: {'servicer': -3111477.134472071, 'target': -1.4012876635700522}
2025-04-03 22:41:01,629 [__main__] [INFO] Evaluation Episode: 4/5
2025-04-03 22:41:30,705 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 22:41:30,708 [__main__] [INFO] Evaluation Episode 4 Rewards: {'servicer': -3111477.134472071, 'target': -1.4012876635700522}
2025-04-03 22:41:30,708 [__main__] [INFO] Evaluation Episode: 5/5
2025-04-03 22:42:00,102 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 22:42:00,106 [__main__] [INFO] Evaluation Episode 5 Rewards: {'servicer': -3111477.134472071, 'target': -1.4012876635700522}
2025-04-03 22:42:00,118 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 22:42:00,118 [__main__] [INFO] Average Evaluation Rewards over 5 episodes: {'servicer': -3111477.134472071, 'target': -1.4012876635700522}
2025-04-03 22:42:00,119 [__main__] [INFO] Saving evaluation video to: /Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results/evaluation_video.mp4
2025-04-03 22:42:34,259 [__main__] [INFO] Shutting down Ray...
2025-04-03 22:42:34,965 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 22:42:34,997 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 22:42:37,255 [__main__] [INFO] Script finished.
