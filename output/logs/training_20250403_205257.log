2025-04-03 20:52:57,357 [__main__] [INFO] Initializing Ray...
2025-04-03 20:53:03,796 [__main__] [INFO] Creating temporary environment to get action/observation spaces...
2025-04-03 20:53:03,798 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 20:53:03,798 [__main__] [INFO] Spaces retrieved.
2025-04-03 20:53:03,798 [__main__] [INFO] Configuring RLlib PPO Algorithm...
2025-04-03 20:53:03,799 [__main__] [INFO] Using 23 environment runners (workers).
2025-04-03 20:53:03,799 [__main__] [INFO] Building Algorithm...
2025-04-03 20:53:17,330 [__main__] [INFO] Algorithm Built. Using Policy/Module Class: DefaultPPOTorchRLModule
2025-04-03 20:53:17,330 [__main__] [INFO] 
--- Starting Training for 100 iterations ---
2025-04-03 20:53:19,721 [__main__] [INFO] Iter: 1/100, Ts(iter): 0, Ts(total): 4000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.39s
2025-04-03 20:53:22,315 [__main__] [INFO] Iter: 2/100, Ts(iter): 0, Ts(total): 8000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.59s
2025-04-03 20:53:24,697 [__main__] [INFO] Iter: 3/100, Ts(iter): 0, Ts(total): 12000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.38s
2025-04-03 20:53:27,332 [__main__] [INFO] Iter: 4/100, Ts(iter): 0, Ts(total): 16000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.63s
2025-04-03 20:53:29,755 [__main__] [INFO] Iter: 5/100, Ts(iter): 0, Ts(total): 20000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.42s
2025-04-03 20:53:32,495 [__main__] [INFO] Iter: 6/100, Ts(iter): 0, Ts(total): 24000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.74s
2025-04-03 20:53:34,804 [__main__] [INFO] Iter: 7/100, Ts(iter): 0, Ts(total): 28000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.31s
2025-04-03 20:53:37,500 [__main__] [INFO] Iter: 8/100, Ts(iter): 0, Ts(total): 32000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.70s
2025-04-03 20:53:39,966 [__main__] [INFO] Iter: 9/100, Ts(iter): 0, Ts(total): 36000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.47s
2025-04-03 20:53:43,419 [__main__] [INFO] Iter: 10/100, Ts(iter): 0, Ts(total): 40000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.45s
2025-04-03 20:53:46,062 [__main__] [INFO] Iter: 11/100, Ts(iter): 0, Ts(total): 44000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.64s
2025-04-03 20:53:48,392 [__main__] [INFO] Iter: 12/100, Ts(iter): 0, Ts(total): 48000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.33s
2025-04-03 20:53:50,906 [__main__] [INFO] Iter: 13/100, Ts(iter): 0, Ts(total): 52000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.51s
2025-04-03 20:53:53,202 [__main__] [INFO] Iter: 14/100, Ts(iter): 0, Ts(total): 56000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.30s
2025-04-03 20:53:55,968 [__main__] [INFO] Iter: 15/100, Ts(iter): 0, Ts(total): 60000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.77s
2025-04-03 20:53:58,340 [__main__] [INFO] Iter: 16/100, Ts(iter): 0, Ts(total): 64000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.37s
2025-04-03 20:54:00,841 [__main__] [INFO] Iter: 17/100, Ts(iter): 0, Ts(total): 68000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.50s
2025-04-03 20:54:03,367 [__main__] [INFO] Iter: 18/100, Ts(iter): 0, Ts(total): 72000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.53s
2025-04-03 20:54:05,902 [__main__] [INFO] Iter: 19/100, Ts(iter): 0, Ts(total): 76000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.54s
2025-04-03 20:54:09,583 [__main__] [INFO] Iter: 20/100, Ts(iter): 0, Ts(total): 80000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.68s
2025-04-03 20:54:09,599 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.4131270657979833, 'restore_env_runners': 1.7774074843766695e-05, 'training_step': 2.412998921557554, 'env_runner_sampling_timer': 0.27405330918783394, 'learner_update_timer': 2.132572965871428, 'synch_weights': 0.005225555399316032, 'synch_env_connectors': 0.007414417325032576, 'restore_eval_env_runners': 4.877928004134446e-06, 'evaluation_iteration': 2.9784083620928867, 'synch_eval_env_connectors': 0.005920272495422978}, 'env_runners': {'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 9.78103551707893e-06, 'remove_single_ts_time_rank_from_batch': 1.1792991842770216e-06, 'normalize_and_clip_actions': 5.3580558650732484e-05, 'un_batch_to_individual_items': 2.103733808298771e-05, 'tensor_to_numpy': 4.867808372232355e-05, 'module_to_agent_unmapping': 4.077211396820393e-06, 'get_actions': 0.00013205316074560772}}, 'connector_pipeline_timer': 0.00031529440670179906}, 'env_to_module_connector': {'timers': {'connectors': {'numpy_to_tensor': 3.0412060541742436e-05, 'add_time_dim_to_batch_and_zero_pad': 6.834609472614042e-06, 'agent_to_module_mapping': 4.3803851070104455e-06, 'add_observations_from_episodes_to_batch': 1.6300024143527357e-05, 'add_states_from_episodes_to_batch': 4.024243304456543e-06, 'batch_individual_items': 1.8093726365024654e-05}}, 'connector_pipeline_timer': 0.00011687700828211176}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 2.164330394209727e-05, 'agent_to_module_mapping': 7.999872373740958e-06, 'add_observations_from_episodes_to_batch': 4.4463781903133444e-05, 'add_states_from_episodes_to_batch': 1.0095915058627725e-05, 'batch_individual_items': 4.1965784317732826e-05, 'numpy_to_tensor': 6.50053483221437e-05}}, 'env_to_module_sum_episodes_length_out': 103.42885547936852, 'num_module_steps_sampled': {'target': 4000, 'servicer': 4000}, 'num_module_steps_sampled_lifetime': {'target': 80000, 'servicer': 80000}, 'rlmodule_inference_timer': 0.00014808748811790572, 'sample': 0.1714651555203754, 'num_agent_steps_sampled_lifetime': {'target': 80000, 'servicer': 80000}, 'num_agent_steps_sampled': {'target': 4000, 'servicer': 4000}, 'connector_pipeline_timer': 0.0003582426946630458, 'num_env_steps_sampled': 4000, 'env_reset_timer': 0.00022803252352826783, 'num_env_steps_sampled_lifetime': 80000, 'weights_seq_no': 19.0, 'env_step_timer': 0.00014140186036666648, 'env_to_module_sum_episodes_length_in': 103.42885547936852, 'time_between_sampling': 2.2433462494254, 'agent_episode_returns_mean': {'servicer': -1113.7138355702205, 'target': -18.409277306898776}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'module_episode_returns_mean': {'target': -18.409277306898776, 'servicer': -1113.7138355702205}, 'episode_len_max': 1000, 'episode_return_min': -1143.9744942489256, 'episode_duration_sec_mean': 0.8365753026541232, 'num_episodes': 0, 'num_episodes_lifetime': 69, 'episode_len_min': 1000, 'episode_return_max': -1118.3161518102913, 'episode_return_mean': -1132.1231128771192, 'episode_len_mean': 1000.0, 'num_env_steps_sampled_lifetime_throughput': 1086.4641807523226}, 'learners': {'target': {'vf_explained_var': 0.1655176281929016, 'vf_loss': 0.15572646260261536, 'total_loss': 0.016887281090021133, 'num_module_steps_trained_lifetime': 807168, 'num_trainable_parameters': 142093.0, 'curr_kl_coeff': 0.00019531250291038305, 'num_module_steps_trained': 40320, 'policy_loss': 0.059808507561683655, 'default_optimizer_learning_rate': 5e-05, 'module_train_batch_size_mean': 128.0, 'entropy': 9.932453155517578, 'curr_entropy_coeff': 0.02, 'weights_seq_no': 20.0, 'gradients_default_optimizer_global_norm': 1.4925786256790161, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.003600897267460823, 'vf_loss_unclipped': 0.15572646260261536}, 'servicer': {'default_optimizer_learning_rate': 5e-05, 'policy_loss': 0.03344006463885307, 'module_train_batch_size_mean': 128.0, 'entropy': 10.099180221557617, 'curr_entropy_coeff': 0.02, 'gradients_default_optimizer_global_norm': 1.4760792255401611, 'weights_seq_no': 20.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.005108306650072336, 'vf_loss_unclipped': 3700.589599609375, 'vf_explained_var': -0.0004994869232177734, 'vf_loss': 9.884424209594727, 'total_loss': 9.715911865234375, 'num_module_steps_trained_lifetime': 807168, 'num_module_steps_trained': 40320, 'curr_kl_coeff': 0.0062500000931322575, 'num_trainable_parameters': 142093.0}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'batch_individual_items': 0.06134956930227371, 'general_advantage_estimation': 0.025621791740286594, 'add_one_ts_to_episodes_and_truncate': 0.004968982058490938, 'numpy_to_tensor': 0.00017191769542197622, 'add_time_dim_to_batch_and_zero_pad': 2.399547951037985e-05, 'agent_to_module_mapping': 0.0032690830582117417, 'add_observations_from_episodes_to_batch': 0.00021809813512343323, 'add_columns_from_episodes_to_train_batch': 0.06754016127798117, 'add_states_from_episodes_to_batch': 5.595114064443754e-06}}, 'connector_pipeline_timer': 0.16337291418529037}, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained': 80640, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime': 25224000, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_module_steps_trained_lifetime': 1614336, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'agent_episode_returns_mean': {'servicer': -1124.2614809250288, 'target': -4.385430716474848}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 6.856119378126177e-06, 'remove_single_ts_time_rank_from_batch': 7.881453827739682e-07, 'normalize_and_clip_actions': 3.417917411259386e-05, 'un_batch_to_individual_items': 1.4453564996350033e-05, 'tensor_to_numpy': 3.271277050338904e-05, 'module_to_agent_unmapping': 2.50382836389179e-06, 'get_actions': 3.426627793767199e-05}}, 'connector_pipeline_timer': 0.00015598526927040763}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'env_to_module_connector': {'timers': {'connectors': {'numpy_to_tensor': 1.8494558968170255e-05, 'add_time_dim_to_batch_and_zero_pad': 3.9901745292013725e-06, 'agent_to_module_mapping': 2.8270008342531863e-06, 'add_observations_from_episodes_to_batch': 1.076477050504419e-05, 'add_states_from_episodes_to_batch': 2.895384007424474e-06, 'batch_individual_items': 1.1446426000213958e-05}}, 'connector_pipeline_timer': 7.553300017493344e-05}, 'module_episode_returns_mean': {'target': -4.385430716474848, 'servicer': -1124.2614809250288}, 'episode_len_max': 1000, 'episode_return_min': -1130.006928558732, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.8290159142634366e-05, 'agent_to_module_mapping': 7.791697532229592e-06, 'add_observations_from_episodes_to_batch': 4.0873143151111434e-05, 'add_states_from_episodes_to_batch': 7.08264511777088e-06, 'batch_individual_items': 3.628947353427065e-05, 'numpy_to_tensor': 4.1125074155570475e-05}}, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'num_module_steps_sampled': {'target': 5000, 'servicer': 5000}, 'num_module_steps_sampled_lifetime': {'target': 10000, 'servicer': 10000}, 'episode_duration_sec_mean': 0.541897127602715, 'rlmodule_inference_timer': 0.00010549932142030263, 'sample': 2.778118636233482, 'num_agent_steps_sampled_lifetime': {'target': 10000, 'servicer': 10000}, 'num_agent_steps_sampled': {'target': 5000, 'servicer': 5000}, 'connector_pipeline_timer': 0.00027415282414440295, 'num_env_steps_sampled': 5000, 'num_episodes': 5, 'num_episodes_lifetime': 10, 'episode_len_min': 1000, 'episode_return_max': -1127.9669031828894, 'env_reset_timer': 0.00021440714118798495, 'episode_return_mean': -1128.6469116415035, 'num_env_steps_sampled_lifetime': 10000, 'weights_seq_no': 19.0, 'env_step_timer': 9.297082709101681e-05, 'episode_len_mean': 1000.0, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'num_env_steps_sampled_per_second': 1679.0818679527847, 'time_between_sampling': 23.159863249995396}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 80000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1086.4641807523226, 'done': False, 'training_iteration': 20, 'trial_id': 'default', 'date': '2025-04-03_20-54-09', 'timestamp': 1743728049, 'time_this_iter_s': 3.667263984680176, 'time_total_s': 52.008188009262085, 'pid': 77277, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x3758dc540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 52.008188009262085, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 77.38333333333334, 'ram_util_percent': 53.199999999999996}})
2025-04-03 20:54:12,371 [__main__] [INFO] Iter: 21/100, Ts(iter): 0, Ts(total): 84000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.77s
2025-04-03 20:54:14,832 [__main__] [INFO] Iter: 22/100, Ts(iter): 0, Ts(total): 88000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.46s
2025-04-03 20:54:17,564 [__main__] [INFO] Iter: 23/100, Ts(iter): 0, Ts(total): 92000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.73s
2025-04-03 20:54:20,103 [__main__] [INFO] Iter: 24/100, Ts(iter): 0, Ts(total): 96000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.54s
2025-04-03 20:54:22,526 [__main__] [INFO] Iter: 25/100, Ts(iter): 0, Ts(total): 100000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.42s
2025-04-03 20:54:25,200 [__main__] [INFO] Iter: 26/100, Ts(iter): 0, Ts(total): 104000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.67s
2025-04-03 20:54:27,845 [__main__] [INFO] Iter: 27/100, Ts(iter): 0, Ts(total): 108000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.65s
2025-04-03 20:54:30,459 [__main__] [INFO] Iter: 28/100, Ts(iter): 0, Ts(total): 112000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.61s
2025-04-03 20:54:33,061 [__main__] [INFO] Iter: 29/100, Ts(iter): 0, Ts(total): 116000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.60s
2025-04-03 20:54:36,700 [__main__] [INFO] Iter: 30/100, Ts(iter): 0, Ts(total): 120000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.64s
2025-04-03 20:54:39,175 [__main__] [INFO] Iter: 31/100, Ts(iter): 0, Ts(total): 124000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.48s
2025-04-03 20:54:41,571 [__main__] [INFO] Iter: 32/100, Ts(iter): 0, Ts(total): 128000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.40s
2025-04-03 20:54:44,013 [__main__] [INFO] Iter: 33/100, Ts(iter): 0, Ts(total): 132000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.44s
2025-04-03 20:54:46,623 [__main__] [INFO] Iter: 34/100, Ts(iter): 0, Ts(total): 136000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.61s
2025-04-03 20:54:49,231 [__main__] [INFO] Iter: 35/100, Ts(iter): 0, Ts(total): 140000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.61s
2025-04-03 20:54:51,996 [__main__] [INFO] Iter: 36/100, Ts(iter): 0, Ts(total): 144000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.77s
2025-04-03 20:54:54,586 [__main__] [INFO] Iter: 37/100, Ts(iter): 0, Ts(total): 148000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.59s
2025-04-03 20:54:57,215 [__main__] [INFO] Iter: 38/100, Ts(iter): 0, Ts(total): 152000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.63s
2025-04-03 20:54:59,612 [__main__] [INFO] Iter: 39/100, Ts(iter): 0, Ts(total): 156000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.40s
2025-04-03 20:55:03,246 [__main__] [INFO] Iter: 40/100, Ts(iter): 0, Ts(total): 160000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.63s
2025-04-03 20:55:03,263 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.4582511053480562, 'restore_env_runners': 1.605629844837239e-05, 'training_step': 2.4581216270401787, 'env_runner_sampling_timer': 0.2624587326496276, 'learner_update_timer': 2.1892370596993964, 'synch_weights': 0.005173793421832694, 'synch_env_connectors': 0.0074321809487089, 'restore_eval_env_runners': 4.878678847540868e-06, 'evaluation_iteration': 2.9782731837563885, 'synch_eval_env_connectors': 0.005830051200259214}, 'env_runners': {'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 1.0411643409305859e-05, 'remove_single_ts_time_rank_from_batch': 1.1381609674964356e-06, 'normalize_and_clip_actions': 5.422367900807287e-05, 'un_batch_to_individual_items': 2.167724416417769e-05, 'tensor_to_numpy': 4.833693467912595e-05, 'module_to_agent_unmapping': 3.966083068906587e-06, 'get_actions': 0.00013117543552635064}}, 'connector_pipeline_timer': 0.0003157814087034397}, 'env_to_module_connector': {'timers': {'connectors': {'numpy_to_tensor': 3.060606674253899e-05, 'add_time_dim_to_batch_and_zero_pad': 6.573339580431243e-06, 'agent_to_module_mapping': 4.357135470001604e-06, 'add_observations_from_episodes_to_batch': 1.6354160442812562e-05, 'add_states_from_episodes_to_batch': 4.093742499136755e-06, 'batch_individual_items': 1.828113493587839e-05}}, 'connector_pipeline_timer': 0.0001166379363784618}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 2.164330394209727e-05, 'agent_to_module_mapping': 7.999872373740958e-06, 'add_observations_from_episodes_to_batch': 4.4463781903133444e-05, 'add_states_from_episodes_to_batch': 1.0095915058627725e-05, 'batch_individual_items': 4.1965784317732826e-05, 'numpy_to_tensor': 6.50053483221437e-05}}, 'env_to_module_sum_episodes_length_out': 106.27241732416265, 'num_module_steps_sampled': {'target': 4000, 'servicer': 4000}, 'num_module_steps_sampled_lifetime': {'target': 160000, 'servicer': 160000}, 'rlmodule_inference_timer': 0.0001498810205610345, 'sample': 0.169124435489881, 'num_agent_steps_sampled_lifetime': {'target': 160000, 'servicer': 160000}, 'num_agent_steps_sampled': {'target': 4000, 'servicer': 4000}, 'connector_pipeline_timer': 0.0003582426946630458, 'num_env_steps_sampled': 4000, 'env_reset_timer': 0.00022803252352826783, 'num_env_steps_sampled_lifetime': 160000, 'weights_seq_no': 39.0, 'env_step_timer': 0.0001427431975814047, 'env_to_module_sum_episodes_length_in': 106.27241732416265, 'time_between_sampling': 2.2926222140081074, 'agent_episode_returns_mean': {'servicer': -1119.2245500850252, 'target': -19.66490278464297}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'module_episode_returns_mean': {'target': -19.66490278464297, 'servicer': -1119.2245500850252}, 'episode_len_max': 1000, 'episode_return_min': -1148.3892427239746, 'episode_duration_sec_mean': 0.8741032426522629, 'num_episodes': 0, 'num_episodes_lifetime': 138, 'episode_len_min': 1000, 'episode_return_max': -1125.5035079493884, 'episode_return_mean': -1138.8894528696678, 'episode_len_mean': 1000.0, 'num_env_steps_sampled_lifetime_throughput': 1100.1137297849207}, 'learners': {'target': {'vf_explained_var': 0.4616277813911438, 'vf_loss': 0.11463955789804459, 'total_loss': -0.053707513958215714, 'num_module_steps_trained_lifetime': 1614208, 'num_trainable_parameters': 142093.0, 'curr_kl_coeff': 6.10351571594947e-06, 'num_module_steps_trained': 40320, 'policy_loss': 0.06133480370044708, 'default_optimizer_learning_rate': 5e-05, 'module_train_batch_size_mean': 128.0, 'entropy': 11.484098434448242, 'curr_entropy_coeff': 0.02, 'weights_seq_no': 40.0, 'gradients_default_optimizer_global_norm': 1.6987992525100708, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.012053834274411201, 'vf_loss_unclipped': 0.11463955789804459}, 'servicer': {'default_optimizer_learning_rate': 5e-05, 'policy_loss': 0.05420760437846184, 'module_train_batch_size_mean': 128.0, 'entropy': 10.341113090515137, 'curr_entropy_coeff': 0.02, 'gradients_default_optimizer_global_norm': 0.9978891611099243, 'weights_seq_no': 40.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.007269170135259628, 'vf_loss_unclipped': 4024.657958984375, 'vf_explained_var': 2.1517276763916016e-05, 'vf_loss': 9.829618453979492, 'total_loss': 9.67700481414795, 'num_module_steps_trained_lifetime': 1614208, 'num_module_steps_trained': 40320, 'curr_kl_coeff': 9.765625145519152e-05, 'num_trainable_parameters': 142093.0}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'batch_individual_items': 0.06210149041540624, 'general_advantage_estimation': 0.025061503185071405, 'add_one_ts_to_episodes_and_truncate': 0.004973350570587319, 'numpy_to_tensor': 0.00016998538745624197, 'add_time_dim_to_batch_and_zero_pad': 2.3560690162641e-05, 'agent_to_module_mapping': 0.0032820304047727383, 'add_observations_from_episodes_to_batch': 0.00021990891145502086, 'add_columns_from_episodes_to_train_batch': 0.06759718311743772, 'add_states_from_episodes_to_batch': 5.516513490324151e-06}}, 'connector_pipeline_timer': 0.16363398010164792}, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained': 80640, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime': 50444000, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_module_steps_trained_lifetime': 3228416, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'agent_episode_returns_mean': {'servicer': -1131.275968241201, 'target': -5.53522680449486}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 6.854980708563701e-06, 'remove_single_ts_time_rank_from_batch': 7.883709956391112e-07, 'normalize_and_clip_actions': 3.4176201815301754e-05, 'un_batch_to_individual_items': 1.4452093451188707e-05, 'tensor_to_numpy': 3.2709504897471604e-05, 'module_to_agent_unmapping': 2.5039338934971324e-06, 'get_actions': 3.42613480144085e-05}}, 'connector_pipeline_timer': 0.00015596670363820332}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'env_to_module_connector': {'timers': {'connectors': {'numpy_to_tensor': 1.848296917061282e-05, 'add_time_dim_to_batch_and_zero_pad': 3.991022192096366e-06, 'agent_to_module_mapping': 2.8265672911345277e-06, 'add_observations_from_episodes_to_batch': 1.0763491882028374e-05, 'add_states_from_episodes_to_batch': 2.895253953519862e-06, 'batch_individual_items': 1.145107277828949e-05}}, 'connector_pipeline_timer': 7.551956553342736e-05}, 'module_episode_returns_mean': {'target': -5.53522680449486, 'servicer': -1131.275968241201}, 'episode_len_max': 1000, 'episode_return_min': -1176.0879266159575, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.8286652598671355e-05, 'agent_to_module_mapping': 7.790352282539098e-06, 'add_observations_from_episodes_to_batch': 4.0868057901694116e-05, 'add_states_from_episodes_to_batch': 7.081047192680416e-06, 'batch_individual_items': 3.628286436784677e-05, 'numpy_to_tensor': 4.1127559578002697e-05}}, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'num_module_steps_sampled': {'target': 5000, 'servicer': 5000}, 'num_module_steps_sampled_lifetime': {'target': 20000, 'servicer': 20000}, 'episode_duration_sec_mean': 0.5417566148421611, 'rlmodule_inference_timer': 0.00010548332885758468, 'sample': 2.778129230464963, 'num_agent_steps_sampled_lifetime': {'target': 20000, 'servicer': 20000}, 'num_agent_steps_sampled': {'target': 5000, 'servicer': 5000}, 'connector_pipeline_timer': 0.0002740977199743832, 'num_env_steps_sampled': 5000, 'num_episodes': 5, 'num_episodes_lifetime': 20, 'episode_len_min': 1000, 'episode_return_max': -1127.9669031828894, 'env_reset_timer': 0.00021436135580977527, 'episode_return_mean': -1136.811195045696, 'num_env_steps_sampled_lifetime': 20000, 'weights_seq_no': 39.0, 'env_step_timer': 9.297022335864129e-05, 'episode_len_mean': 1000.0, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'num_env_steps_sampled_per_second': 1679.0773929531738, 'time_between_sampling': 23.160153775290212}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 160000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1100.1137297849207, 'done': False, 'training_iteration': 40, 'trial_id': 'default', 'date': '2025-04-03_20-55-03', 'timestamp': 1743728103, 'time_this_iter_s': 3.621515989303589, 'time_total_s': 105.3763575553894, 'pid': 77277, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x3758dc540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 105.3763575553894, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': 79.76, 'ram_util_percent': 53.3}})
2025-04-03 20:55:06,039 [__main__] [INFO] Iter: 41/100, Ts(iter): 0, Ts(total): 164000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.77s
2025-04-03 20:55:08,754 [__main__] [INFO] Iter: 42/100, Ts(iter): 0, Ts(total): 168000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.72s
2025-04-03 20:55:11,393 [__main__] [INFO] Iter: 43/100, Ts(iter): 0, Ts(total): 172000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.64s
2025-04-03 20:55:14,149 [__main__] [INFO] Iter: 44/100, Ts(iter): 0, Ts(total): 176000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.76s
2025-04-03 20:55:16,910 [__main__] [INFO] Iter: 45/100, Ts(iter): 0, Ts(total): 180000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.76s
2025-04-03 20:55:19,631 [__main__] [INFO] Iter: 46/100, Ts(iter): 0, Ts(total): 184000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.72s
2025-04-03 20:55:22,593 [__main__] [INFO] Iter: 47/100, Ts(iter): 0, Ts(total): 188000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.96s
2025-04-03 20:55:25,169 [__main__] [INFO] Iter: 48/100, Ts(iter): 0, Ts(total): 192000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.58s
2025-04-03 20:55:27,922 [__main__] [INFO] Iter: 49/100, Ts(iter): 0, Ts(total): 196000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.75s
2025-04-03 20:55:31,843 [__main__] [INFO] Iter: 50/100, Ts(iter): 0, Ts(total): 200000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.92s
2025-04-03 20:55:34,383 [__main__] [INFO] Iter: 51/100, Ts(iter): 0, Ts(total): 204000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.54s
2025-04-03 20:55:37,081 [__main__] [INFO] Iter: 52/100, Ts(iter): 0, Ts(total): 208000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.70s
2025-04-03 20:55:39,885 [__main__] [INFO] Iter: 53/100, Ts(iter): 0, Ts(total): 212000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.80s
2025-04-03 20:55:42,561 [__main__] [INFO] Iter: 54/100, Ts(iter): 0, Ts(total): 216000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.68s
2025-04-03 20:55:45,012 [__main__] [INFO] Iter: 55/100, Ts(iter): 0, Ts(total): 220000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.45s
2025-04-03 20:55:47,366 [__main__] [INFO] Iter: 56/100, Ts(iter): 0, Ts(total): 224000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.35s
2025-04-03 20:55:50,019 [__main__] [INFO] Iter: 57/100, Ts(iter): 0, Ts(total): 228000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.65s
2025-04-03 20:55:53,032 [__main__] [INFO] Iter: 58/100, Ts(iter): 0, Ts(total): 232000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.01s
2025-04-03 20:55:55,518 [__main__] [INFO] Iter: 59/100, Ts(iter): 0, Ts(total): 236000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.49s
2025-04-03 20:55:59,150 [__main__] [INFO] Iter: 60/100, Ts(iter): 0, Ts(total): 240000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.63s
2025-04-03 20:55:59,169 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.5150317829205484, 'restore_env_runners': 1.5046948463876314e-05, 'training_step': 2.5148993889729723, 'env_runner_sampling_timer': 0.25338061528912353, 'learner_update_timer': 2.2549629589257183, 'synch_weights': 0.005182097820076652, 'synch_env_connectors': 0.007487484766293352, 'restore_eval_env_runners': 4.883135721908717e-06, 'evaluation_iteration': 2.97909215631046, 'synch_eval_env_connectors': 0.005856858710573091}, 'env_runners': {'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 9.904271071302483e-06, 'remove_single_ts_time_rank_from_batch': 1.1622575944965235e-06, 'normalize_and_clip_actions': 5.377111442239457e-05, 'un_batch_to_individual_items': 2.2084795787328914e-05, 'tensor_to_numpy': 4.949977084394679e-05, 'module_to_agent_unmapping': 3.847861457122698e-06, 'get_actions': 0.0001315732545480084}}, 'connector_pipeline_timer': 0.00031642757800069953}, 'env_to_module_connector': {'timers': {'connectors': {'numpy_to_tensor': 2.97784506854277e-05, 'add_time_dim_to_batch_and_zero_pad': 6.674423040854087e-06, 'agent_to_module_mapping': 4.212222952585526e-06, 'add_observations_from_episodes_to_batch': 1.6324324761770504e-05, 'add_states_from_episodes_to_batch': 4.09466692419583e-06, 'batch_individual_items': 1.799258135237897e-05}}, 'connector_pipeline_timer': 0.0001156707039743042}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 2.164330394209727e-05, 'agent_to_module_mapping': 7.999872373740958e-06, 'add_observations_from_episodes_to_batch': 4.4463781903133444e-05, 'add_states_from_episodes_to_batch': 1.0095915058627725e-05, 'batch_individual_items': 4.1965784317732826e-05, 'numpy_to_tensor': 6.50053483221437e-05}}, 'env_to_module_sum_episodes_length_out': 101.27250081465326, 'num_module_steps_sampled': {'target': 4000, 'servicer': 4000}, 'num_module_steps_sampled_lifetime': {'target': 240000, 'servicer': 240000}, 'rlmodule_inference_timer': 0.00014956968093456376, 'sample': 0.1681541675603504, 'num_agent_steps_sampled_lifetime': {'target': 240000, 'servicer': 240000}, 'num_agent_steps_sampled': {'target': 4000, 'servicer': 4000}, 'connector_pipeline_timer': 0.0003582426946630458, 'num_env_steps_sampled': 4000, 'env_reset_timer': 0.00022803252352826783, 'num_env_steps_sampled_lifetime': 240000, 'weights_seq_no': 59.0, 'env_step_timer': 0.00014200443634639458, 'env_to_module_sum_episodes_length_in': 101.27250081465326, 'time_between_sampling': 2.350884910893811, 'agent_episode_returns_mean': {'servicer': -1119.199053354955, 'target': -20.59080492123314}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'module_episode_returns_mean': {'target': -20.59080492123314, 'servicer': -1119.199053354955}, 'episode_len_max': 1000, 'episode_return_min': -1151.936297550483, 'episode_duration_sec_mean': 0.8947180747402499, 'num_episodes': 0, 'num_episodes_lifetime': 230, 'episode_len_min': 1000, 'episode_return_max': -1120.377144777754, 'episode_return_mean': -1139.7898582761882, 'episode_len_mean': 1000.0, 'num_env_steps_sampled_lifetime_throughput': 1101.2248521552617}, 'learners': {'target': {'vf_explained_var': 0.11264705657958984, 'vf_loss': 0.18994927406311035, 'total_loss': -0.12033452093601227, 'num_module_steps_trained_lifetime': 2421376, 'num_trainable_parameters': 142093.0, 'curr_kl_coeff': 1.1920929132713809e-08, 'num_module_steps_trained': 40320, 'policy_loss': -0.06197989732027054, 'default_optimizer_learning_rate': 5e-05, 'module_train_batch_size_mean': 128.0, 'entropy': 12.41519546508789, 'curr_entropy_coeff': 0.02, 'weights_seq_no': 60.0, 'gradients_default_optimizer_global_norm': 1.5841593742370605, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.0042741987854242325, 'vf_loss_unclipped': 0.18994927406311035}, 'servicer': {'default_optimizer_learning_rate': 5e-05, 'policy_loss': -0.1036098524928093, 'module_train_batch_size_mean': 128.0, 'entropy': 13.667839050292969, 'curr_entropy_coeff': 0.02, 'gradients_default_optimizer_global_norm': 1.4991439580917358, 'weights_seq_no': 60.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.009558578953146935, 'vf_loss_unclipped': 3570.223876953125, 'vf_explained_var': -0.0006704330444335938, 'vf_loss': 9.710376739501953, 'total_loss': 9.333410263061523, 'num_module_steps_trained_lifetime': 2421376, 'num_module_steps_trained': 40320, 'curr_kl_coeff': 9.536743306171047e-08, 'num_trainable_parameters': 142093.0}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'batch_individual_items': 0.06327808244849738, 'general_advantage_estimation': 0.024291811042800395, 'add_one_ts_to_episodes_and_truncate': 0.004979844370219863, 'numpy_to_tensor': 0.00016760454034241384, 'add_time_dim_to_batch_and_zero_pad': 2.3012467907183064e-05, 'agent_to_module_mapping': 0.0033011167350372747, 'add_observations_from_episodes_to_batch': 0.00022251215933758792, 'add_columns_from_episodes_to_train_batch': 0.06770451400292232, 'add_states_from_episodes_to_batch': 5.417815176008397e-06}}, 'connector_pipeline_timer': 0.16416770055585828}, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained': 80640, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime': 75668000, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_module_steps_trained_lifetime': 4842752, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'agent_episode_returns_mean': {'servicer': -1139.9894645310033, 'target': -6.503361596837644}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 6.859604647009681e-06, 'remove_single_ts_time_rank_from_batch': 7.892331604669047e-07, 'normalize_and_clip_actions': 3.420664863697458e-05, 'un_batch_to_individual_items': 1.4465456990523544e-05, 'tensor_to_numpy': 3.273182709378282e-05, 'module_to_agent_unmapping': 2.5073974405642306e-06, 'get_actions': 3.4293925913738495e-05}}, 'connector_pipeline_timer': 0.00015609021296187145}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'env_to_module_connector': {'timers': {'connectors': {'numpy_to_tensor': 1.8489597894810364e-05, 'add_time_dim_to_batch_and_zero_pad': 3.994627650356877e-06, 'agent_to_module_mapping': 2.828568912047537e-06, 'add_observations_from_episodes_to_batch': 1.0779798548663099e-05, 'add_states_from_episodes_to_batch': 2.8970368061481595e-06, 'batch_individual_items': 1.1462863390148582e-05}}, 'connector_pipeline_timer': 7.557023988570155e-05}, 'module_episode_returns_mean': {'target': -6.503361596837644, 'servicer': -1139.9894645310033}, 'episode_len_max': 1000, 'episode_return_min': -1223.4036318085691, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.8280943601346075e-05, 'agent_to_module_mapping': 7.788192088099996e-06, 'add_observations_from_episodes_to_batch': 4.085935933441236e-05, 'add_states_from_episodes_to_batch': 7.078714403950971e-06, 'batch_individual_items': 3.62730196166346e-05, 'numpy_to_tensor': 4.115214073302976e-05}}, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'num_module_steps_sampled': {'target': 5000, 'servicer': 5000}, 'num_module_steps_sampled_lifetime': {'target': 30000, 'servicer': 30000}, 'episode_duration_sec_mean': 0.5442085232313548, 'rlmodule_inference_timer': 0.00010555099557510755, 'sample': 2.7781644068311544, 'num_agent_steps_sampled_lifetime': {'target': 30000, 'servicer': 30000}, 'num_agent_steps_sampled': {'target': 5000, 'servicer': 5000}, 'connector_pipeline_timer': 0.0002740315082938434, 'num_env_steps_sampled': 5000, 'num_episodes': 5, 'num_episodes_lifetime': 30, 'episode_len_min': 1000, 'episode_return_max': -1127.9669031828894, 'env_reset_timer': 0.00021429215027752845, 'episode_return_mean': -1146.4928261278408, 'num_env_steps_sampled_lifetime': 30000, 'weights_seq_no': 59.0, 'env_step_timer': 9.306021854588971e-05, 'episode_len_mean': 1000.0, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'num_env_steps_sampled_per_second': 1679.0689747453346, 'time_between_sampling': 23.16111236395989}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 240000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1101.2248521552617, 'done': False, 'training_iteration': 60, 'trial_id': 'default', 'date': '2025-04-03_20-55-59', 'timestamp': 1743728159, 'time_this_iter_s': 3.6191232204437256, 'time_total_s': 160.9785397052765, 'pid': 77277, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x3758dc540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 160.9785397052765, 'iterations_since_restore': 60, 'perf': {'cpu_util_percent': 77.64, 'ram_util_percent': 53.4}})
2025-04-03 20:56:02,071 [__main__] [INFO] Iter: 61/100, Ts(iter): 0, Ts(total): 244000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.90s
2025-04-03 20:56:04,728 [__main__] [INFO] Iter: 62/100, Ts(iter): 0, Ts(total): 248000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.66s
2025-04-03 20:56:07,761 [__main__] [INFO] Iter: 63/100, Ts(iter): 0, Ts(total): 252000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.03s
2025-04-03 20:56:10,586 [__main__] [INFO] Iter: 64/100, Ts(iter): 0, Ts(total): 256000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.83s
2025-04-03 20:56:13,407 [__main__] [INFO] Iter: 65/100, Ts(iter): 0, Ts(total): 260000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.82s
2025-04-03 20:56:16,417 [__main__] [INFO] Iter: 66/100, Ts(iter): 0, Ts(total): 264000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.01s
2025-04-03 20:56:19,281 [__main__] [INFO] Iter: 67/100, Ts(iter): 0, Ts(total): 268000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.86s
2025-04-03 20:56:22,195 [__main__] [INFO] Iter: 68/100, Ts(iter): 0, Ts(total): 272000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.91s
2025-04-03 20:56:25,360 [__main__] [INFO] Iter: 69/100, Ts(iter): 0, Ts(total): 276000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.16s
2025-04-03 20:56:29,096 [__main__] [INFO] Iter: 70/100, Ts(iter): 0, Ts(total): 280000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.74s
2025-04-03 20:56:32,084 [__main__] [INFO] Iter: 71/100, Ts(iter): 0, Ts(total): 284000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.99s
2025-04-03 20:56:34,544 [__main__] [INFO] Iter: 72/100, Ts(iter): 0, Ts(total): 288000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.46s
2025-04-03 20:56:37,138 [__main__] [INFO] Iter: 73/100, Ts(iter): 0, Ts(total): 292000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.59s
2025-04-03 20:56:39,570 [__main__] [INFO] Iter: 74/100, Ts(iter): 0, Ts(total): 296000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.43s
2025-04-03 20:56:42,145 [__main__] [INFO] Iter: 75/100, Ts(iter): 0, Ts(total): 300000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.58s
2025-04-03 20:56:44,841 [__main__] [INFO] Iter: 76/100, Ts(iter): 0, Ts(total): 304000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.70s
2025-04-03 20:56:47,563 [__main__] [INFO] Iter: 77/100, Ts(iter): 0, Ts(total): 308000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.72s
2025-04-03 20:56:50,091 [__main__] [INFO] Iter: 78/100, Ts(iter): 0, Ts(total): 312000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.53s
2025-04-03 20:56:52,842 [__main__] [INFO] Iter: 79/100, Ts(iter): 0, Ts(total): 316000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.75s
2025-04-03 20:56:56,421 [__main__] [INFO] Iter: 80/100, Ts(iter): 0, Ts(total): 320000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.58s
2025-04-03 20:56:56,440 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.5733239269113364, 'restore_env_runners': 1.4084346304621065e-05, 'training_step': 2.5731901611189123, 'env_runner_sampling_timer': 0.2476726011842059, 'learner_update_timer': 2.3189422694993986, 'synch_weights': 0.005125210567397994, 'synch_env_connectors': 0.007459056733798623, 'restore_eval_env_runners': 4.9255113679216e-06, 'evaluation_iteration': 2.979697795579149, 'synch_eval_env_connectors': 0.0057753135863969785}, 'env_runners': {'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 9.553476396111334e-06, 'remove_single_ts_time_rank_from_batch': 1.228021247001396e-06, 'normalize_and_clip_actions': 5.3543756829720014e-05, 'un_batch_to_individual_items': 2.127733184987158e-05, 'tensor_to_numpy': 4.9074333909310254e-05, 'module_to_agent_unmapping': 3.630972869076268e-06, 'get_actions': 0.0001316379908151423}}, 'connector_pipeline_timer': 0.0003156979776137892}, 'env_to_module_connector': {'timers': {'connectors': {'numpy_to_tensor': 2.982414974969356e-05, 'add_time_dim_to_batch_and_zero_pad': 6.6277897667484254e-06, 'agent_to_module_mapping': 4.109908022453902e-06, 'add_observations_from_episodes_to_batch': 1.5772893807793245e-05, 'add_states_from_episodes_to_batch': 4.0736129966752246e-06, 'batch_individual_items': 1.771678078311493e-05}}, 'connector_pipeline_timer': 0.00011516430402926864}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 2.164330394209727e-05, 'agent_to_module_mapping': 7.999872373740958e-06, 'add_observations_from_episodes_to_batch': 4.4463781903133444e-05, 'add_states_from_episodes_to_batch': 1.0095915058627725e-05, 'batch_individual_items': 4.1965784317732826e-05, 'numpy_to_tensor': 6.50053483221437e-05}}, 'env_to_module_sum_episodes_length_out': 106.95241103664021, 'num_module_steps_sampled': {'target': 4000, 'servicer': 4000}, 'num_module_steps_sampled_lifetime': {'target': 320000, 'servicer': 320000}, 'rlmodule_inference_timer': 0.00015057996280502648, 'sample': 0.16693581442261596, 'num_agent_steps_sampled_lifetime': {'target': 320000, 'servicer': 320000}, 'num_agent_steps_sampled': {'target': 4000, 'servicer': 4000}, 'connector_pipeline_timer': 0.0003582426946630458, 'num_env_steps_sampled': 4000, 'env_reset_timer': 0.00022803252352826783, 'num_env_steps_sampled_lifetime': 320000, 'weights_seq_no': 79.0, 'env_step_timer': 0.00014196471457882231, 'env_to_module_sum_episodes_length_in': 106.95241103664021, 'time_between_sampling': 2.414007940849186, 'agent_episode_returns_mean': {'servicer': -1165.156710262779, 'target': -21.31896781568943}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'module_episode_returns_mean': {'target': -21.31896781568943, 'servicer': -1165.156710262779}, 'episode_len_max': 1000, 'episode_return_min': -1208.1952794189854, 'episode_duration_sec_mean': 0.8961933279959181, 'num_episodes': 0, 'num_episodes_lifetime': 299, 'episode_len_min': 1000, 'episode_return_max': -1168.954469225601, 'episode_return_mean': -1186.4756780784683, 'episode_len_mean': 1000.0, 'num_env_steps_sampled_lifetime_throughput': 1118.013355378273}, 'learners': {'target': {'vf_explained_var': 0.3083779811859131, 'vf_loss': 0.1933211386203766, 'total_loss': -0.06712564080953598, 'num_module_steps_trained_lifetime': 3228288, 'num_trainable_parameters': 142093.0, 'curr_kl_coeff': 4.6566129424663316e-11, 'num_module_steps_trained': 40320, 'policy_loss': 0.020890310406684875, 'default_optimizer_learning_rate': 5e-05, 'module_train_batch_size_mean': 128.0, 'entropy': 14.066855430603027, 'curr_entropy_coeff': 0.02, 'weights_seq_no': 80.0, 'gradients_default_optimizer_global_norm': 1.4065496921539307, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.003528955392539501, 'vf_loss_unclipped': 0.1933211386203766}, 'servicer': {'default_optimizer_learning_rate': 5e-05, 'policy_loss': -0.008666926994919777, 'module_train_batch_size_mean': 128.0, 'entropy': 13.90380859375, 'curr_entropy_coeff': 0.02, 'gradients_default_optimizer_global_norm': 1.4393113851547241, 'weights_seq_no': 80.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.0055684675462543964, 'vf_loss_unclipped': 4497.8955078125, 'vf_explained_var': -0.0005434751510620117, 'vf_loss': 9.801419258117676, 'total_loss': 9.514677047729492, 'num_module_steps_trained_lifetime': 3228288, 'num_module_steps_trained': 40320, 'curr_kl_coeff': 1.1920929132713809e-08, 'num_trainable_parameters': 142093.0}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'batch_individual_items': 0.06466842635953263, 'general_advantage_estimation': 0.023400540189375856, 'add_one_ts_to_episodes_and_truncate': 0.004991040899983207, 'numpy_to_tensor': 0.000165174399407286, 'add_time_dim_to_batch_and_zero_pad': 2.2428079978493615e-05, 'agent_to_module_mapping': 0.003326335825420664, 'add_observations_from_episodes_to_batch': 0.00022602279319939274, 'add_columns_from_episodes_to_train_batch': 0.06786586290717371, 'add_states_from_episodes_to_batch': 5.314862846718306e-06}}, 'connector_pipeline_timer': 0.16485880252254406}, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained': 80640, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime': 100884000, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_module_steps_trained_lifetime': 6456576, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'agent_episode_returns_mean': {'servicer': -1174.8497968334573, 'target': -8.324116258442404}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 6.8622081140107375e-06, 'remove_single_ts_time_rank_from_batch': 7.896357648599205e-07, 'normalize_and_clip_actions': 3.423038935441994e-05, 'un_batch_to_individual_items': 1.447004874813376e-05, 'tensor_to_numpy': 3.2765658616329066e-05, 'module_to_agent_unmapping': 2.509367755334906e-06, 'get_actions': 3.4314809508027157e-05}}, 'connector_pipeline_timer': 0.000156188817461947}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'env_to_module_connector': {'timers': {'connectors': {'numpy_to_tensor': 1.8497977517484498e-05, 'add_time_dim_to_batch_and_zero_pad': 3.999154975134529e-06, 'agent_to_module_mapping': 2.8302595156460363e-06, 'add_observations_from_episodes_to_batch': 1.0787888449062487e-05, 'add_states_from_episodes_to_batch': 2.8981930724148466e-06, 'batch_individual_items': 1.1472231242031846e-05}}, 'connector_pipeline_timer': 7.561068614941715e-05}, 'module_episode_returns_mean': {'target': -8.324116258442404, 'servicer': -1174.8497968334573}, 'episode_len_max': 1000, 'episode_return_min': -1307.4991312792495, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.8273593745414525e-05, 'agent_to_module_mapping': 7.785242213784803e-06, 'add_observations_from_episodes_to_batch': 4.084823091475806e-05, 'add_states_from_episodes_to_batch': 7.0757361728645e-06, 'batch_individual_items': 3.626009616937541e-05, 'numpy_to_tensor': 4.1197869684972155e-05}}, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'num_module_steps_sampled': {'target': 5000, 'servicer': 5000}, 'num_module_steps_sampled_lifetime': {'target': 40000, 'servicer': 40000}, 'episode_duration_sec_mean': 0.5480081995905494, 'rlmodule_inference_timer': 0.00010561443745249186, 'sample': 2.7782266896836187, 'num_agent_steps_sampled_lifetime': {'target': 40000, 'servicer': 40000}, 'num_agent_steps_sampled': {'target': 5000, 'servicer': 5000}, 'connector_pipeline_timer': 0.00027395656423120587, 'num_env_steps_sampled': 5000, 'num_episodes': 5, 'num_episodes_lifetime': 40, 'episode_len_min': 1000, 'episode_return_max': -1127.9669031828894, 'env_reset_timer': 0.000214201835231583, 'episode_return_mean': -1183.1739130918995, 'num_env_steps_sampled_lifetime': 40000, 'weights_seq_no': 79.0, 'env_step_timer': 9.313940322010545e-05, 'episode_len_mean': 1000.0, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'num_env_steps_sampled_per_second': 1679.053397413405, 'time_between_sampling': 23.163092094925947}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 320000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1118.013355378273, 'done': False, 'training_iteration': 80, 'trial_id': 'default', 'date': '2025-04-03_20-56-56', 'timestamp': 1743728216, 'time_this_iter_s': 3.565438985824585, 'time_total_s': 217.9511501789093, 'pid': 77277, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x3758dc540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 217.9511501789093, 'iterations_since_restore': 80, 'perf': {'cpu_util_percent': 78.53333333333335, 'ram_util_percent': 53.5}})
2025-04-03 20:56:59,058 [__main__] [INFO] Iter: 81/100, Ts(iter): 0, Ts(total): 324000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.62s
2025-04-03 20:57:01,698 [__main__] [INFO] Iter: 82/100, Ts(iter): 0, Ts(total): 328000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.64s
2025-04-03 20:57:04,376 [__main__] [INFO] Iter: 83/100, Ts(iter): 0, Ts(total): 332000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.68s
2025-04-03 20:57:07,146 [__main__] [INFO] Iter: 84/100, Ts(iter): 0, Ts(total): 336000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.77s
2025-04-03 20:57:09,837 [__main__] [INFO] Iter: 85/100, Ts(iter): 0, Ts(total): 340000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.69s
2025-04-03 20:57:12,383 [__main__] [INFO] Iter: 86/100, Ts(iter): 0, Ts(total): 344000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.55s
2025-04-03 20:57:15,208 [__main__] [INFO] Iter: 87/100, Ts(iter): 0, Ts(total): 348000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.82s
2025-04-03 20:57:17,506 [__main__] [INFO] Iter: 88/100, Ts(iter): 0, Ts(total): 352000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.30s
2025-04-03 20:57:20,066 [__main__] [INFO] Iter: 89/100, Ts(iter): 0, Ts(total): 356000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.56s
2025-04-03 20:57:23,759 [__main__] [INFO] Iter: 90/100, Ts(iter): 0, Ts(total): 360000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.69s
2025-04-03 20:57:26,581 [__main__] [INFO] Iter: 91/100, Ts(iter): 0, Ts(total): 364000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.82s
2025-04-03 20:57:29,193 [__main__] [INFO] Iter: 92/100, Ts(iter): 0, Ts(total): 368000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.61s
2025-04-03 20:57:31,985 [__main__] [INFO] Iter: 93/100, Ts(iter): 0, Ts(total): 372000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.79s
2025-04-03 20:57:34,708 [__main__] [INFO] Iter: 94/100, Ts(iter): 0, Ts(total): 376000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.72s
2025-04-03 20:57:37,410 [__main__] [INFO] Iter: 95/100, Ts(iter): 0, Ts(total): 380000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.70s
2025-04-03 20:57:39,775 [__main__] [INFO] Iter: 96/100, Ts(iter): 0, Ts(total): 384000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.36s
2025-04-03 20:57:42,570 [__main__] [INFO] Iter: 97/100, Ts(iter): 0, Ts(total): 388000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.79s
2025-04-03 20:57:45,208 [__main__] [INFO] Iter: 98/100, Ts(iter): 0, Ts(total): 392000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.64s
2025-04-03 20:57:47,911 [__main__] [INFO] Iter: 99/100, Ts(iter): 0, Ts(total): 396000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.70s
2025-04-03 20:57:51,604 [__main__] [INFO] Iter: 100/100, Ts(iter): 0, Ts(total): 400000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.69s
2025-04-03 20:57:51,622 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.6031469230575692, 'restore_env_runners': 1.3223166634660465e-05, 'training_step': 2.6030116051151815, 'env_runner_sampling_timer': 0.24056675349467754, 'learner_update_timer': 2.3558023286791627, 'synch_weights': 0.005099130145002465, 'synch_env_connectors': 0.007467441455940909, 'restore_eval_env_runners': 4.9576070034521715e-06, 'evaluation_iteration': 2.979371471768762, 'synch_eval_env_connectors': 0.005688115250182541}, 'env_runners': {'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 9.943564652003334e-06, 'remove_single_ts_time_rank_from_batch': 1.1787314946479206e-06, 'normalize_and_clip_actions': 5.470293548070651e-05, 'un_batch_to_individual_items': 2.171241895370228e-05, 'tensor_to_numpy': 4.880665132794994e-05, 'module_to_agent_unmapping': 3.6994896532724833e-06, 'get_actions': 0.00013006161791575868}}, 'connector_pipeline_timer': 0.0003146677111077034}, 'env_to_module_connector': {'timers': {'connectors': {'numpy_to_tensor': 3.090225260658209e-05, 'add_time_dim_to_batch_and_zero_pad': 7.209968669373741e-06, 'agent_to_module_mapping': 4.23746821328216e-06, 'add_observations_from_episodes_to_batch': 1.64212636452498e-05, 'add_states_from_episodes_to_batch': 4.534724808506327e-06, 'batch_individual_items': 1.834227487587035e-05}}, 'connector_pipeline_timer': 0.00011851208119269142}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 2.164330394209727e-05, 'agent_to_module_mapping': 7.999872373740958e-06, 'add_observations_from_episodes_to_batch': 4.4463781903133444e-05, 'add_states_from_episodes_to_batch': 1.0095915058627725e-05, 'batch_individual_items': 4.1965784317732826e-05, 'numpy_to_tensor': 6.50053483221437e-05}}, 'env_to_module_sum_episodes_length_out': 101.95413642173257, 'num_module_steps_sampled': {'target': 4000, 'servicer': 4000}, 'num_module_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'rlmodule_inference_timer': 0.00014876917003546245, 'sample': 0.16521060672762014, 'num_agent_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'num_agent_steps_sampled': {'target': 4000, 'servicer': 4000}, 'connector_pipeline_timer': 0.0003582426946630458, 'num_env_steps_sampled': 4000, 'env_reset_timer': 0.00022803252352826783, 'num_env_steps_sampled_lifetime': 400000, 'weights_seq_no': 99.0, 'env_step_timer': 0.0001454361593687859, 'env_to_module_sum_episodes_length_in': 101.95413642173257, 'time_between_sampling': 2.447188109139937, 'agent_episode_returns_mean': {'servicer': -1151.7999623585777, 'target': -22.169012470919164}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'module_episode_returns_mean': {'target': -22.169012470919164, 'servicer': -1151.7999623585777}, 'episode_len_max': 1000, 'episode_return_min': -1189.3248539543554, 'episode_duration_sec_mean': 0.89200889499815, 'num_episodes': 0, 'num_episodes_lifetime': 391, 'episode_len_min': 1000, 'episode_return_max': -1157.4433315925558, 'episode_return_mean': -1173.9689748294968, 'episode_len_mean': 1000.0, 'num_env_steps_sampled_lifetime_throughput': 1082.8071341805723}, 'learners': {'target': {'vf_explained_var': 0.08153575658798218, 'vf_loss': 0.2347772717475891, 'total_loss': -0.08002650737762451, 'num_module_steps_trained_lifetime': 4035456, 'num_trainable_parameters': 142093.0, 'curr_kl_coeff': 2.2737367883136385e-14, 'num_module_steps_trained': 40320, 'policy_loss': -0.006340198218822479, 'default_optimizer_learning_rate': 5e-05, 'module_train_batch_size_mean': 128.0, 'entropy': 15.423178672790527, 'curr_entropy_coeff': 0.02, 'weights_seq_no': 100.0, 'gradients_default_optimizer_global_norm': 1.7384915351867676, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.004051133058965206, 'vf_loss_unclipped': 0.2347772717475891}, 'servicer': {'default_optimizer_learning_rate': 5e-05, 'policy_loss': 0.157072976231575, 'module_train_batch_size_mean': 128.0, 'entropy': 18.675291061401367, 'curr_entropy_coeff': 0.02, 'gradients_default_optimizer_global_norm': 1.363038420677185, 'weights_seq_no': 100.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.0028580951038748026, 'vf_loss_unclipped': 4077.818115234375, 'vf_explained_var': -0.00036323070526123047, 'vf_loss': 9.901031494140625, 'total_loss': 9.684599876403809, 'num_module_steps_trained_lifetime': 4035456, 'num_module_steps_trained': 40320, 'curr_kl_coeff': 2.3283064712331658e-11, 'num_trainable_parameters': 142093.0}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'batch_individual_items': 0.06598522968159812, 'general_advantage_estimation': 0.02243823726158572, 'add_one_ts_to_episodes_and_truncate': 0.004999879440943742, 'numpy_to_tensor': 0.0001624118817738624, 'add_time_dim_to_batch_and_zero_pad': 2.176119170700411e-05, 'agent_to_module_mapping': 0.0033529666045228872, 'add_observations_from_episodes_to_batch': 0.00022980940126125592, 'add_columns_from_episodes_to_train_batch': 0.06804073185349035, 'add_states_from_episodes_to_batch': 5.201551848828716e-06}}, 'connector_pipeline_timer': 0.16541704670888327}, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained': 80640, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime': 126108000, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_module_steps_trained_lifetime': 8070912, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'agent_episode_returns_mean': {'servicer': -1209.6206550030827, 'target': -9.511370450764895}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 6.863501842281813e-06, 'remove_single_ts_time_rank_from_batch': 7.897642263810023e-07, 'normalize_and_clip_actions': 3.4229081617987834e-05, 'un_batch_to_individual_items': 1.4467083173967605e-05, 'tensor_to_numpy': 3.277727962710671e-05, 'module_to_agent_unmapping': 2.5123004570391888e-06, 'get_actions': 3.431860963201205e-05}}, 'connector_pipeline_timer': 0.00015619939337036532}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'env_to_module_connector': {'timers': {'connectors': {'numpy_to_tensor': 1.8499964194335166e-05, 'add_time_dim_to_batch_and_zero_pad': 4.002028121577676e-06, 'agent_to_module_mapping': 2.832208156635201e-06, 'add_observations_from_episodes_to_batch': 1.0791854024044335e-05, 'add_states_from_episodes_to_batch': 2.898766356181129e-06, 'batch_individual_items': 1.147435876650181e-05}}, 'connector_pipeline_timer': 7.562940783786872e-05}, 'module_episode_returns_mean': {'target': -9.511370450764895, 'servicer': -1209.6206550030827}, 'episode_len_max': 1000, 'episode_return_min': -1327.5479030336162, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.826346863397965e-05, 'agent_to_module_mapping': 7.780966986123444e-06, 'add_observations_from_episodes_to_batch': 4.083066736594803e-05, 'add_states_from_episodes_to_batch': 7.071577994562904e-06, 'batch_individual_items': 3.624192698166662e-05, 'numpy_to_tensor': 4.124257490674532e-05}}, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'num_module_steps_sampled': {'target': 5000, 'servicer': 5000}, 'num_module_steps_sampled_lifetime': {'target': 50000, 'servicer': 50000}, 'episode_duration_sec_mean': 0.5469654820900177, 'rlmodule_inference_timer': 0.0001056247638420456, 'sample': 2.7782938650371687, 'num_agent_steps_sampled_lifetime': {'target': 50000, 'servicer': 50000}, 'num_agent_steps_sampled': {'target': 5000, 'servicer': 5000}, 'connector_pipeline_timer': 0.00027383416570848424, 'num_env_steps_sampled': 5000, 'num_episodes': 5, 'num_episodes_lifetime': 50, 'episode_len_min': 1000, 'episode_return_max': -1127.9669031828894, 'env_reset_timer': 0.00021407950899848837, 'episode_return_mean': -1219.1320254538473, 'num_env_steps_sampled_lifetime': 50000, 'weights_seq_no': 99.0, 'env_step_timer': 9.317072185380736e-05, 'episode_len_mean': 1000.0, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'num_env_steps_sampled_per_second': 1679.033878369688, 'time_between_sampling': 23.165572599077002}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 400000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1082.8071341805723, 'done': False, 'training_iteration': 100, 'trial_id': 'default', 'date': '2025-04-03_20-57-51', 'timestamp': 1743728271, 'time_this_iter_s': 3.679244041442871, 'time_total_s': 272.82737135887146, 'pid': 77277, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x3758dc540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 272.82737135887146, 'iterations_since_restore': 100, 'perf': {'cpu_util_percent': 78.88000000000001, 'ram_util_percent': 53.42}})
2025-04-03 20:57:51,623 [__main__] [INFO] 
--- Training Finished ---
2025-04-03 20:57:51,623 [__main__] [INFO] Total Training Time: 274.29 seconds
2025-04-03 20:57:51,623 [__main__] [INFO] Using last checkpoint: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.6031469230575692, 'restore_env_runners': 1.3223166634660465e-05, 'training_step': 2.6030116051151815, 'env_runner_sampling_timer': 0.24056675349467754, 'learner_update_timer': 2.3558023286791627, 'synch_weights': 0.005099130145002465, 'synch_env_connectors': 0.007467441455940909, 'restore_eval_env_runners': 4.9576070034521715e-06, 'evaluation_iteration': 2.979371471768762, 'synch_eval_env_connectors': 0.005688115250182541}, 'env_runners': {'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 9.943564652003334e-06, 'remove_single_ts_time_rank_from_batch': 1.1787314946479206e-06, 'normalize_and_clip_actions': 5.470293548070651e-05, 'un_batch_to_individual_items': 2.171241895370228e-05, 'tensor_to_numpy': 4.880665132794994e-05, 'module_to_agent_unmapping': 3.6994896532724833e-06, 'get_actions': 0.00013006161791575868}}, 'connector_pipeline_timer': 0.0003146677111077034}, 'env_to_module_connector': {'timers': {'connectors': {'numpy_to_tensor': 3.090225260658209e-05, 'add_time_dim_to_batch_and_zero_pad': 7.209968669373741e-06, 'agent_to_module_mapping': 4.23746821328216e-06, 'add_observations_from_episodes_to_batch': 1.64212636452498e-05, 'add_states_from_episodes_to_batch': 4.534724808506327e-06, 'batch_individual_items': 1.834227487587035e-05}}, 'connector_pipeline_timer': 0.00011851208119269142}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 2.164330394209727e-05, 'agent_to_module_mapping': 7.999872373740958e-06, 'add_observations_from_episodes_to_batch': 4.4463781903133444e-05, 'add_states_from_episodes_to_batch': 1.0095915058627725e-05, 'batch_individual_items': 4.1965784317732826e-05, 'numpy_to_tensor': 6.50053483221437e-05}}, 'env_to_module_sum_episodes_length_out': 101.95413642173257, 'num_module_steps_sampled': {'target': 4000, 'servicer': 4000}, 'num_module_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'rlmodule_inference_timer': 0.00014876917003546245, 'sample': 0.16521060672762014, 'num_agent_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'num_agent_steps_sampled': {'target': 4000, 'servicer': 4000}, 'connector_pipeline_timer': 0.0003582426946630458, 'num_env_steps_sampled': 4000, 'env_reset_timer': 0.00022803252352826783, 'num_env_steps_sampled_lifetime': 400000, 'weights_seq_no': 99.0, 'env_step_timer': 0.0001454361593687859, 'env_to_module_sum_episodes_length_in': 101.95413642173257, 'time_between_sampling': 2.447188109139937, 'agent_episode_returns_mean': {'servicer': -1151.7999623585777, 'target': -22.169012470919164}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'module_episode_returns_mean': {'target': -22.169012470919164, 'servicer': -1151.7999623585777}, 'episode_len_max': 1000, 'episode_return_min': -1189.3248539543554, 'episode_duration_sec_mean': 0.89200889499815, 'num_episodes': 0, 'num_episodes_lifetime': 391, 'episode_len_min': 1000, 'episode_return_max': -1157.4433315925558, 'episode_return_mean': -1173.9689748294968, 'episode_len_mean': 1000.0, 'num_env_steps_sampled_lifetime_throughput': 1082.8071341805723}, 'learners': {'target': {'vf_explained_var': 0.08153575658798218, 'vf_loss': 0.2347772717475891, 'total_loss': -0.08002650737762451, 'num_module_steps_trained_lifetime': 4035456, 'num_trainable_parameters': 142093.0, 'curr_kl_coeff': 2.2737367883136385e-14, 'num_module_steps_trained': 40320, 'policy_loss': -0.006340198218822479, 'default_optimizer_learning_rate': 5e-05, 'module_train_batch_size_mean': 128.0, 'entropy': 15.423178672790527, 'curr_entropy_coeff': 0.02, 'weights_seq_no': 100.0, 'gradients_default_optimizer_global_norm': 1.7384915351867676, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.004051133058965206, 'vf_loss_unclipped': 0.2347772717475891}, 'servicer': {'default_optimizer_learning_rate': 5e-05, 'policy_loss': 0.157072976231575, 'module_train_batch_size_mean': 128.0, 'entropy': 18.675291061401367, 'curr_entropy_coeff': 0.02, 'gradients_default_optimizer_global_norm': 1.363038420677185, 'weights_seq_no': 100.0, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'mean_kl_loss': 0.0028580951038748026, 'vf_loss_unclipped': 4077.818115234375, 'vf_explained_var': -0.00036323070526123047, 'vf_loss': 9.901031494140625, 'total_loss': 9.684599876403809, 'num_module_steps_trained_lifetime': 4035456, 'num_module_steps_trained': 40320, 'curr_kl_coeff': 2.3283064712331658e-11, 'num_trainable_parameters': 142093.0}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'batch_individual_items': 0.06598522968159812, 'general_advantage_estimation': 0.02243823726158572, 'add_one_ts_to_episodes_and_truncate': 0.004999879440943742, 'numpy_to_tensor': 0.0001624118817738624, 'add_time_dim_to_batch_and_zero_pad': 2.176119170700411e-05, 'agent_to_module_mapping': 0.0033529666045228872, 'add_observations_from_episodes_to_batch': 0.00022980940126125592, 'add_columns_from_episodes_to_train_batch': 0.06804073185349035, 'add_states_from_episodes_to_batch': 5.201551848828716e-06}}, 'connector_pipeline_timer': 0.16541704670888327}, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained': 80640, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime': 126108000, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_module_steps_trained_lifetime': 8070912, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'agent_episode_returns_mean': {'servicer': -1209.6206550030827, 'target': -9.511370450764895}, 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': 6.863501842281813e-06, 'remove_single_ts_time_rank_from_batch': 7.897642263810023e-07, 'normalize_and_clip_actions': 3.4229081617987834e-05, 'un_batch_to_individual_items': 1.4467083173967605e-05, 'tensor_to_numpy': 3.277727962710671e-05, 'module_to_agent_unmapping': 2.5123004570391888e-06, 'get_actions': 3.431860963201205e-05}}, 'connector_pipeline_timer': 0.00015619939337036532}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'env_to_module_connector': {'timers': {'connectors': {'numpy_to_tensor': 1.8499964194335166e-05, 'add_time_dim_to_batch_and_zero_pad': 4.002028121577676e-06, 'agent_to_module_mapping': 2.832208156635201e-06, 'add_observations_from_episodes_to_batch': 1.0791854024044335e-05, 'add_states_from_episodes_to_batch': 2.898766356181129e-06, 'batch_individual_items': 1.147435876650181e-05}}, 'connector_pipeline_timer': 7.562940783786872e-05}, 'module_episode_returns_mean': {'target': -9.511370450764895, 'servicer': -1209.6206550030827}, 'episode_len_max': 1000, 'episode_return_min': -1327.5479030336162, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 1.826346863397965e-05, 'agent_to_module_mapping': 7.780966986123444e-06, 'add_observations_from_episodes_to_batch': 4.083066736594803e-05, 'add_states_from_episodes_to_batch': 7.071577994562904e-06, 'batch_individual_items': 3.624192698166662e-05, 'numpy_to_tensor': 4.124257490674532e-05}}, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'num_module_steps_sampled': {'target': 5000, 'servicer': 5000}, 'num_module_steps_sampled_lifetime': {'target': 50000, 'servicer': 50000}, 'episode_duration_sec_mean': 0.5469654820900177, 'rlmodule_inference_timer': 0.0001056247638420456, 'sample': 2.7782938650371687, 'num_agent_steps_sampled_lifetime': {'target': 50000, 'servicer': 50000}, 'num_agent_steps_sampled': {'target': 5000, 'servicer': 5000}, 'connector_pipeline_timer': 0.00027383416570848424, 'num_env_steps_sampled': 5000, 'num_episodes': 5, 'num_episodes_lifetime': 50, 'episode_len_min': 1000, 'episode_return_max': -1127.9669031828894, 'env_reset_timer': 0.00021407950899848837, 'episode_return_mean': -1219.1320254538473, 'num_env_steps_sampled_lifetime': 50000, 'weights_seq_no': 99.0, 'env_step_timer': 9.317072185380736e-05, 'episode_len_mean': 1000.0, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'num_env_steps_sampled_per_second': 1679.033878369688, 'time_between_sampling': 23.165572599077002}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 400000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1082.8071341805723, 'done': False, 'training_iteration': 100, 'trial_id': 'default', 'date': '2025-04-03_20-57-51', 'timestamp': 1743728271, 'time_this_iter_s': 3.679244041442871, 'time_total_s': 272.82737135887146, 'pid': 77277, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x3758dc540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False, 'observation_filter': 'MeanStdFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.02, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 272.82737135887146, 'iterations_since_restore': 100, 'perf': {'cpu_util_percent': 78.88000000000001, 'ram_util_percent': 53.42}})
2025-04-03 20:57:51,624 [__main__] [INFO] 
--- Running Evaluation & Recording Video ---
2025-04-03 20:57:51,625 [__main__] [INFO] Successfully retrieved RLModules for evaluation.
2025-04-03 20:57:51,625 [__main__] [INFO] Evaluation Episode: 1/5
2025-04-03 20:57:51,715 [src.satellite_marl_env] [INFO] MuJoCo Renderer initialized for rgb_array.
2025-04-03 20:57:54,504 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 20:57:54,506 [__main__] [INFO] Evaluation Episode 1 Rewards: {'servicer': -1326.3190865066956, 'target': -15.854057803154012}
2025-04-03 20:57:54,506 [__main__] [INFO] Evaluation Episode: 2/5
2025-04-03 20:57:57,275 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 20:57:57,277 [__main__] [INFO] Evaluation Episode 2 Rewards: {'servicer': -1326.3190865066956, 'target': -15.854057803154012}
2025-04-03 20:57:57,277 [__main__] [INFO] Evaluation Episode: 3/5
2025-04-03 20:57:59,979 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 20:57:59,982 [__main__] [INFO] Evaluation Episode 3 Rewards: {'servicer': -1326.3190865066956, 'target': -15.854057803154012}
2025-04-03 20:57:59,982 [__main__] [INFO] Evaluation Episode: 4/5
2025-04-03 20:58:02,692 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 20:58:02,695 [__main__] [INFO] Evaluation Episode 4 Rewards: {'servicer': -1326.3190865066956, 'target': -15.854057803154012}
2025-04-03 20:58:02,695 [__main__] [INFO] Evaluation Episode: 5/5
2025-04-03 20:58:05,392 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 20:58:05,395 [__main__] [INFO] Evaluation Episode 5 Rewards: {'servicer': -1326.3190865066956, 'target': -15.854057803154012}
2025-04-03 20:58:05,403 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 20:58:05,403 [__main__] [INFO] Average Evaluation Rewards over 5 episodes: {'servicer': -1326.3190865066956, 'target': -15.854057803154012}
2025-04-03 20:58:05,403 [__main__] [INFO] Saving evaluation video to: /Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results/evaluation_video.mp4
2025-04-03 20:58:08,693 [__main__] [INFO] Shutting down Ray...
2025-04-03 20:58:09,014 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 20:58:09,025 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 20:58:10,621 [__main__] [INFO] Script finished.
