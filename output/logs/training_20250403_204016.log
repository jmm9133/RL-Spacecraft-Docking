2025-04-03 20:40:16,984 [__main__] [INFO] Initializing Ray...
2025-04-03 20:40:21,938 [__main__] [INFO] Creating temporary environment to get action/observation spaces...
2025-04-03 20:40:21,941 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 20:40:21,941 [__main__] [INFO] Spaces retrieved.
2025-04-03 20:40:21,941 [__main__] [INFO] Configuring RLlib PPO Algorithm...
2025-04-03 20:40:21,941 [__main__] [INFO] Using 23 environment runners (workers).
2025-04-03 20:40:21,942 [__main__] [INFO] Building Algorithm...
2025-04-03 20:40:35,481 [__main__] [INFO] Algorithm Built. Using Policy/Module Class: DefaultPPOTorchRLModule
2025-04-03 20:40:35,481 [__main__] [INFO] 
--- Starting Training for 100 iterations ---
2025-04-03 20:40:37,630 [__main__] [INFO] Iter: 1/100, Ts(iter): 0, Ts(total): 4000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.15s
2025-04-03 20:40:39,826 [__main__] [INFO] Iter: 2/100, Ts(iter): 0, Ts(total): 8000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.20s
2025-04-03 20:40:42,038 [__main__] [INFO] Iter: 3/100, Ts(iter): 0, Ts(total): 12000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.21s
2025-04-03 20:40:44,019 [__main__] [INFO] Iter: 4/100, Ts(iter): 0, Ts(total): 16000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 1.98s
2025-04-03 20:40:46,297 [__main__] [INFO] Iter: 5/100, Ts(iter): 0, Ts(total): 20000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.28s
2025-04-03 20:40:48,676 [__main__] [INFO] Iter: 6/100, Ts(iter): 0, Ts(total): 24000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.38s
2025-04-03 20:40:50,888 [__main__] [INFO] Iter: 7/100, Ts(iter): 0, Ts(total): 28000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.21s
2025-04-03 20:40:52,940 [__main__] [INFO] Iter: 8/100, Ts(iter): 0, Ts(total): 32000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.05s
2025-04-03 20:40:55,009 [__main__] [INFO] Iter: 9/100, Ts(iter): 0, Ts(total): 36000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.07s
2025-04-03 20:40:58,153 [__main__] [INFO] Iter: 10/100, Ts(iter): 0, Ts(total): 40000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.14s
2025-04-03 20:41:00,546 [__main__] [INFO] Iter: 11/100, Ts(iter): 0, Ts(total): 44000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.39s
2025-04-03 20:41:02,879 [__main__] [INFO] Iter: 12/100, Ts(iter): 0, Ts(total): 48000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.33s
2025-04-03 20:41:05,093 [__main__] [INFO] Iter: 13/100, Ts(iter): 0, Ts(total): 52000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.21s
2025-04-03 20:41:07,153 [__main__] [INFO] Iter: 14/100, Ts(iter): 0, Ts(total): 56000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.06s
2025-04-03 20:41:09,502 [__main__] [INFO] Iter: 15/100, Ts(iter): 0, Ts(total): 60000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.35s
2025-04-03 20:41:11,557 [__main__] [INFO] Iter: 16/100, Ts(iter): 0, Ts(total): 64000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.05s
2025-04-03 20:41:13,677 [__main__] [INFO] Iter: 17/100, Ts(iter): 0, Ts(total): 68000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.12s
2025-04-03 20:41:15,811 [__main__] [INFO] Iter: 18/100, Ts(iter): 0, Ts(total): 72000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.13s
2025-04-03 20:41:18,109 [__main__] [INFO] Iter: 19/100, Ts(iter): 0, Ts(total): 76000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.30s
2025-04-03 20:41:21,437 [__main__] [INFO] Iter: 20/100, Ts(iter): 0, Ts(total): 80000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.33s
2025-04-03 20:41:21,454 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.158405780317749, 'restore_env_runners': 1.697625697940598e-05, 'training_step': 2.15823447326718, 'env_runner_sampling_timer': 0.24942899697262028, 'learner_update_timer': 1.9032658093483545, 'synch_weights': 0.004377696229189335, 'synch_env_connectors': 0.007308921061744158, 'restore_eval_env_runners': 4.494150634855032e-06, 'evaluation_iteration': 2.905708754408406, 'synch_eval_env_connectors': 0.002168951662024483}, 'env_runners': {'num_module_steps_sampled_lifetime': {'target': 80000, 'servicer': 80000}, 'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 1.5416256928047806e-05, 'add_states_from_episodes_to_batch': 4.0555820991304525e-06, 'add_time_dim_to_batch_and_zero_pad': 6.557111446742756e-06, 'numpy_to_tensor': 2.8438588222526712e-05, 'batch_individual_items': 1.7090526444262167e-05, 'agent_to_module_mapping': 4.152528254926719e-06}}, 'connector_pipeline_timer': 0.00011103188981964264}, 'module_to_env_connector': {'timers': {'connectors': {'module_to_agent_unmapping': 3.616403018116492e-06, 'get_actions': 0.00012828416593604775, 'remove_single_ts_time_rank_from_batch': 1.1331541447970943e-06, 'tensor_to_numpy': 4.8427241431285326e-05, 'normalize_and_clip_actions': 5.2150442434186964e-05, 'listify_data_for_vector_env': 9.586233341367014e-06, 'un_batch_to_individual_items': 2.0858236539760895e-05}}, 'connector_pipeline_timer': 0.0003083723075915794}, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 80000, 'servicer': 80000}, 'timers': {'connectors': {'agent_to_module_mapping': 9.363578283227973e-05, 'batch_individual_items': 4.139121712954796e-05, 'add_observations_from_episodes_to_batch': 4.1268216117042236e-05, 'add_time_dim_to_batch_and_zero_pad': 1.900895617639079e-05, 'add_states_from_episodes_to_batch': 7.0145223340343525e-06, 'numpy_to_tensor': 5.42011757320522e-05}}, 'weights_seq_no': 19.0, 'env_step_timer': 0.00012247703145768134, 'num_env_steps_sampled': 4000, 'connector_pipeline_timer': 0.0004174982611363268, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'env_to_module_sum_episodes_length_out': 103.42885547936852, 'rlmodule_inference_timer': 0.00014462600158417931, 'sample': 0.14636654531078847, 'env_reset_timer': 0.00022442026111884448, 'env_to_module_sum_episodes_length_in': 103.42885547936852, 'num_env_steps_sampled_lifetime': 80000, 'time_between_sampling': 2.016677628289853, 'agent_episode_returns_mean': {'servicer': -1087.9366401099176, 'target': -17.34433212417623}, 'episode_return_mean': -1105.2809722340942, 'num_episodes': 0, 'module_episode_returns_mean': {'target': -17.34433212417623, 'servicer': -1087.9366401099176}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_duration_sec_mean': 0.8360622773413879, 'episode_len_mean': 1000.0, 'episode_len_max': 1000, 'episode_return_max': -1096.4227507646137, 'episode_return_min': -1119.7433500353509, 'num_episodes_lifetime': 69, 'episode_len_min': 1000, 'num_env_steps_sampled_lifetime_throughput': 1202.0847905576825}, 'learners': {'servicer': {'vf_explained_var': 2.968311309814453e-05, 'weights_seq_no': 20.0, 'policy_loss': 0.05592837929725647, 'num_module_steps_trained': 40320, 'curr_entropy_coeff': 0.01, 'curr_kl_coeff': 0.0003906250058207661, 'gradients_default_optimizer_global_norm': 1.9185562133789062, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'vf_loss_unclipped': 3667.219482421875, 'module_train_batch_size_mean': 128.0, 'total_loss': 9.677390098571777, 'entropy': 9.19609546661377, 'vf_loss': 9.713420867919922, 'mean_kl_loss': 0.005877094808965921, 'default_optimizer_learning_rate': 5e-05, 'num_module_steps_trained_lifetime': 807168, 'num_trainable_parameters': 142093.0}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 0.00020655829169514064, 'add_columns_from_episodes_to_train_batch': 0.06691320841975393, 'add_time_dim_to_batch_and_zero_pad': 1.9515562123939026e-05, 'add_states_from_episodes_to_batch': 4.938678483602488e-06, 'numpy_to_tensor': 0.0001651705911736044, 'general_advantage_estimation': 0.026019772390386407, 'add_one_ts_to_episodes_and_truncate': 0.0048550443923466875, 'agent_to_module_mapping': 0.003324943823985348, 'batch_individual_items': 0.06142975323326402}}, 'connector_pipeline_timer': 0.16311603478213635}, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained_lifetime': 1614336, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained_lifetime': 25224000, 'num_module_steps_trained': 80640, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 8.558768272399902, 'vf_loss': 0.13844157755374908, 'mean_kl_loss': 0.0033580439630895853, 'default_optimizer_learning_rate': 5e-05, 'num_module_steps_trained_lifetime': 807168, 'num_trainable_parameters': 142093.0, 'vf_explained_var': 0.13307994604110718, 'weights_seq_no': 20.0, 'policy_loss': 0.050007857382297516, 'num_module_steps_trained': 40320, 'curr_entropy_coeff': 0.01, 'curr_kl_coeff': 4.882812572759576e-05, 'gradients_default_optimizer_global_norm': 1.4153271913528442, 'vf_loss_unclipped': 0.13844157755374908, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'module_train_batch_size_mean': 128.0, 'total_loss': 0.10286207497119904}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_module_steps_sampled_lifetime': {'target': 10000, 'servicer': 10000}, 'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 1.0431253865240557e-05, 'add_states_from_episodes_to_batch': 2.9159347756696007e-06, 'add_time_dim_to_batch_and_zero_pad': 4.20782987393569e-06, 'numpy_to_tensor': 1.8271745591503757e-05, 'batch_individual_items': 1.1775824963898827e-05, 'agent_to_module_mapping': 2.811976108186665e-06}}, 'connector_pipeline_timer': 7.575285512728695e-05}, 'agent_episode_returns_mean': {'servicer': -1065.378769554343, 'target': -2.3200993476311376}, 'module_to_env_connector': {'timers': {'connectors': {'module_to_agent_unmapping': 2.574294038191554e-06, 'get_actions': 3.32369151041129e-05, 'remove_single_ts_time_rank_from_batch': 8.031070356320311e-07, 'tensor_to_numpy': 3.3807570928681424e-05, 'normalize_and_clip_actions': 3.538996972897207e-05, 'listify_data_for_vector_env': 6.682468329362357e-06, 'un_batch_to_individual_items': 1.4783905209919557e-05}}, 'connector_pipeline_timer': 0.00015791455592978785}, 'num_agent_steps_sampled': {'servicer': 5000, 'target': 5000}, 'num_agent_steps_sampled_lifetime': {'target': 10000, 'servicer': 10000}, 'episode_return_mean': -1067.6988689019743, 'timers': {'connectors': {'agent_to_module_mapping': 5.624840875680092e-06, 'batch_individual_items': 2.729122969612945e-05, 'add_observations_from_episodes_to_batch': 2.987415080278879e-05, 'add_time_dim_to_batch_and_zero_pad': 1.4457388868322597e-05, 'add_states_from_episodes_to_batch': 6.91667211940512e-06, 'numpy_to_tensor': 4.4373592847841785e-05}}, 'num_episodes': 5, 'weights_seq_no': 19.0, 'env_step_timer': 8.941259299827917e-05, 'module_episode_returns_mean': {'target': -2.3200993476311376, 'servicer': -1065.378769554343}, 'num_env_steps_sampled': 5000, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_duration_sec_mean': 0.5433302862007016, 'connector_pipeline_timer': 0.00025252811125246803, 'num_module_steps_sampled': {'servicer': 5000, 'target': 5000}, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'episode_len_mean': 1000.0, 'rlmodule_inference_timer': 0.00010162914919023829, 'episode_len_max': 1000, 'episode_return_max': -1062.708247339549, 'sample': 2.765936448012448, 'env_reset_timer': 0.00014870714247808793, 'num_env_steps_sampled_lifetime': 10000, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'episode_return_min': -1077.6801120268253, 'num_episodes_lifetime': 10, 'episode_len_min': 1000, 'num_env_steps_sampled_per_second': 1721.7316869195627, 'time_between_sampling': 20.365343625002424}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 80000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1202.0847905576825, 'done': False, 'training_iteration': 20, 'trial_id': 'default', 'date': '2025-04-03_20-41-21', 'timestamp': 1743727281, 'time_this_iter_s': 3.3143298625946045, 'time_total_s': 45.72828912734985, 'pid': 76224, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x374ddc540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 45.72828912734985, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 78.17999999999999, 'ram_util_percent': 55.02}})
2025-04-03 20:41:23,876 [__main__] [INFO] Iter: 21/100, Ts(iter): 0, Ts(total): 84000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.42s
2025-04-03 20:41:26,263 [__main__] [INFO] Iter: 22/100, Ts(iter): 0, Ts(total): 88000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.39s
2025-04-03 20:41:28,340 [__main__] [INFO] Iter: 23/100, Ts(iter): 0, Ts(total): 92000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.08s
2025-04-03 20:41:30,365 [__main__] [INFO] Iter: 24/100, Ts(iter): 0, Ts(total): 96000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.03s
2025-04-03 20:41:32,830 [__main__] [INFO] Iter: 25/100, Ts(iter): 0, Ts(total): 100000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.46s
2025-04-03 20:41:34,813 [__main__] [INFO] Iter: 26/100, Ts(iter): 0, Ts(total): 104000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 1.98s
2025-04-03 20:41:36,748 [__main__] [INFO] Iter: 27/100, Ts(iter): 0, Ts(total): 108000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 1.94s
2025-04-03 20:41:39,136 [__main__] [INFO] Iter: 28/100, Ts(iter): 0, Ts(total): 112000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.39s
2025-04-03 20:41:41,159 [__main__] [INFO] Iter: 29/100, Ts(iter): 0, Ts(total): 116000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.02s
2025-04-03 20:41:44,386 [__main__] [INFO] Iter: 30/100, Ts(iter): 0, Ts(total): 120000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.23s
2025-04-03 20:41:46,367 [__main__] [INFO] Iter: 31/100, Ts(iter): 0, Ts(total): 124000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 1.98s
2025-04-03 20:41:48,686 [__main__] [INFO] Iter: 32/100, Ts(iter): 0, Ts(total): 128000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.32s
2025-04-03 20:41:50,985 [__main__] [INFO] Iter: 33/100, Ts(iter): 0, Ts(total): 132000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.30s
2025-04-03 20:41:53,138 [__main__] [INFO] Iter: 34/100, Ts(iter): 0, Ts(total): 136000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.15s
2025-04-03 20:41:55,256 [__main__] [INFO] Iter: 35/100, Ts(iter): 0, Ts(total): 140000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.12s
2025-04-03 20:41:57,585 [__main__] [INFO] Iter: 36/100, Ts(iter): 0, Ts(total): 144000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.33s
2025-04-03 20:41:59,862 [__main__] [INFO] Iter: 37/100, Ts(iter): 0, Ts(total): 148000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.28s
2025-04-03 20:42:01,978 [__main__] [INFO] Iter: 38/100, Ts(iter): 0, Ts(total): 152000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.12s
2025-04-03 20:42:04,392 [__main__] [INFO] Iter: 39/100, Ts(iter): 0, Ts(total): 156000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.41s
2025-04-03 20:42:07,574 [__main__] [INFO] Iter: 40/100, Ts(iter): 0, Ts(total): 160000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.18s
2025-04-03 20:42:07,590 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.1818143859978707, 'restore_env_runners': 1.5268285634662475e-05, 'training_step': 2.181648151957025, 'env_runner_sampling_timer': 0.23988157232866034, 'learner_update_timer': 1.936058426135746, 'synch_weights': 0.004431330010017216, 'synch_env_connectors': 0.007292170782427885, 'restore_eval_env_runners': 4.523395481635816e-06, 'evaluation_iteration': 2.9065659919381246, 'synch_eval_env_connectors': 0.0021548067763830186}, 'env_runners': {'num_module_steps_sampled_lifetime': {'target': 160000, 'servicer': 160000}, 'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 1.514256414761455e-05, 'add_states_from_episodes_to_batch': 3.9397849317869356e-06, 'add_time_dim_to_batch_and_zero_pad': 6.23692455102483e-06, 'numpy_to_tensor': 2.7482156239234016e-05, 'batch_individual_items': 1.7039071547301613e-05, 'agent_to_module_mapping': 3.97564904181346e-06}}, 'connector_pipeline_timer': 0.00010833177632011415}, 'module_to_env_connector': {'timers': {'connectors': {'module_to_agent_unmapping': 3.556448589942532e-06, 'get_actions': 0.0001230018577516357, 'remove_single_ts_time_rank_from_batch': 1.1288398955634085e-06, 'tensor_to_numpy': 4.58887553018985e-05, 'normalize_and_clip_actions': 4.999547305606372e-05, 'listify_data_for_vector_env': 9.16929024698615e-06, 'un_batch_to_individual_items': 2.053655656945143e-05}}, 'connector_pipeline_timer': 0.0002959153932392857}, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 160000, 'servicer': 160000}, 'timers': {'connectors': {'agent_to_module_mapping': 9.363578283227973e-05, 'batch_individual_items': 4.139121712954796e-05, 'add_observations_from_episodes_to_batch': 4.1268216117042236e-05, 'add_time_dim_to_batch_and_zero_pad': 1.900895617639079e-05, 'add_states_from_episodes_to_batch': 7.0145223340343525e-06, 'numpy_to_tensor': 5.42011757320522e-05}}, 'weights_seq_no': 39.0, 'env_step_timer': 0.00011907186030434152, 'num_env_steps_sampled': 4000, 'connector_pipeline_timer': 0.0004174982611363268, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'env_to_module_sum_episodes_length_out': 106.27241732416265, 'rlmodule_inference_timer': 0.00013982917904152323, 'sample': 0.14686486016118006, 'env_reset_timer': 0.00022442026111884448, 'env_to_module_sum_episodes_length_in': 106.27241732416265, 'num_env_steps_sampled_lifetime': 160000, 'time_between_sampling': 2.0413259445793654, 'agent_episode_returns_mean': {'servicer': -1087.5602394322505, 'target': -17.232385426526484}, 'episode_return_mean': -1104.7926248587771, 'num_episodes': 0, 'module_episode_returns_mean': {'target': -17.232385426526484, 'servicer': -1087.5602394322505}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_duration_sec_mean': 0.8116973658711093, 'episode_len_mean': 1000.0, 'episode_len_max': 1000, 'episode_return_max': -1095.063653364894, 'episode_return_min': -1112.6559383371277, 'num_episodes_lifetime': 138, 'episode_len_min': 1000, 'num_env_steps_sampled_lifetime_throughput': 1257.1319156088846}, 'learners': {'servicer': {'vf_explained_var': 0.0005494952201843262, 'weights_seq_no': 40.0, 'policy_loss': 0.10120737552642822, 'num_module_steps_trained': 40320, 'curr_entropy_coeff': 0.01, 'curr_kl_coeff': 7.629394644936838e-07, 'gradients_default_optimizer_global_norm': 0.9512544870376587, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'vf_loss_unclipped': 3581.403564453125, 'module_train_batch_size_mean': 128.0, 'total_loss': 9.64392375946045, 'entropy': 9.656452178955078, 'vf_loss': 9.639281272888184, 'mean_kl_loss': 0.006638797931373119, 'default_optimizer_learning_rate': 5e-05, 'num_module_steps_trained_lifetime': 1614208, 'num_trainable_parameters': 142093.0}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 0.00020853800157531036, 'add_columns_from_episodes_to_train_batch': 0.0669552438103121, 'add_time_dim_to_batch_and_zero_pad': 1.9247861448656692e-05, 'add_states_from_episodes_to_batch': 4.892788444034597e-06, 'numpy_to_tensor': 0.00016367317108744245, 'general_advantage_estimation': 0.025452566365248556, 'add_one_ts_to_episodes_and_truncate': 0.004862338074526001, 'agent_to_module_mapping': 0.0033362098693311957, 'batch_individual_items': 0.0622158792663173}}, 'connector_pipeline_timer': 0.16339234643446454}, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained_lifetime': 3228416, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained_lifetime': 50444000, 'num_module_steps_trained': 80640, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 8.366544723510742, 'vf_loss': 0.08105747401714325, 'mean_kl_loss': 0.004559063818305731, 'default_optimizer_learning_rate': 5e-05, 'num_module_steps_trained_lifetime': 1614208, 'num_trainable_parameters': 142093.0, 'vf_explained_var': 0.4551055431365967, 'weights_seq_no': 40.0, 'policy_loss': 0.043108198791742325, 'num_module_steps_trained': 40320, 'curr_entropy_coeff': 0.01, 'curr_kl_coeff': 1.1920929132713809e-08, 'gradients_default_optimizer_global_norm': 1.4086180925369263, 'vf_loss_unclipped': 0.08105747401714325, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'module_train_batch_size_mean': 128.0, 'total_loss': 0.04050023853778839}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_module_steps_sampled_lifetime': {'target': 20000, 'servicer': 20000}, 'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 1.0449374488091898e-05, 'add_states_from_episodes_to_batch': 2.916701730056135e-06, 'add_time_dim_to_batch_and_zero_pad': 4.207943543918005e-06, 'numpy_to_tensor': 1.8283901807999625e-05, 'batch_individual_items': 1.178076558970199e-05, 'agent_to_module_mapping': 2.8137898193537604e-06}}, 'connector_pipeline_timer': 7.580410575393535e-05}, 'agent_episode_returns_mean': {'servicer': -1067.069473225909, 'target': -2.7777765789330005}, 'module_to_env_connector': {'timers': {'connectors': {'module_to_agent_unmapping': 2.575136636824321e-06, 'get_actions': 3.327400931989913e-05, 'remove_single_ts_time_rank_from_batch': 8.034426102144446e-07, 'tensor_to_numpy': 3.382047223847305e-05, 'normalize_and_clip_actions': 3.5404604088923397e-05, 'listify_data_for_vector_env': 6.685570280637121e-06, 'un_batch_to_individual_items': 1.478750332454038e-05}}, 'connector_pipeline_timer': 0.00015801428710722417}, 'num_agent_steps_sampled': {'servicer': 5000, 'target': 5000}, 'num_agent_steps_sampled_lifetime': {'target': 20000, 'servicer': 20000}, 'episode_return_mean': -1069.8472498048418, 'timers': {'connectors': {'agent_to_module_mapping': 5.62414872594687e-06, 'batch_individual_items': 2.7288068669022468e-05, 'add_observations_from_episodes_to_batch': 2.9870349993162816e-05, 'add_time_dim_to_batch_and_zero_pad': 1.4454511701207959e-05, 'add_states_from_episodes_to_batch': 6.914994436383712e-06, 'numpy_to_tensor': 4.4368479367177056e-05}}, 'num_episodes': 5, 'weights_seq_no': 39.0, 'env_step_timer': 8.947433189288125e-05, 'module_episode_returns_mean': {'target': -2.7777765789330005, 'servicer': -1067.069473225909}, 'num_env_steps_sampled': 5000, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_duration_sec_mean': 0.5443131834204542, 'connector_pipeline_timer': 0.0002524685757518152, 'num_module_steps_sampled': {'servicer': 5000, 'target': 5000}, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'episode_len_mean': 1000.0, 'rlmodule_inference_timer': 0.0001017152104092576, 'episode_len_max': 1000, 'episode_return_max': -1058.0854663372045, 'sample': 2.7659697812173096, 'env_reset_timer': 0.00014869985903283523, 'num_env_steps_sampled_lifetime': 20000, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'episode_return_min': -1078.2568531362717, 'num_episodes_lifetime': 20, 'episode_len_min': 1000, 'num_env_steps_sampled_per_second': 1721.709745000185, 'time_between_sampling': 20.365306252428052}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 160000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1257.1319156088846, 'done': False, 'training_iteration': 40, 'trial_id': 'default', 'date': '2025-04-03_20-42-07', 'timestamp': 1743727327, 'time_this_iter_s': 3.1690468788146973, 'time_total_s': 91.58834981918335, 'pid': 76224, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x374ddc540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 91.58834981918335, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': 79.4, 'ram_util_percent': 55.1}})
2025-04-03 20:42:09,758 [__main__] [INFO] Iter: 41/100, Ts(iter): 0, Ts(total): 164000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.17s
2025-04-03 20:42:11,680 [__main__] [INFO] Iter: 42/100, Ts(iter): 0, Ts(total): 168000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 1.92s
2025-04-03 20:42:14,091 [__main__] [INFO] Iter: 43/100, Ts(iter): 0, Ts(total): 172000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.41s
2025-04-03 20:42:16,244 [__main__] [INFO] Iter: 44/100, Ts(iter): 0, Ts(total): 176000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.15s
2025-04-03 20:42:18,368 [__main__] [INFO] Iter: 45/100, Ts(iter): 0, Ts(total): 180000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.12s
2025-04-03 20:42:20,589 [__main__] [INFO] Iter: 46/100, Ts(iter): 0, Ts(total): 184000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.22s
2025-04-03 20:42:22,680 [__main__] [INFO] Iter: 47/100, Ts(iter): 0, Ts(total): 188000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.09s
2025-04-03 20:42:25,041 [__main__] [INFO] Iter: 48/100, Ts(iter): 0, Ts(total): 192000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.36s
2025-04-03 20:42:27,441 [__main__] [INFO] Iter: 49/100, Ts(iter): 0, Ts(total): 196000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.40s
2025-04-03 20:42:30,635 [__main__] [INFO] Iter: 50/100, Ts(iter): 0, Ts(total): 200000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.19s
2025-04-03 20:42:32,741 [__main__] [INFO] Iter: 51/100, Ts(iter): 0, Ts(total): 204000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.11s
2025-04-03 20:42:34,915 [__main__] [INFO] Iter: 52/100, Ts(iter): 0, Ts(total): 208000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.17s
2025-04-03 20:42:37,416 [__main__] [INFO] Iter: 53/100, Ts(iter): 0, Ts(total): 212000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.50s
2025-04-03 20:42:39,602 [__main__] [INFO] Iter: 54/100, Ts(iter): 0, Ts(total): 216000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.19s
2025-04-03 20:42:42,080 [__main__] [INFO] Iter: 55/100, Ts(iter): 0, Ts(total): 220000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.48s
2025-04-03 20:42:44,453 [__main__] [INFO] Iter: 56/100, Ts(iter): 0, Ts(total): 224000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.37s
2025-04-03 20:42:46,910 [__main__] [INFO] Iter: 57/100, Ts(iter): 0, Ts(total): 228000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.46s
2025-04-03 20:42:49,227 [__main__] [INFO] Iter: 58/100, Ts(iter): 0, Ts(total): 232000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.32s
2025-04-03 20:42:51,379 [__main__] [INFO] Iter: 59/100, Ts(iter): 0, Ts(total): 236000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.15s
2025-04-03 20:42:54,877 [__main__] [INFO] Iter: 60/100, Ts(iter): 0, Ts(total): 240000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.50s
2025-04-03 20:42:54,896 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.2120623049742068, 'restore_env_runners': 1.4055215877168306e-05, 'training_step': 2.2119011073123542, 'env_runner_sampling_timer': 0.23329120571587533, 'learner_update_timer': 1.9727206355685252, 'synch_weights': 0.004505022144821294, 'synch_env_connectors': 0.007326012333640155, 'restore_eval_env_runners': 4.6009449592922e-06, 'evaluation_iteration': 2.9080010525318394, 'synch_eval_env_connectors': 0.0021377944374913562}, 'env_runners': {'num_module_steps_sampled_lifetime': {'target': 240000, 'servicer': 240000}, 'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 1.6792018681804226e-05, 'add_states_from_episodes_to_batch': 4.299770351199706e-06, 'add_time_dim_to_batch_and_zero_pad': 6.846321975825832e-06, 'numpy_to_tensor': 3.06890776875594e-05, 'batch_individual_items': 1.872757559560905e-05, 'agent_to_module_mapping': 4.3767765747762575e-06}}, 'connector_pipeline_timer': 0.00011904322959675616}, 'module_to_env_connector': {'timers': {'connectors': {'module_to_agent_unmapping': 3.889513678578085e-06, 'get_actions': 0.0001346611852708745, 'remove_single_ts_time_rank_from_batch': 1.2661361434726964e-06, 'tensor_to_numpy': 4.9909288983731496e-05, 'normalize_and_clip_actions': 5.5488156828867785e-05, 'listify_data_for_vector_env': 1.0079055112922135e-05, 'un_batch_to_individual_items': 2.2143445751827974e-05}}, 'connector_pipeline_timer': 0.00032396020763907383}, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 240000, 'servicer': 240000}, 'timers': {'connectors': {'agent_to_module_mapping': 9.363578283227973e-05, 'batch_individual_items': 4.139121712954796e-05, 'add_observations_from_episodes_to_batch': 4.1268216117042236e-05, 'add_time_dim_to_batch_and_zero_pad': 1.900895617639079e-05, 'add_states_from_episodes_to_batch': 7.0145223340343525e-06, 'numpy_to_tensor': 5.42011757320522e-05}}, 'weights_seq_no': 59.0, 'env_step_timer': 0.00012755385163783561, 'num_env_steps_sampled': 4000, 'connector_pipeline_timer': 0.0004174982611363268, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'env_to_module_sum_episodes_length_out': 101.27250081465326, 'rlmodule_inference_timer': 0.0001531775294925826, 'sample': 0.14820788129399784, 'env_reset_timer': 0.00022442026111884448, 'env_to_module_sum_episodes_length_in': 101.27250081465326, 'num_env_steps_sampled_lifetime': 240000, 'time_between_sampling': 2.0676863539433494, 'agent_episode_returns_mean': {'servicer': -1076.9979910246448, 'target': -17.412244337486186}, 'episode_return_mean': -1094.410235362131, 'num_episodes': 0, 'module_episode_returns_mean': {'target': -17.412244337486186, 'servicer': -1076.9979910246448}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_duration_sec_mean': 0.8831786229502935, 'episode_len_mean': 1000.0, 'episode_len_max': 1000, 'episode_return_max': -1085.8880404065674, 'episode_return_min': -1107.6753766184736, 'num_episodes_lifetime': 230, 'episode_len_min': 1000, 'num_env_steps_sampled_lifetime_throughput': 1142.8566804936847}, 'learners': {'servicer': {'vf_explained_var': 0.0003757476806640625, 'weights_seq_no': 60.0, 'policy_loss': -0.06362338364124298, 'num_module_steps_trained': 40320, 'curr_entropy_coeff': 0.01, 'curr_kl_coeff': 1.4901161415892261e-09, 'gradients_default_optimizer_global_norm': 1.7055102586746216, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'vf_loss_unclipped': 3278.815673828125, 'module_train_batch_size_mean': 128.0, 'total_loss': 9.625875473022461, 'entropy': 10.80929946899414, 'vf_loss': 9.797591209411621, 'mean_kl_loss': 0.005143354646861553, 'default_optimizer_learning_rate': 5e-05, 'num_module_steps_trained_lifetime': 2421376, 'num_trainable_parameters': 142093.0}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 0.0002113546238044078, 'add_columns_from_episodes_to_train_batch': 0.06703680709946622, 'add_time_dim_to_batch_and_zero_pad': 1.8955766960878915e-05, 'add_states_from_episodes_to_batch': 4.839718404642494e-06, 'numpy_to_tensor': 0.0001616479558397891, 'general_advantage_estimation': 0.024659763705241047, 'add_one_ts_to_episodes_and_truncate': 0.00487294275964156, 'agent_to_module_mapping': 0.003351681561396267, 'batch_individual_items': 0.06339481034915383}}, 'connector_pipeline_timer': 0.16388197399900636}, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained_lifetime': 4842752, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained_lifetime': 75668000, 'num_module_steps_trained': 80640, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 8.57447624206543, 'vf_loss': 0.18350106477737427, 'mean_kl_loss': 0.004263144452124834, 'default_optimizer_learning_rate': 5e-05, 'num_module_steps_trained_lifetime': 2421376, 'num_trainable_parameters': 142093.0, 'vf_explained_var': 0.08318620920181274, 'weights_seq_no': 60.0, 'policy_loss': -0.07909387350082397, 'num_module_steps_trained': 40320, 'curr_entropy_coeff': 0.01, 'curr_kl_coeff': 5.8207661780829145e-12, 'gradients_default_optimizer_global_norm': 1.260769009590149, 'vf_loss_unclipped': 0.18350106477737427, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'module_train_batch_size_mean': 128.0, 'total_loss': 0.018662430346012115}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_module_steps_sampled_lifetime': {'target': 30000, 'servicer': 30000}, 'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 1.0463186699049307e-05, 'add_states_from_episodes_to_batch': 2.916870771377685e-06, 'add_time_dim_to_batch_and_zero_pad': 4.2038155538611685e-06, 'numpy_to_tensor': 1.8289085735377613e-05, 'batch_individual_items': 1.178100344889601e-05, 'agent_to_module_mapping': 2.814753514107112e-06}}, 'connector_pipeline_timer': 7.582796063176892e-05}, 'agent_episode_returns_mean': {'servicer': -1065.0485087818163, 'target': -3.182495449304582}, 'module_to_env_connector': {'timers': {'connectors': {'module_to_agent_unmapping': 2.5735236017320948e-06, 'get_actions': 3.3326732638159056e-05, 'remove_single_ts_time_rank_from_batch': 8.032339257095832e-07, 'tensor_to_numpy': 3.38205971652888e-05, 'normalize_and_clip_actions': 3.5414748006394844e-05, 'listify_data_for_vector_env': 6.688465273583818e-06, 'un_batch_to_individual_items': 1.4781988278445834e-05}}, 'connector_pipeline_timer': 0.0001580859481995012}, 'num_agent_steps_sampled': {'servicer': 5000, 'target': 5000}, 'num_agent_steps_sampled_lifetime': {'target': 30000, 'servicer': 30000}, 'episode_return_mean': -1068.231004231121, 'timers': {'connectors': {'agent_to_module_mapping': 5.6229354881783605e-06, 'batch_individual_items': 2.7282537552898147e-05, 'add_observations_from_episodes_to_batch': 2.986396844219855e-05, 'add_time_dim_to_batch_and_zero_pad': 1.4449514179486728e-05, 'add_states_from_episodes_to_batch': 6.912071654593584e-06, 'numpy_to_tensor': 4.4360555804092944e-05}}, 'num_episodes': 5, 'weights_seq_no': 59.0, 'env_step_timer': 8.948997694014802e-05, 'module_episode_returns_mean': {'target': -3.182495449304582, 'servicer': -1065.0485087818163}, 'num_env_steps_sampled': 5000, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_duration_sec_mean': 0.544548471760354, 'connector_pipeline_timer': 0.000252365105447614, 'num_module_steps_sampled': {'servicer': 5000, 'target': 5000}, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'episode_len_mean': 1000.0, 'rlmodule_inference_timer': 0.00010174648288257418, 'episode_len_max': 1000, 'episode_return_max': -1053.0877850738625, 'sample': 2.7660112517154682, 'env_reset_timer': 0.0001486824173311253, 'num_env_steps_sampled_lifetime': 30000, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'episode_return_min': -1078.2568531362717, 'num_episodes_lifetime': 30, 'episode_len_min': 1000, 'num_env_steps_sampled_per_second': 1721.6800079881928, 'time_between_sampling': 20.365341251842064}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 240000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1142.8566804936847, 'done': False, 'training_iteration': 60, 'trial_id': 'default', 'date': '2025-04-03_20-42-54', 'timestamp': 1743727374, 'time_this_iter_s': 3.483686923980713, 'time_total_s': 138.59268379211426, 'pid': 76224, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x374ddc540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 138.59268379211426, 'iterations_since_restore': 60, 'perf': {'cpu_util_percent': 77.94000000000001, 'ram_util_percent': 55.1}})
2025-04-03 20:42:57,305 [__main__] [INFO] Iter: 61/100, Ts(iter): 0, Ts(total): 244000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.41s
2025-04-03 20:42:59,741 [__main__] [INFO] Iter: 62/100, Ts(iter): 0, Ts(total): 248000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.44s
2025-04-03 20:43:02,215 [__main__] [INFO] Iter: 63/100, Ts(iter): 0, Ts(total): 252000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.47s
2025-04-03 20:43:04,808 [__main__] [INFO] Iter: 64/100, Ts(iter): 0, Ts(total): 256000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.59s
2025-04-03 20:43:07,163 [__main__] [INFO] Iter: 65/100, Ts(iter): 0, Ts(total): 260000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.35s
2025-04-03 20:43:09,453 [__main__] [INFO] Iter: 66/100, Ts(iter): 0, Ts(total): 264000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.29s
2025-04-03 20:43:12,025 [__main__] [INFO] Iter: 67/100, Ts(iter): 0, Ts(total): 268000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.57s
2025-04-03 20:43:14,599 [__main__] [INFO] Iter: 68/100, Ts(iter): 0, Ts(total): 272000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.57s
2025-04-03 20:43:17,065 [__main__] [INFO] Iter: 69/100, Ts(iter): 0, Ts(total): 276000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.47s
2025-04-03 20:43:20,258 [__main__] [INFO] Iter: 70/100, Ts(iter): 0, Ts(total): 280000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.19s
2025-04-03 20:43:22,786 [__main__] [INFO] Iter: 71/100, Ts(iter): 0, Ts(total): 284000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.53s
2025-04-03 20:43:25,057 [__main__] [INFO] Iter: 72/100, Ts(iter): 0, Ts(total): 288000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.27s
2025-04-03 20:43:27,588 [__main__] [INFO] Iter: 73/100, Ts(iter): 0, Ts(total): 292000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.53s
2025-04-03 20:43:29,667 [__main__] [INFO] Iter: 74/100, Ts(iter): 0, Ts(total): 296000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.08s
2025-04-03 20:43:31,808 [__main__] [INFO] Iter: 75/100, Ts(iter): 0, Ts(total): 300000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.14s
2025-04-03 20:43:34,141 [__main__] [INFO] Iter: 76/100, Ts(iter): 0, Ts(total): 304000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.33s
2025-04-03 20:43:36,261 [__main__] [INFO] Iter: 77/100, Ts(iter): 0, Ts(total): 308000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.12s
2025-04-03 20:43:38,361 [__main__] [INFO] Iter: 78/100, Ts(iter): 0, Ts(total): 312000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.10s
2025-04-03 20:43:40,837 [__main__] [INFO] Iter: 79/100, Ts(iter): 0, Ts(total): 316000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.48s
2025-04-03 20:43:44,149 [__main__] [INFO] Iter: 80/100, Ts(iter): 0, Ts(total): 320000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.31s
2025-04-03 20:43:44,168 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.2529182567992647, 'restore_env_runners': 1.2928657092651206e-05, 'training_step': 2.252762327880412, 'env_runner_sampling_timer': 0.23089124741316447, 'learner_update_timer': 2.0157843200486845, 'synch_weights': 0.004625150995596811, 'synch_env_connectors': 0.007353906296024008, 'restore_eval_env_runners': 4.644827874214858e-06, 'evaluation_iteration': 2.9099083917831874, 'synch_eval_env_connectors': 0.002123223729070422}, 'env_runners': {'num_module_steps_sampled_lifetime': {'target': 320000, 'servicer': 320000}, 'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 1.6094841945984162e-05, 'add_states_from_episodes_to_batch': 4.048555225433979e-06, 'add_time_dim_to_batch_and_zero_pad': 6.727620876196007e-06, 'numpy_to_tensor': 2.9241251472354855e-05, 'batch_individual_items': 1.7324055066807185e-05, 'agent_to_module_mapping': 4.119441296591426e-06}}, 'connector_pipeline_timer': 0.00011356435763496832}, 'module_to_env_connector': {'timers': {'connectors': {'module_to_agent_unmapping': 3.7477554540715335e-06, 'get_actions': 0.0001291150740539511, 'remove_single_ts_time_rank_from_batch': 1.1741285069080883e-06, 'tensor_to_numpy': 4.7651989306731935e-05, 'normalize_and_clip_actions': 5.243829594261108e-05, 'listify_data_for_vector_env': 9.605288250862939e-06, 'un_batch_to_individual_items': 2.134608656754836e-05}}, 'connector_pipeline_timer': 0.0003100459775644988}, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 320000, 'servicer': 320000}, 'timers': {'connectors': {'agent_to_module_mapping': 9.363578283227973e-05, 'batch_individual_items': 4.139121712954796e-05, 'add_observations_from_episodes_to_batch': 4.1268216117042236e-05, 'add_time_dim_to_batch_and_zero_pad': 1.900895617639079e-05, 'add_states_from_episodes_to_batch': 7.0145223340343525e-06, 'numpy_to_tensor': 5.42011757320522e-05}}, 'weights_seq_no': 79.0, 'env_step_timer': 0.0001229793537808341, 'num_env_steps_sampled': 4000, 'connector_pipeline_timer': 0.0004174982611363268, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'env_to_module_sum_episodes_length_out': 106.95241103664021, 'rlmodule_inference_timer': 0.00014650843900789292, 'sample': 0.1503911553825212, 'env_reset_timer': 0.00022442026111884448, 'env_to_module_sum_episodes_length_in': 106.95241103664021, 'num_env_steps_sampled_lifetime': 320000, 'time_between_sampling': 2.1118978854083412, 'agent_episode_returns_mean': {'servicer': -1070.8655627777332, 'target': -17.577387991379137}, 'episode_return_mean': -1088.4429507691123, 'num_episodes': 0, 'module_episode_returns_mean': {'target': -17.577387991379137, 'servicer': -1070.8655627777332}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_duration_sec_mean': 0.9076086249488465, 'episode_len_mean': 1000.0, 'episode_len_max': 1000, 'episode_return_max': -1071.4131277984175, 'episode_return_min': -1098.6776649232115, 'num_episodes_lifetime': 299, 'episode_len_min': 1000, 'num_env_steps_sampled_lifetime_throughput': 1209.0377536770795}, 'learners': {'servicer': {'vf_explained_var': 0.0024204254150390625, 'weights_seq_no': 80.0, 'policy_loss': 0.014502463862299919, 'num_module_steps_trained': 40320, 'curr_entropy_coeff': 0.01, 'curr_kl_coeff': 7.275957722603643e-13, 'gradients_default_optimizer_global_norm': 1.4015259742736816, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'vf_loss_unclipped': 3108.55029296875, 'module_train_batch_size_mean': 128.0, 'total_loss': 9.446490287780762, 'entropy': 10.601509094238281, 'vf_loss': 9.538002967834473, 'mean_kl_loss': 0.0076059442944824696, 'default_optimizer_learning_rate': 5e-05, 'num_module_steps_trained_lifetime': 3228288, 'num_trainable_parameters': 142093.0}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 0.0002149356021521014, 'add_columns_from_episodes_to_train_batch': 0.06716821923295853, 'add_time_dim_to_batch_and_zero_pad': 1.8654904718012822e-05, 'add_states_from_episodes_to_batch': 4.788094033096743e-06, 'numpy_to_tensor': 0.00015948258569554655, 'general_advantage_estimation': 0.023750843703462175, 'add_one_ts_to_episodes_and_truncate': 0.004889417096573827, 'agent_to_module_mapping': 0.00337744828495329, 'batch_individual_items': 0.06478299082589234}}, 'connector_pipeline_timer': 0.16453121028368714}, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained_lifetime': 6456576, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained_lifetime': 100884000, 'num_module_steps_trained': 80640, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 8.744951248168945, 'vf_loss': 0.1204444169998169, 'mean_kl_loss': 0.0039015542715787888, 'default_optimizer_learning_rate': 5e-05, 'num_module_steps_trained_lifetime': 3228288, 'num_trainable_parameters': 142093.0, 'vf_explained_var': 0.3439042568206787, 'weights_seq_no': 80.0, 'policy_loss': -0.05546880513429642, 'num_module_steps_trained': 40320, 'curr_entropy_coeff': 0.01, 'curr_kl_coeff': 5.684341970784096e-15, 'gradients_default_optimizer_global_norm': 1.0923947095870972, 'vf_loss_unclipped': 0.1204444169998169, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'module_train_batch_size_mean': 128.0, 'total_loss': -0.0224738921970129}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_module_steps_sampled_lifetime': {'target': 40000, 'servicer': 40000}, 'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 1.0468187217537702e-05, 'add_states_from_episodes_to_batch': 2.917135331218772e-06, 'add_time_dim_to_batch_and_zero_pad': 4.2004407555942175e-06, 'numpy_to_tensor': 1.829461689996253e-05, 'batch_individual_items': 1.1784122048557534e-05, 'agent_to_module_mapping': 2.8150375205391364e-06}}, 'connector_pipeline_timer': 7.584295636064707e-05}, 'agent_episode_returns_mean': {'servicer': -1058.580667978916, 'target': -3.915908196181059}, 'module_to_env_connector': {'timers': {'connectors': {'module_to_agent_unmapping': 2.5737239209568516e-06, 'get_actions': 3.339596026085732e-05, 'remove_single_ts_time_rank_from_batch': 8.032505125517612e-07, 'tensor_to_numpy': 3.38169234573766e-05, 'normalize_and_clip_actions': 3.540413412704981e-05, 'listify_data_for_vector_env': 6.690852749124949e-06, 'un_batch_to_individual_items': 1.478612966403541e-05}}, 'connector_pipeline_timer': 0.00015815378882196357}, 'num_agent_steps_sampled': {'servicer': 5000, 'target': 5000}, 'num_agent_steps_sampled_lifetime': {'target': 40000, 'servicer': 40000}, 'episode_return_mean': -1062.4965761750973, 'timers': {'connectors': {'agent_to_module_mapping': 5.6211972597561005e-06, 'batch_individual_items': 2.7274622827299853e-05, 'add_observations_from_episodes_to_batch': 2.985466776881516e-05, 'add_time_dim_to_batch_and_zero_pad': 1.4442765356447293e-05, 'add_states_from_episodes_to_batch': 6.907921295410324e-06, 'numpy_to_tensor': 4.4351232251884956e-05}}, 'num_episodes': 5, 'weights_seq_no': 79.0, 'env_step_timer': 8.949552004123625e-05, 'module_episode_returns_mean': {'target': -3.915908196181059, 'servicer': -1058.580667978916}, 'num_env_steps_sampled': 5000, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_duration_sec_mean': 0.5453597775900562, 'connector_pipeline_timer': 0.00025221987500787527, 'num_module_steps_sampled': {'servicer': 5000, 'target': 5000}, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'episode_len_mean': 1000.0, 'rlmodule_inference_timer': 0.00010177913136278712, 'episode_len_max': 1000, 'episode_return_max': -1011.5511544488048, 'sample': 2.766073529075446, 'env_reset_timer': 0.00014865504484310317, 'num_env_steps_sampled_lifetime': 40000, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'episode_return_min': -1078.2568531362717, 'num_episodes_lifetime': 40, 'episode_len_min': 1000, 'num_env_steps_sampled_per_second': 1721.6281572614935, 'time_between_sampling': 20.366006115199216}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 320000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1209.0377536770795, 'done': False, 'training_iteration': 80, 'trial_id': 'default', 'date': '2025-04-03_20-43-44', 'timestamp': 1743727424, 'time_this_iter_s': 3.2944960594177246, 'time_total_s': 187.5593671798706, 'pid': 76224, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x374ddc540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 187.5593671798706, 'iterations_since_restore': 80, 'perf': {'cpu_util_percent': 78.07499999999999, 'ram_util_percent': 55.2}})
2025-04-03 20:43:46,418 [__main__] [INFO] Iter: 81/100, Ts(iter): 0, Ts(total): 324000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.25s
2025-04-03 20:43:48,396 [__main__] [INFO] Iter: 82/100, Ts(iter): 0, Ts(total): 328000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 1.98s
2025-04-03 20:43:50,608 [__main__] [INFO] Iter: 83/100, Ts(iter): 0, Ts(total): 332000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.21s
2025-04-03 20:43:53,026 [__main__] [INFO] Iter: 84/100, Ts(iter): 0, Ts(total): 336000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.42s
2025-04-03 20:43:55,409 [__main__] [INFO] Iter: 85/100, Ts(iter): 0, Ts(total): 340000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.38s
2025-04-03 20:43:57,472 [__main__] [INFO] Iter: 86/100, Ts(iter): 0, Ts(total): 344000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.06s
2025-04-03 20:43:59,518 [__main__] [INFO] Iter: 87/100, Ts(iter): 0, Ts(total): 348000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.05s
2025-04-03 20:44:02,027 [__main__] [INFO] Iter: 88/100, Ts(iter): 0, Ts(total): 352000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.51s
2025-04-03 20:44:04,160 [__main__] [INFO] Iter: 89/100, Ts(iter): 0, Ts(total): 356000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.13s
2025-04-03 20:44:07,431 [__main__] [INFO] Iter: 90/100, Ts(iter): 0, Ts(total): 360000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.27s
2025-04-03 20:44:09,503 [__main__] [INFO] Iter: 91/100, Ts(iter): 0, Ts(total): 364000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.07s
2025-04-03 20:44:11,645 [__main__] [INFO] Iter: 92/100, Ts(iter): 0, Ts(total): 368000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.14s
2025-04-03 20:44:13,817 [__main__] [INFO] Iter: 93/100, Ts(iter): 0, Ts(total): 372000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.17s
2025-04-03 20:44:16,163 [__main__] [INFO] Iter: 94/100, Ts(iter): 0, Ts(total): 376000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.35s
2025-04-03 20:44:18,471 [__main__] [INFO] Iter: 95/100, Ts(iter): 0, Ts(total): 380000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.31s
2025-04-03 20:44:20,664 [__main__] [INFO] Iter: 96/100, Ts(iter): 0, Ts(total): 384000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.19s
2025-04-03 20:44:23,044 [__main__] [INFO] Iter: 97/100, Ts(iter): 0, Ts(total): 388000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.38s
2025-04-03 20:44:25,245 [__main__] [INFO] Iter: 98/100, Ts(iter): 0, Ts(total): 392000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.20s
2025-04-03 20:44:27,567 [__main__] [INFO] Iter: 99/100, Ts(iter): 0, Ts(total): 396000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 2.32s
2025-04-03 20:44:30,783 [__main__] [INFO] Iter: 100/100, Ts(iter): 0, Ts(total): 400000, Reward (Eval/Sample): nan, Loss(serv): nan, Loss(targ): nan, Time: 3.22s
2025-04-03 20:44:30,802 [__main__] [INFO] Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.2635729115154177, 'restore_env_runners': 1.2149063085140043e-05, 'training_step': 2.263420288480966, 'env_runner_sampling_timer': 0.22724484298561495, 'learner_update_timer': 2.029976932256148, 'synch_weights': 0.004651390687839649, 'synch_env_connectors': 0.007330874671821412, 'restore_eval_env_runners': 4.684038321109839e-06, 'evaluation_iteration': 2.9107594154692547, 'synch_eval_env_connectors': 0.002112266797693737}, 'env_runners': {'num_module_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 1.6599866925532404e-05, 'add_states_from_episodes_to_batch': 4.697340916543084e-06, 'add_time_dim_to_batch_and_zero_pad': 6.683646034497674e-06, 'numpy_to_tensor': 3.0304729930834105e-05, 'batch_individual_items': 1.8343413339753484e-05, 'agent_to_module_mapping': 4.516315591612941e-06}}, 'connector_pipeline_timer': 0.00011897239548959943}, 'module_to_env_connector': {'timers': {'connectors': {'module_to_agent_unmapping': 3.902561270652953e-06, 'get_actions': 0.00013406395002380774, 'remove_single_ts_time_rank_from_batch': 1.199779976025498e-06, 'tensor_to_numpy': 4.9279098744900474e-05, 'normalize_and_clip_actions': 5.4647822537190805e-05, 'listify_data_for_vector_env': 9.589769804169622e-06, 'un_batch_to_individual_items': 2.222007755675517e-05}}, 'connector_pipeline_timer': 0.00032190767655115735}, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'timers': {'connectors': {'agent_to_module_mapping': 9.363578283227973e-05, 'batch_individual_items': 4.139121712954796e-05, 'add_observations_from_episodes_to_batch': 4.1268216117042236e-05, 'add_time_dim_to_batch_and_zero_pad': 1.900895617639079e-05, 'add_states_from_episodes_to_batch': 7.0145223340343525e-06, 'numpy_to_tensor': 5.42011757320522e-05}}, 'weights_seq_no': 99.0, 'env_step_timer': 0.00012755042677484993, 'num_env_steps_sampled': 4000, 'connector_pipeline_timer': 0.0004174982611363268, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'env_to_module_sum_episodes_length_out': 101.95413642173257, 'rlmodule_inference_timer': 0.00015274136053019453, 'sample': 0.15161623427949592, 'env_reset_timer': 0.00022442026111884448, 'env_to_module_sum_episodes_length_in': 101.95413642173257, 'num_env_steps_sampled_lifetime': 400000, 'time_between_sampling': 2.1246830316683667, 'agent_episode_returns_mean': {'servicer': -1063.065536140764, 'target': -17.710082869691693}, 'episode_return_mean': -1080.7756190104556, 'num_episodes': 0, 'module_episode_returns_mean': {'target': -17.710082869691693, 'servicer': -1063.065536140764}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_duration_sec_mean': 0.9388858293962624, 'episode_len_mean': 1000.0, 'episode_len_max': 1000, 'episode_return_max': -1062.0357661402606, 'episode_return_min': -1089.1508229452847, 'num_episodes_lifetime': 391, 'episode_len_min': 1000, 'num_env_steps_sampled_lifetime_throughput': 1243.9417285600503}, 'learners': {'servicer': {'vf_explained_var': 0.00047475099563598633, 'weights_seq_no': 100.0, 'policy_loss': 0.012711379677057266, 'num_module_steps_trained': 40320, 'curr_entropy_coeff': 0.01, 'curr_kl_coeff': 7.10542746348012e-16, 'gradients_default_optimizer_global_norm': 1.6485813856124878, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'vf_loss_unclipped': 3486.28759765625, 'module_train_batch_size_mean': 128.0, 'total_loss': 9.715082168579102, 'entropy': 12.50847339630127, 'vf_loss': 9.827455520629883, 'mean_kl_loss': 0.006390842143446207, 'default_optimizer_learning_rate': 5e-05, 'num_module_steps_trained_lifetime': 4035456, 'num_trainable_parameters': 142093.0}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 0.00021891238426184075, 'add_columns_from_episodes_to_train_batch': 0.06731460042852325, 'add_time_dim_to_batch_and_zero_pad': 1.830777500227034e-05, 'add_states_from_episodes_to_batch': 4.731875063343223e-06, 'numpy_to_tensor': 0.0001570873135219681, 'general_advantage_estimation': 0.022790072278253366, 'add_one_ts_to_episodes_and_truncate': 0.00490655427180361, 'agent_to_module_mapping': 0.0034053385564980494, 'batch_individual_items': 0.06613701454209729}}, 'connector_pipeline_timer': 0.1651120221081922}, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained_lifetime': 8070912, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained_lifetime': 126108000, 'num_module_steps_trained': 80640, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 8.86994743347168, 'vf_loss': 0.15240180492401123, 'mean_kl_loss': 0.004223159980028868, 'default_optimizer_learning_rate': 5e-05, 'num_module_steps_trained_lifetime': 4035456, 'num_trainable_parameters': 142093.0, 'vf_explained_var': 0.0694546103477478, 'weights_seq_no': 100.0, 'policy_loss': 0.1477043181657791, 'num_module_steps_trained': 40320, 'curr_entropy_coeff': 0.01, 'curr_kl_coeff': 1.387778801460961e-18, 'gradients_default_optimizer_global_norm': 0.9252397418022156, 'vf_loss_unclipped': 0.15240180492401123, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'module_train_batch_size_mean': 128.0, 'total_loss': 0.2114066332578659}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_module_steps_sampled_lifetime': {'target': 50000, 'servicer': 50000}, 'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 1.047181452715772e-05, 'add_states_from_episodes_to_batch': 2.9172961671045452e-06, 'add_time_dim_to_batch_and_zero_pad': 4.200229876435613e-06, 'numpy_to_tensor': 1.8305516879544294e-05, 'batch_individual_items': 1.1783597909182454e-05, 'agent_to_module_mapping': 2.816511048776096e-06}}, 'connector_pipeline_timer': 7.58636808022201e-05}, 'agent_episode_returns_mean': {'servicer': -1048.341954903753, 'target': -4.280016130387781}, 'module_to_env_connector': {'timers': {'connectors': {'module_to_agent_unmapping': 2.573298619882895e-06, 'get_actions': 3.340469141761125e-05, 'remove_single_ts_time_rank_from_batch': 8.028156854941452e-07, 'tensor_to_numpy': 3.381095333474469e-05, 'normalize_and_clip_actions': 3.539978054516945e-05, 'listify_data_for_vector_env': 6.69353385986943e-06, 'un_batch_to_individual_items': 1.4785462916465214e-05}}, 'connector_pipeline_timer': 0.00015815786703175073}, 'num_agent_steps_sampled': {'servicer': 5000, 'target': 5000}, 'num_agent_steps_sampled_lifetime': {'target': 50000, 'servicer': 50000}, 'episode_return_mean': -1052.6219710341404, 'timers': {'connectors': {'agent_to_module_mapping': 5.6189646249422415e-06, 'batch_individual_items': 2.7264728913608022e-05, 'add_observations_from_episodes_to_batch': 2.9843317727633868e-05, 'add_time_dim_to_batch_and_zero_pad': 1.4434491205339452e-05, 'add_states_from_episodes_to_batch': 6.902622089224512e-06, 'numpy_to_tensor': 4.434185458290612e-05}}, 'num_episodes': 5, 'weights_seq_no': 99.0, 'env_step_timer': 8.949456320609655e-05, 'module_episode_returns_mean': {'target': -4.280016130387781, 'servicer': -1048.341954903753}, 'num_env_steps_sampled': 5000, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_duration_sec_mean': 0.5439892158894508, 'connector_pipeline_timer': 0.00025203775422295117, 'num_module_steps_sampled': {'servicer': 5000, 'target': 5000}, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'episode_len_mean': 1000.0, 'rlmodule_inference_timer': 0.0001018039622752937, 'episode_len_max': 1000, 'episode_return_max': -1011.5511544488048, 'sample': 2.766144148682682, 'env_reset_timer': 0.00014861854230583708, 'num_env_steps_sampled_lifetime': 50000, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'episode_return_min': -1078.2568531362717, 'num_episodes_lifetime': 50, 'episode_len_min': 1000, 'num_env_steps_sampled_per_second': 1721.5595018529218, 'time_between_sampling': 20.366751731830686}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 400000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1243.9417285600503, 'done': False, 'training_iteration': 100, 'trial_id': 'default', 'date': '2025-04-03_20-44-30', 'timestamp': 1743727470, 'time_this_iter_s': 3.2019858360290527, 'time_total_s': 233.9013683795929, 'pid': 76224, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x374ddc540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 233.9013683795929, 'iterations_since_restore': 100, 'perf': {'cpu_util_percent': 79.44000000000001, 'ram_util_percent': 55.2}})
2025-04-03 20:44:30,802 [__main__] [INFO] 
--- Training Finished ---
2025-04-03 20:44:30,802 [__main__] [INFO] Total Training Time: 235.32 seconds
2025-04-03 20:44:30,803 [__main__] [INFO] Using last checkpoint: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results), metrics={'timers': {'training_iteration': 2.2635729115154177, 'restore_env_runners': 1.2149063085140043e-05, 'training_step': 2.263420288480966, 'env_runner_sampling_timer': 0.22724484298561495, 'learner_update_timer': 2.029976932256148, 'synch_weights': 0.004651390687839649, 'synch_env_connectors': 0.007330874671821412, 'restore_eval_env_runners': 4.684038321109839e-06, 'evaluation_iteration': 2.9107594154692547, 'synch_eval_env_connectors': 0.002112266797693737}, 'env_runners': {'num_module_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 1.6599866925532404e-05, 'add_states_from_episodes_to_batch': 4.697340916543084e-06, 'add_time_dim_to_batch_and_zero_pad': 6.683646034497674e-06, 'numpy_to_tensor': 3.0304729930834105e-05, 'batch_individual_items': 1.8343413339753484e-05, 'agent_to_module_mapping': 4.516315591612941e-06}}, 'connector_pipeline_timer': 0.00011897239548959943}, 'module_to_env_connector': {'timers': {'connectors': {'module_to_agent_unmapping': 3.902561270652953e-06, 'get_actions': 0.00013406395002380774, 'remove_single_ts_time_rank_from_batch': 1.199779976025498e-06, 'tensor_to_numpy': 4.9279098744900474e-05, 'normalize_and_clip_actions': 5.4647822537190805e-05, 'listify_data_for_vector_env': 9.589769804169622e-06, 'un_batch_to_individual_items': 2.222007755675517e-05}}, 'connector_pipeline_timer': 0.00032190767655115735}, 'num_agent_steps_sampled': {'servicer': 4000, 'target': 4000}, 'num_agent_steps_sampled_lifetime': {'target': 400000, 'servicer': 400000}, 'timers': {'connectors': {'agent_to_module_mapping': 9.363578283227973e-05, 'batch_individual_items': 4.139121712954796e-05, 'add_observations_from_episodes_to_batch': 4.1268216117042236e-05, 'add_time_dim_to_batch_and_zero_pad': 1.900895617639079e-05, 'add_states_from_episodes_to_batch': 7.0145223340343525e-06, 'numpy_to_tensor': 5.42011757320522e-05}}, 'weights_seq_no': 99.0, 'env_step_timer': 0.00012755042677484993, 'num_env_steps_sampled': 4000, 'connector_pipeline_timer': 0.0004174982611363268, 'num_module_steps_sampled': {'servicer': 4000, 'target': 4000}, 'env_to_module_sum_episodes_length_out': 101.95413642173257, 'rlmodule_inference_timer': 0.00015274136053019453, 'sample': 0.15161623427949592, 'env_reset_timer': 0.00022442026111884448, 'env_to_module_sum_episodes_length_in': 101.95413642173257, 'num_env_steps_sampled_lifetime': 400000, 'time_between_sampling': 2.1246830316683667, 'agent_episode_returns_mean': {'servicer': -1063.065536140764, 'target': -17.710082869691693}, 'episode_return_mean': -1080.7756190104556, 'num_episodes': 0, 'module_episode_returns_mean': {'target': -17.710082869691693, 'servicer': -1063.065536140764}, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_duration_sec_mean': 0.9388858293962624, 'episode_len_mean': 1000.0, 'episode_len_max': 1000, 'episode_return_max': -1062.0357661402606, 'episode_return_min': -1089.1508229452847, 'num_episodes_lifetime': 391, 'episode_len_min': 1000, 'num_env_steps_sampled_lifetime_throughput': 1243.9417285600503}, 'learners': {'servicer': {'vf_explained_var': 0.00047475099563598633, 'weights_seq_no': 100.0, 'policy_loss': 0.012711379677057266, 'num_module_steps_trained': 40320, 'curr_entropy_coeff': 0.01, 'curr_kl_coeff': 7.10542746348012e-16, 'gradients_default_optimizer_global_norm': 1.6485813856124878, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'vf_loss_unclipped': 3486.28759765625, 'module_train_batch_size_mean': 128.0, 'total_loss': 9.715082168579102, 'entropy': 12.50847339630127, 'vf_loss': 9.827455520629883, 'mean_kl_loss': 0.006390842143446207, 'default_optimizer_learning_rate': 5e-05, 'num_module_steps_trained_lifetime': 4035456, 'num_trainable_parameters': 142093.0}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 0.00021891238426184075, 'add_columns_from_episodes_to_train_batch': 0.06731460042852325, 'add_time_dim_to_batch_and_zero_pad': 1.830777500227034e-05, 'add_states_from_episodes_to_batch': 4.731875063343223e-06, 'numpy_to_tensor': 0.0001570873135219681, 'general_advantage_estimation': 0.022790072278253366, 'add_one_ts_to_episodes_and_truncate': 0.00490655427180361, 'agent_to_module_mapping': 0.0034053385564980494, 'batch_individual_items': 0.06613701454209729}}, 'connector_pipeline_timer': 0.1651120221081922}, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_env_steps_trained': 1260000, 'num_module_steps_trained_lifetime': 8070912, 'num_trainable_parameters': 284186.0, 'num_env_steps_trained_lifetime': 126108000, 'num_module_steps_trained': 80640, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_out': 4000.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'target': {'entropy': 8.86994743347168, 'vf_loss': 0.15240180492401123, 'mean_kl_loss': 0.004223159980028868, 'default_optimizer_learning_rate': 5e-05, 'num_module_steps_trained_lifetime': 4035456, 'num_trainable_parameters': 142093.0, 'vf_explained_var': 0.0694546103477478, 'weights_seq_no': 100.0, 'policy_loss': 0.1477043181657791, 'num_module_steps_trained': 40320, 'curr_entropy_coeff': 0.01, 'curr_kl_coeff': 1.387778801460961e-18, 'gradients_default_optimizer_global_norm': 0.9252397418022156, 'vf_loss_unclipped': 0.15240180492401123, 'diff_num_grad_updates_vs_sampler_policy': 1.0, 'module_train_batch_size_mean': 128.0, 'total_loss': 0.2114066332578659}}, 'num_training_step_calls_per_iteration': 1, 'evaluation': {'env_runners': {'num_module_steps_sampled_lifetime': {'target': 50000, 'servicer': 50000}, 'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 1.047181452715772e-05, 'add_states_from_episodes_to_batch': 2.9172961671045452e-06, 'add_time_dim_to_batch_and_zero_pad': 4.200229876435613e-06, 'numpy_to_tensor': 1.8305516879544294e-05, 'batch_individual_items': 1.1783597909182454e-05, 'agent_to_module_mapping': 2.816511048776096e-06}}, 'connector_pipeline_timer': 7.58636808022201e-05}, 'agent_episode_returns_mean': {'servicer': -1048.341954903753, 'target': -4.280016130387781}, 'module_to_env_connector': {'timers': {'connectors': {'module_to_agent_unmapping': 2.573298619882895e-06, 'get_actions': 3.340469141761125e-05, 'remove_single_ts_time_rank_from_batch': 8.028156854941452e-07, 'tensor_to_numpy': 3.381095333474469e-05, 'normalize_and_clip_actions': 3.539978054516945e-05, 'listify_data_for_vector_env': 6.69353385986943e-06, 'un_batch_to_individual_items': 1.4785462916465214e-05}}, 'connector_pipeline_timer': 0.00015815786703175073}, 'num_agent_steps_sampled': {'servicer': 5000, 'target': 5000}, 'num_agent_steps_sampled_lifetime': {'target': 50000, 'servicer': 50000}, 'episode_return_mean': -1052.6219710341404, 'timers': {'connectors': {'agent_to_module_mapping': 5.6189646249422415e-06, 'batch_individual_items': 2.7264728913608022e-05, 'add_observations_from_episodes_to_batch': 2.9843317727633868e-05, 'add_time_dim_to_batch_and_zero_pad': 1.4434491205339452e-05, 'add_states_from_episodes_to_batch': 6.902622089224512e-06, 'numpy_to_tensor': 4.434185458290612e-05}}, 'num_episodes': 5, 'weights_seq_no': 99.0, 'env_step_timer': 8.949456320609655e-05, 'module_episode_returns_mean': {'target': -4.280016130387781, 'servicer': -1048.341954903753}, 'num_env_steps_sampled': 5000, 'agent_steps': {'servicer': 1000.0, 'target': 1000.0}, 'episode_duration_sec_mean': 0.5439892158894508, 'connector_pipeline_timer': 0.00025203775422295117, 'num_module_steps_sampled': {'servicer': 5000, 'target': 5000}, 'env_to_module_sum_episodes_length_out': 901.0423566894266, 'episode_len_mean': 1000.0, 'rlmodule_inference_timer': 0.0001018039622752937, 'episode_len_max': 1000, 'episode_return_max': -1011.5511544488048, 'sample': 2.766144148682682, 'env_reset_timer': 0.00014861854230583708, 'num_env_steps_sampled_lifetime': 50000, 'env_to_module_sum_episodes_length_in': 901.0423566894266, 'episode_return_min': -1078.2568531362717, 'num_episodes_lifetime': 50, 'episode_len_min': 1000, 'num_env_steps_sampled_per_second': 1721.5595018529218, 'time_between_sampling': 20.366751731830686}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'num_env_steps_sampled_lifetime': 400000, 'fault_tolerance': {'num_healthy_workers': 23, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1243.9417285600503, 'done': False, 'training_iteration': 100, 'trial_id': 'default', 'date': '2025-04-03_20-44-30', 'timestamp': 1743727470, 'time_this_iter_s': 3.2019858360290527, 'time_total_s': 233.9013683795929, 'pid': 76224, 'hostname': 'Nathans-Mac-Studio.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'satellite_marl', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 23, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function <lambda> at 0x374ddc540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 5, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': True, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'servicer': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None), 'target': (None, Box(-inf, inf, (13,), float32), Box(-1.0, 1.0, (6,), float32), None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 233.9013683795929, 'iterations_since_restore': 100, 'perf': {'cpu_util_percent': 79.44000000000001, 'ram_util_percent': 55.2}})
2025-04-03 20:44:30,803 [__main__] [INFO] 
--- Running Evaluation & Recording Video ---
2025-04-03 20:44:30,804 [__main__] [INFO] Successfully retrieved RLModules for evaluation.
2025-04-03 20:44:30,805 [__main__] [INFO] Evaluation Episode: 1/5
2025-04-03 20:44:30,902 [src.satellite_marl_env] [INFO] MuJoCo Renderer initialized for rgb_array.
2025-04-03 20:44:33,765 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 20:44:33,767 [__main__] [INFO] Evaluation Episode 1 Rewards: {'servicer': -1028.8907792850293, 'target': -6.384406590461747}
2025-04-03 20:44:33,768 [__main__] [INFO] Evaluation Episode: 2/5
2025-04-03 20:44:36,514 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 20:44:36,516 [__main__] [INFO] Evaluation Episode 2 Rewards: {'servicer': -1028.8907792850293, 'target': -6.384406590461747}
2025-04-03 20:44:36,517 [__main__] [INFO] Evaluation Episode: 3/5
2025-04-03 20:44:39,241 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 20:44:39,245 [__main__] [INFO] Evaluation Episode 3 Rewards: {'servicer': -1028.8907792850293, 'target': -6.384406590461747}
2025-04-03 20:44:39,245 [__main__] [INFO] Evaluation Episode: 4/5
2025-04-03 20:44:42,049 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 20:44:42,053 [__main__] [INFO] Evaluation Episode 4 Rewards: {'servicer': -1028.8907792850293, 'target': -6.384406590461747}
2025-04-03 20:44:42,053 [__main__] [INFO] Evaluation Episode: 5/5
2025-04-03 20:44:44,877 [src.satellite_marl_env] [INFO] Max steps reached, episode truncated.
2025-04-03 20:44:44,880 [__main__] [INFO] Evaluation Episode 5 Rewards: {'servicer': -1028.8907792850293, 'target': -6.384406590461747}
2025-04-03 20:44:44,888 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 20:44:44,888 [__main__] [INFO] Average Evaluation Rewards over 5 episodes: {'servicer': -1028.8907792850293, 'target': -6.384406590461747}
2025-04-03 20:44:44,888 [__main__] [INFO] Saving evaluation video to: /Users/nathanleo/Downloads/IST 597 - RL/Final Project/RL-Spacecraft-Docking/output/ray_results/evaluation_video.mp4
2025-04-03 20:44:48,453 [__main__] [INFO] Shutting down Ray...
2025-04-03 20:44:49,155 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 20:44:49,168 [src.satellite_marl_env] [INFO] SatelliteMARLEnv closed.
2025-04-03 20:44:50,665 [__main__] [INFO] Script finished.
