{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellites_xml = \"\"\"\n",
    "<mujoco model=\"satellites\">\n",
    "  <compiler angle=\"degree\"/>\n",
    "  <option timestep=\"0.001\" gravity=\"0 0 0\"/>\n",
    "  \n",
    "  <default>\n",
    "    <geom contype=\"1\" conaffinity=\"1\" density=\"1000\" friction=\"0.5 0.005 0.0001\"/>\n",
    "  </default>\n",
    "  \n",
    "  <worldbody>\n",
    "    <light diffuse=\".5 .5 .5\" pos=\"0 0 3\" dir=\"0 0 -1\"/>\n",
    "    <camera pos=\"5 0 2\" xyaxes=\"-1 0 0 0 0 1\"/>\n",
    "    \n",
    "    <!-- Servicing Satellite -->\n",
    "    <body name=\"servicer\" pos=\"0 0 0\">\n",
    "      <joint name=\"servicer_free\" type=\"free\"/>\n",
    "      <!-- Main body -->\n",
    "      <geom name=\"servicer_body\" type=\"cube\" size=\"0.5\" rgba=\"0.7 0.7 0.7 1\"/>\n",
    "      <!-- Docking port (protrusion) -->\n",
    "      <geom name=\"servicer_port\" type=\"cylinder\" pos=\"0 0 0.5\" size=\"0.1 0.2\" rgba=\"1 0 0 1\"/>\n",
    "      <!-- Docking site (for reference) -->\n",
    "      <site name=\"servicer_dock_site\" pos=\"0 0 0.5\" size=\"0.15\" rgba=\"0 1 0 1\"/>\n",
    "    </body>\n",
    "    \n",
    "    <!-- Target Satellite -->\n",
    "    <body name=\"target\" pos=\"3 0 0\">\n",
    "      <joint name=\"target_free\" type=\"free\"/>\n",
    "      <!-- Main body -->\n",
    "      <geom name=\"target_body\" type=\"cube\" size=\"0.5\" rgba=\"0.7 0.7 0.7 1\"/>\n",
    "      <!-- Docking cavity (receptacle) -->\n",
    "      <geom name=\"target_cavity\" type=\"cylinder\" pos=\"0 0 -0.5\" size=\"0.15 0.25\" rgba=\"0 0 1 1\"/>\n",
    "      <!-- Docking site (for reference) -->\n",
    "      <site name=\"target_dock_site\" pos=\"0 0 -0.5\" size=\"0.15\" rgba=\"0 1 0 1\"/>\n",
    "    </body>\n",
    "  </worldbody>\n",
    "</mujoco>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define dynamics\n",
    "#Rigid Body dynamics mujoco shapes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Define satellites shapes\n",
    "#Define scenario and enviorment\n",
    "#Shape Rewards\n",
    "#Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"show_videos\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><video controls width=\"320\" height=\"240\" style=\"object-fit:cover;\" loop autoplay muted>\n",
       "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"/>\n",
       "      This browser does not support the video tag.\n",
       "      </video></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "# Set appropriate backend for macOS\n",
    "if platform.system() == \"Darwin\":\n",
    "    os.environ[\"MUJOCO_GL\"] = \"glfw\"  # macOS native OpenGL context\n",
    "else:\n",
    "    os.environ[\"MUJOCO_GL\"] = \"osmesa\"  # For Linux systems\n",
    "\n",
    "import mujoco\n",
    "import numpy as np\n",
    "import time\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt  # For debugging\n",
    "import mediapy as media\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# XML model definition\n",
    "sat_xml = \"\"\"<mujoco model=\"satellites\">\n",
    "  <compiler angle=\"degree\" />\n",
    "  <option timestep=\"0.01\" gravity=\"0 0 0\" />\n",
    "  <default>\n",
    "    <!-- Default geom properties -->\n",
    "    <geom contype=\"1\" conaffinity=\"1\" friction=\"0.1\" density=\"1000\"/>\n",
    "  </default>\n",
    "\n",
    "  <worldbody>\n",
    "    <!-- Create a camera that follows the servicer -->\n",
    "    <camera name=\"trackercam\" mode=\"trackcom\" target=\"servicer\" pos=\"0 -15 0\"/>\n",
    "    <!-- Fixed camera -->\n",
    "    <camera name=\"fixed\" pos=\"0 -15 2\" xyaxes=\"1 0 0 0 0 1\"/>\n",
    "\n",
    "\n",
    "    \n",
    "    <!-- Lighting -->\n",
    "    <light directional=\"true\" diffuse=\".8 .8 .8\" specular=\".2 .2 .2\" pos=\"0 0 5\" dir=\"0 0 -1\"/>\n",
    "    \n",
    "    <!-- Servicer Satellite -->\n",
    "    <body name=\"servicer\" pos=\"0 2 0\">\n",
    "      <freejoint/>\n",
    "      <!-- Main body (e.g., sphere) -->\n",
    "      <geom type=\"box\" size=\".5 .5 .5\" rgba=\"0.7 0.7 0.7 1\"/>\n",
    "      <!-- Docking port protrusion -->\n",
    "      <geom name=\"servicer_dock_port\" type=\"cylinder\" pos=\"0 0 0.5\" size=\"0.1 0.2\" euler=\"0 0 0\" rgba=\"1 0 0 1\"/>\n",
    "      <!-- Docking detection site -->\n",
    "      <site name=\"servicer_dock_site\" pos=\"0 0 0.5\" size=\"0.15\" rgba=\"0 1 0 0.5\" />\n",
    "    </body>\n",
    "\n",
    "    <!-- Target Satellite -->\n",
    "    <body name=\"target\" pos=\"2 0 0\">\n",
    "      <freejoint/>\n",
    "      <!-- Main body (e.g., sphere) -->\n",
    "      <geom type=\"box\" size=\".5 .5 .5\" rgba=\"0.7 0.7 0.7 1\"/>\n",
    "      <!-- Docking cavity (for receiving the docking port) -->\n",
    "      <geom name=\"target_dock_cavity\" type=\"cylinder\" pos=\"0 0 -0.5\" size=\"0.15 0.25\" euler=\"0 0 0\" rgba=\"0 0 1 1\"/>\n",
    "      <!-- Docking detection site -->\n",
    "      <site name=\"target_dock_site\" pos=\"0 0 -0.5\" size=\"0.15\" rgba=\"0 1 0 0.5\" />\n",
    "    </body>\n",
    "  </worldbody>\n",
    "  \n",
    "\n",
    "  <visual>\n",
    "    <global offwidth=\"1920\" offheight=\"1080\" />\n",
    "  </visual>\n",
    "</mujoco>\n",
    "\"\"\"\n",
    "\n",
    "# Load the model\n",
    "model = mujoco.MjModel.from_xml_string(sat_xml)\n",
    "\n",
    "# Create simulation data\n",
    "data = mujoco.MjData(model)\n",
    "\n",
    "# Set initial conditions\n",
    "# Servicer position and velocity\n",
    "data.qpos[0:3] = np.array([0, 0, 0])      # x, y, z position\n",
    "data.qpos[3:7] = np.array([1, 0, 0, 0])   # quaternion orientation\n",
    "data.qvel[0:3] = np.array([1, 0, 1])      # velocity\n",
    "\n",
    "# Target position and velocity (7 DOF offset for the second free joint)\n",
    "target_offset = 7\n",
    "data.qpos[target_offset:target_offset+3] = np.array([0, 2, 0])  # position\n",
    "data.qpos[target_offset+3:target_offset+7] = np.array([1, 0, 0, 0])  # orientation\n",
    "data.qvel[target_offset:target_offset+3] = np.array([0, 0, 1])  # velocity\n",
    "# Servicer position and orientation (facing +Y)\n",
    "data.qpos[0:3] = np.array([0, 0, 0])      # x, y, z position\n",
    "data.qpos[3:7] = np.array([1, 0, 0, 0])    # identity quaternion (facing +Y)\n",
    "data.qvel[0:6] = 0                         # zero linear and angular velocity\n",
    "\n",
    "# Target position and orientation (facing -Y)\n",
    "target_offset = 7\n",
    "data.qpos[target_offset:target_offset+3] = np.array([0, 2, 0])         # position\n",
    "data.qpos[target_offset+3:target_offset+7] = np.array([0, 0, 1, 0])    # 180° yaw (facing -Y)\n",
    "data.qvel[target_offset:target_offset+6] = 0                           # zero velocity\n",
    "\n",
    "# Simulation parameters\n",
    "duration = 15.0  # seconds\n",
    "dt = model.opt.timestep\n",
    "fps = 30  # Frames per second for rendering\n",
    "render_every = int(1.0 / (dt * fps))  # How many simulation steps between renders\n",
    "\n",
    "# Setup for recording\n",
    "record = True\n",
    "video_path = os.path.join(\"output\", \"satellite_simulation.mp4\")\n",
    "width, height = 640, 480\n",
    "\n",
    "# Option 1: Interactive viewer without recording\n",
    "def run_interactive():\n",
    "    # Initialize the viewer\n",
    "    with mujoco.viewer.launch_passive(model, data) as viewer:\n",
    "        # Initial sync\n",
    "        viewer.sync()\n",
    "        \n",
    "        # Run simulation with rendering\n",
    "        step_count = 0\n",
    "        start_time = time.time()\n",
    "        sim_time = 0\n",
    "        \n",
    "        while sim_time < duration:\n",
    "            # Step the simulation\n",
    "            mujoco.mj_step(model, data)\n",
    "            sim_time += dt\n",
    "            step_count += 1\n",
    "            \n",
    "            # Only render at the specified FPS\n",
    "            if step_count % render_every == 0:\n",
    "                # Update visualization\n",
    "                viewer.sync()\n",
    "                \n",
    "                # Optional: add time delay to watch in real-time\n",
    "                elapsed = time.time() - start_time\n",
    "                if elapsed < sim_time:\n",
    "                    time.sleep(sim_time - elapsed)\n",
    "        \n",
    "        # Keep the viewer open for a moment to see the final state\n",
    "        time.sleep(1.0)\n",
    "\n",
    "# Option 2: Render to offscreen buffer and save video\n",
    "duration = 10  # (seconds)\n",
    "framerate = 60  # (Hz)\n",
    "frames = []\n",
    "scene_option = mujoco.MjvOption()\n",
    "scene_option.flags[mujoco.mjtVisFlag.mjVIS_JOINT] = True\n",
    "#mujoco.mj_resetData(model, data)\n",
    "with mujoco.Renderer(model) as renderer:\n",
    "\n",
    "  while data.time < duration:\n",
    "    mujoco.mj_step(model, data)\n",
    "    if len(frames) < data.time * framerate:\n",
    "      renderer.update_scene(data, scene_option=scene_option)\n",
    "      pixels = renderer.render()\n",
    "      frames.append(pixels)\n",
    "\n",
    "media.show_video(frames, fps=framerate)\n",
    "\n",
    "# Choose which method to use\n",
    "\n",
    "\n",
    "print(\"Simulation complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import mujoco\n",
    "import os\n",
    "import platform\n",
    "\n",
    "# Setup rendering backend\n",
    "if platform.system() == \"Darwin\":\n",
    "    os.environ[\"MUJOCO_GL\"] = \"glfw\"\n",
    "else:\n",
    "    os.environ[\"MUJOCO_GL\"] = \"osmesa\"\n",
    "\n",
    "class SatelliteEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = mujoco.MjModel.from_xml_string(sat_xml)\n",
    "        self.data = mujoco.MjData(self.model)\n",
    "\n",
    "        self.obs_dim = 6  \n",
    "        self.action_dim = 3  #force on servicer\n",
    "\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.obs_dim,), dtype=np.float32)\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(self.action_dim,), dtype=np.float32)\n",
    "        self.max_episode_steps = 500  # or any desired number\n",
    "        self.current_step = 0\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        if seed is not None:\n",
    "            self.np_random, _ = gym.utils.seeding.np_random(seed)\n",
    "\n",
    "        mujoco.mj_resetData(self.model, self.data)\n",
    "\n",
    "        '''# Initialize state\n",
    "        self.data.qpos[:3] = [0, 0, 0]\n",
    "        self.data.qpos[3:7] = [1, 0, 0, 0]\n",
    "        self.data.qvel[:3] = [0, 0, 0]\n",
    "\n",
    "        offset = 7\n",
    "        self.data.qpos[offset:offset+3] = [0, 0, 3]\n",
    "        self.data.qpos[offset+3:offset+7] = [1, 0, 0, 0]\n",
    "        self.data.qvel[offset:offset+3] = [0, 0, 0]'''\n",
    "         # Randomize servicer state\n",
    "        self.data.qpos[:3] = self.np_random.uniform(low=-0.1, high=0.1, size=3)  # small initial position noise\n",
    "        self.data.qpos[3:7] = [1, 0, 0, 0]  # identity quaternion\n",
    "        self.data.qvel[:3] = self.np_random.uniform(low=-0.01, high=0.01, size=3)  # small initial velocity noise\n",
    "\n",
    "    # Randomize target state\n",
    "        offset = 7\n",
    "        self.data.qpos[offset:offset+3] = self.np_random.uniform(low=[-1.5, -1.5, 0.0], high=[1.5, 1.5, 5.5])  # random position near (0,0,3)\n",
    "        self.data.qpos[offset+3:offset+7] = [1, 0, 0, 0]  # identity quaternion\n",
    "        self.data.qvel[offset:offset+3] = self.np_random.uniform(low=-0.01, high=0.01, size=3)  # small initial velocity noise\n",
    "        self.current_step = 0\n",
    "\n",
    "        return self._get_obs(), {}\n",
    "    def _dock_error(self):\n",
    "        sid1 = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_SITE, \"servicer_dock_site\")\n",
    "        sid2 = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_SITE, \"target_dock_site\")\n",
    "        return self.data.site_xpos[sid2] - self.data.site_xpos[sid1]\n",
    "\n",
    "    def step(self, action):\n",
    "        action = np.clip(action, -1.0, 1.0)\n",
    "        self.data.qvel[:3] = action\n",
    "\n",
    "        mujoco.mj_step(self.model, self.data)\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        dock_dist = np.linalg.norm(self._dock_error())\n",
    "\n",
    "        '''\n",
    "        relative_velocity = np.linalg.norm()\n",
    "        reward = -dock_dist\n",
    "        if np.linalg.norm(obs[:3]) < 0.01:\n",
    "            reward = 1\n",
    "        terminated = np.linalg.norm(obs[:3]) < 0.01  #Success\n",
    "        '''\n",
    "        rel_pos = dock_dist\n",
    "        rel_pos = self.data.qpos[7:10] - self.data.qpos[0:3]\n",
    "        rel_vel = self.data.qvel[0:3] - self.data.qvel[6:9]\n",
    "        rel_ang_vel = np.linalg.norm(self.data.qvel[3:6] - self.data.qvel[9:12])\n",
    "\n",
    "    # Unit vector toward target\n",
    "        norm_rel_pos = np.linalg.norm(rel_pos)\n",
    "        if norm_rel_pos > 1e-6:\n",
    "            direction = rel_pos / norm_rel_pos\n",
    "            velocity_toward_target = np.dot(rel_vel, direction)\n",
    "        else:\n",
    "            velocity_toward_target = 0.0\n",
    "\n",
    "    # Reward: encourage motion toward target, discourage distance\n",
    "        reward = velocity_toward_target - 0.1 * dock_dist - rel_ang_vel\n",
    "\n",
    "        terminated = dock_dist < 0.01 and np.linalg.norm(rel_vel) < 1\n",
    "        self.current_step += 1\n",
    "        truncated = self.current_step >= self.max_episode_steps\n",
    "\n",
    "\n",
    "        return obs, reward, terminated, truncated, {}\n",
    "    def _dock_error(self):\n",
    "        sid1 = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_SITE, \"servicer_dock_site\")\n",
    "        sid2 = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_SITE, \"target_dock_site\")\n",
    "        return self.data.site_xpos[sid2] - self.data.site_xpos[sid1]\n",
    "\n",
    "    def _get_obs(self):\n",
    "        pos1 = self.data.qpos[:3]\n",
    "        pos2 = self.data.qpos[7:10]\n",
    "        vel1 = self.data.qvel[:3]\n",
    "        vel2 = self.data.qvel[7:10]\n",
    "        return np.concatenate([pos2 - pos1, vel2 - vel1], dtype=np.float32)\n",
    "\n",
    "    def render_video(self, duration=10, framerate=60):\n",
    "        \"\"\"\n",
    "        Renders a video of the environment for the specified duration\n",
    "        \n",
    "        Args:\n",
    "            duration (float): Duration in seconds\n",
    "            framerate (int): Frames per second\n",
    "            \n",
    "        Returns:\n",
    "            mediapy video object\n",
    "        \"\"\"\n",
    "        # Reset environment to start a fresh simulation\n",
    "        self.reset()\n",
    "        \n",
    "        frames = []\n",
    "        scene_option = mujoco.MjvOption()\n",
    "        scene_option.flags[mujoco.mjtVisFlag.mjVIS_JOINT] = True\n",
    "        \n",
    "        # Create renderer\n",
    "        with mujoco.Renderer(model=self.model, height=480, width=640) as renderer:\n",
    "            # Run simulation and collect frames\n",
    "            while self.data.time < duration:\n",
    "                mujoco.mj_step(self.model, self.data)\n",
    "                \n",
    "                if len(frames) < self.data.time * framerate:\n",
    "                    renderer.update_scene(self.data, scene_option=scene_option)\n",
    "                    pixels = renderer.render()\n",
    "                    frames.append(pixels)\n",
    "        \n",
    "        return media.show_video(frames, fps=framerate)\n",
    "        \n",
    "\n",
    "    def close(self):\n",
    "        if hasattr(self, \"viewer\"):\n",
    "            self.viewer.close()\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = SatelliteEnv()\n",
    "#model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "#model.learn(total_timesteps=100_000)\n",
    "\n",
    "#model.save(\"ppo_satellite_docking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mj_env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 6282 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4420        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012196979 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.27       |\n",
      "|    explained_variance   | -0.011      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.297       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4036        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018182004 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.25       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00804    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 0.046       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3861        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013963673 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | -0.993      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0377     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 0.0421      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3759         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073793745 |\n",
      "|    clip_fraction        | 0.0772       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.2         |\n",
      "|    explained_variance   | -0.742       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0497       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00688     |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 0.178        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3669         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090282895 |\n",
      "|    clip_fraction        | 0.0899       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | -0.287       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0142      |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00892     |\n",
      "|    std                  | 0.971        |\n",
      "|    value_loss           | 0.00658      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3634         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060651875 |\n",
      "|    clip_fraction        | 0.0706       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.17        |\n",
      "|    explained_variance   | 0.0366       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0281      |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00741     |\n",
      "|    std                  | 0.973        |\n",
      "|    value_loss           | 0.0376       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3602        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008778548 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | -0.72       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0167     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.00293     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3587         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051959045 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.19        |\n",
      "|    explained_variance   | 0.173        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00221     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    std                  | 0.984        |\n",
      "|    value_loss           | 0.03         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3578         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070283604 |\n",
      "|    clip_fraction        | 0.0642       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.19        |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00628      |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 0.00103      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3575        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010312734 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 0.000762    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3567        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008029751 |\n",
      "|    clip_fraction        | 0.0772      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0362      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.00267     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3569        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005948852 |\n",
      "|    clip_fraction        | 0.0553      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | -0.0306     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0139      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 0.00994     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3553        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006009817 |\n",
      "|    clip_fraction        | 0.0446      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00156    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    std                  | 0.98        |\n",
      "|    value_loss           | 0.00308     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3538         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076518194 |\n",
      "|    clip_fraction        | 0.0688       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.19        |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0308      |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00742     |\n",
      "|    std                  | 0.979        |\n",
      "|    value_loss           | 0.00039      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3524         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078756325 |\n",
      "|    clip_fraction        | 0.0917       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.19        |\n",
      "|    explained_variance   | 0.916        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0029      |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00885     |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 0.00114      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3511        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010492101 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0255     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 0.00043     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3506        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008990899 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0507     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 0.000675    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m media\u001b[38;5;241m.\u001b[39mshow_video(frames, fps\u001b[38;5;241m=\u001b[39mframerate)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[43mtrain_and_visualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mtrain_and_visualize\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m env \u001b[38;5;241m=\u001b[39m VecNormalize(env, norm_obs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, norm_reward\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10_000_000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_satellite_docking\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Create a new environment for visualization\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mj_env/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mj_env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:324\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 324\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mj_env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:202\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     obs_tensor \u001b[38;5;241m=\u001b[39m obs_as_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 202\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mj_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mj_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mj_env/lib/python3.10/site-packages/stable_baselines3/common/policies.py:654\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[0;34m(self, obs, deterministic)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;66;03m# Evaluate the values for the given observations\u001b[39;00m\n\u001b[1;32m    653\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(latent_vf)\n\u001b[0;32m--> 654\u001b[0m distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_action_dist_from_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m actions \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mget_actions(deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n\u001b[1;32m    656\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mlog_prob(actions)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mj_env/lib/python3.10/site-packages/stable_baselines3/common/policies.py:694\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[0;34m(self, latent_pi)\u001b[0m\n\u001b[1;32m    691\u001b[0m mean_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_net(latent_pi)\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, DiagGaussianDistribution):\n\u001b[0;32m--> 694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproba_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;66;03m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(action_logits\u001b[38;5;241m=\u001b[39mmean_actions)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mj_env/lib/python3.10/site-packages/stable_baselines3/common/distributions.py:164\u001b[0m, in \u001b[0;36mDiagGaussianDistribution.proba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mCreate the distribution given its parameters (mean, std)\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m action_std \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mones_like(mean_actions) \u001b[38;5;241m*\u001b[39m log_std\u001b[38;5;241m.\u001b[39mexp()\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;241m=\u001b[39m \u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mj_env/lib/python3.10/site-packages/torch/distributions/normal.py:59\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mj_env/lib/python3.10/site-packages/torch/distributions/distribution.py:70\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     68\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, param)\n\u001b[1;32m     69\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[0;32m---> 70\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mvalid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     71\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     72\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_and_visualize():\n",
    "    from stable_baselines3 import PPO\n",
    "    from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "    \n",
    "    # Create and train the model\n",
    "    env = SatelliteEnv()\n",
    "    env = DummyVecEnv([lambda: SatelliteEnv()])  # wraps in a VecEnv\n",
    "\n",
    "# Then apply VecNormalize\n",
    "    env = VecNormalize(env, norm_obs=True, norm_reward=True)\n",
    "    model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "    model.learn(total_timesteps=10_000_000)\n",
    "    model.save(\"ppo_satellite_docking\")\n",
    "    \n",
    "    # Create a new environment for visualization\n",
    "    vis_env = SatelliteEnv()\n",
    "    vis_env = DummyVecEnv([lambda: SatelliteEnv()])  # wraps in a VecEnv\n",
    "\n",
    "# Then apply VecNormalize\n",
    "    vis_env = VecNormalize(env, norm_obs=True, norm_reward=True)\n",
    "\n",
    "    \n",
    "    #record a simulation with the trained policy\n",
    "    obs= vis_env.reset()\n",
    "    \n",
    "    # Reset data for visualization\n",
    "    vis_env.reset()\n",
    "    \n",
    "    # Render video of trained agent\n",
    "    print(\"Rendering video...\")\n",
    "    \n",
    "    # Create frames with policy actions\n",
    "    frames = []\n",
    "    scene_option = mujoco.MjvOption()\n",
    "    scene_option.flags[mujoco.mjtVisFlag.mjVIS_JOINT] = True\n",
    "    duration = 10\n",
    "    framerate = 60\n",
    "    '''\n",
    "    with mujoco.Renderer(model=vis_env.model, height=480, width=640) as renderer:\n",
    "        while vis_env.data.time < duration:\n",
    "            # Get action from the trained policy\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            \n",
    "            # Take step in environment\n",
    "            obs, reward, terminated, truncated, _ = vis_env.step(action)\n",
    "            print(\"Reward\",reward)\n",
    "            \n",
    "            # Render frame if needed\n",
    "            if len(frames) < vis_env.data.time * framerate:\n",
    "                renderer.update_scene(vis_env.data, scene_option=scene_option)\n",
    "                pixels = renderer.render()\n",
    "                frames.append(pixels)\n",
    "                \n",
    "            if terminated or truncated:\n",
    "                break\n",
    "    '''\n",
    "    # Unwrap to get the raw env\n",
    "    raw_env = vis_env.venv.envs[0]  # unwrap DummyVecEnv -> SatelliteEnv\n",
    "\n",
    "    with mujoco.Renderer(model=raw_env.model, height=480, width=640) as renderer:\n",
    "        while raw_env.data.time < duration:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, terminated, _ = vis_env.step(action)\n",
    "            print(\"Reward\", reward)\n",
    "\n",
    "            if len(frames) < raw_env.data.time * framerate:\n",
    "                renderer.update_scene(raw_env.data, scene_option=scene_option)\n",
    "                pixels = renderer.render()\n",
    "                frames.append(pixels)\n",
    "\n",
    "            if terminated:\n",
    "                break\n",
    "\n",
    "    # Display the video\n",
    "    return media.show_video(frames, fps=framerate)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mujoco' has no attribute 'viewer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Optional: real-time viewer\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     17\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 73\u001b[0m, in \u001b[0;36mSatelliteEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviewer\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 73\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer \u001b[38;5;241m=\u001b[39m \u001b[43mmujoco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviewer\u001b[49m\u001b[38;5;241m.\u001b[39mlaunch_passive(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer\u001b[38;5;241m.\u001b[39msync()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mujoco' has no attribute 'viewer'"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import time\n",
    "\n",
    "# Load trained model\n",
    "#model = PPO.load(\".zip\")\n",
    "\n",
    "# Create env (same as during training)\n",
    "env = SatelliteEnv()\n",
    "\n",
    "obs = env.reset()[0]  # for gym>=0.26\n",
    "done = False\n",
    "\n",
    "# Optional: real-time viewer\n",
    "env.render()\n",
    "\n",
    "while not done:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    time.sleep(env.model.opt.timestep)  # slow down for visibility\n",
    "\n",
    "env.close()\n",
    "import imageio\n",
    "\n",
    "frames = []\n",
    "obs = env.reset()[0]\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    frame = env.render(mode=\"rgb_array\")  # requires proper render implementation\n",
    "    frames.append(frame)\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "# Save as video\n",
    "imageio.mimsave(\"docking_test.mp4\", frames, fps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SatelliteEnv' object has no attribute 'viewer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 90\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo saved as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m     env\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m---> 90\u001b[0m \u001b[43mcreate_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 75\u001b[0m, in \u001b[0;36mcreate_video\u001b[0;34m(env, steps, filename)\u001b[0m\n\u001b[1;32m     73\u001b[0m action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()  \u001b[38;5;66;03m# Random action\u001b[39;00m\n\u001b[1;32m     74\u001b[0m obs, reward, done,truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m---> 75\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrgb_array\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(frame)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "Cell \u001b[0;32mIn[11], line 72\u001b[0m, in \u001b[0;36mSatelliteEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviewer\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;66;03m# Use mujoco_viewer package instead of mujoco.viewer\u001b[39;00m\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer \u001b[38;5;241m=\u001b[39m mujoco_viewer\u001b[38;5;241m.\u001b[39mMujocoViewer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SatelliteEnv' object has no attribute 'viewer'"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import time\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have the SatelliteEnv class defined elsewhere\n",
    "# and it's imported properly at the top of your script\n",
    "\n",
    "# Create env\n",
    "env = SatelliteEnv()\n",
    "\n",
    "# For demonstration, we'll use random actions\n",
    "# But you can uncomment the model loading part if you have a trained model\n",
    "# model = PPO.load(\"ppo_satellite_docking\")\n",
    "\n",
    "# Option 1: Real-time visualization (using random actions if no model available)\n",
    "def visualize_realtime():\n",
    "    obs = env.reset()  # No need for [0] with regular gym\n",
    "    done = False\n",
    "    \n",
    "    # If you have a trained model:\n",
    "    # while not done:\n",
    "    #     action, _ = model.predict(obs, deterministic=True)\n",
    "    #     obs, reward, done, info = env.step(action)\n",
    "    #     env.render()\n",
    "    #     time.sleep(env.model.opt.timestep)  # slow down for visibility\n",
    "    \n",
    "    # For testing without a model (random actions):\n",
    "    for _ in range(200):  # Run for 200 steps or until done\n",
    "        action = env.action_space.sample()  # Random action\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        time.sleep(env.model.opt.timestep)\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "# Option 2: Save as video\n",
    "def create_video():\n",
    "    frames = []\n",
    "    obs = env.reset()  # No need for [0] with regular gym\n",
    "    done = False\n",
    "    \n",
    "    # If you have a trained model:\n",
    "    # while not done:\n",
    "    #     action, _ = model.predict(obs, deterministic=True)\n",
    "    #     obs, reward, done, info = env.step(action)\n",
    "    #     frame = env.render(mode=\"rgb_array\")\n",
    "    #     frames.append(frame)\n",
    "    \n",
    "    # For testing without a model (random actions):\n",
    "    for _ in range(200):  # Run for 200 steps or until done\n",
    "        action = env.action_space.sample()  # Random action\n",
    "        obs, reward, terminated,truncated, info = env.step(action)\n",
    "        frame = env.render(mode=\"rgb_array\")\n",
    "        frames.append(frame)\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    # Convert frames to uint8 if they aren't already\n",
    "    frames = [frame.astype(np.uint8) if frame.dtype != np.uint8 else frame for frame in frames]\n",
    "    \n",
    "    # Save as video\n",
    "    imageio.mimsave(\"docking_test.mp4\", frames, fps=30)\n",
    "    print(\"Video saved as docking_test.mp4\")\n",
    "def create_video(env, steps=200, filename=\"docking_test.mp4\"):\n",
    "    frames = []\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    for _ in range(steps):  # Run for specified steps or until done\n",
    "        action = env.action_space.sample()  # Random action\n",
    "        obs, reward, done,truncated, info = env.step(action)\n",
    "        frame = env.render(mode=\"rgb_array\")\n",
    "        frames.append(frame)\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    # Convert frames to uint8 if they aren't already\n",
    "    frames = [frame.astype(np.uint8) if frame.dtype != np.uint8 else frame for frame in frames]\n",
    "    \n",
    "    # Save as video\n",
    "    imageio.mimsave(filename, frames, fps=30)\n",
    "    print(f\"Video saved as {filename}\")\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "\n",
    "create_video(env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
